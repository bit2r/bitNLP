[{"path":"https://r2bit.com/bitNLP/dev/CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"기여자 행동 강령","title":"기여자 행동 강령","text":"이 프로젝트의 기여자이자 유지 관리자로서 우리는 문제(issues)의 보고, 기능 요청 게시, 문서 업데이트, 풀(pull) 요청 또는 패치 제출 및 기타 활동을 통해 기여하는 모든 사람들을 존중할 것을 약속합니다. 우리는 경험의 수준, 성별, 성 정체성 및 표현, 성적 취향, 장애, 외모, 신체 크기, 인종, 민족, 연령 또는 종교에 관계없이 모든 사람이 이 프로젝트에 괴롭힘 없는 경험을 할 수 있도록 최선을 다하고 있습니다. 참가자가 용인할 수 없는 행동의 예로는 성적인 언어나 이미지의 사용, 경멸적인 말이나 인신공격, 조롱, 공개적 또는 사적 괴롭힘, 모욕 또는 기타 비전문적인 행동이 있습니다. 프로젝트 관리자는 이 행동 강령과 일치하지 않는 주석, 커밋, 코드, Wiki 편집, 문제 및 기타 기여를 제거, 편집 또는 거부할 권리와 책임이 있습니다. 행동 강령을 따르지 않는 프로젝트 관리자는 프로젝트 팀에서 제거될 수 있습니다. 욕설, 괴롭힘 또는 기타 용납할 수 없는 행동의 사례는 문제를 열거나 한 명 이상의 프로젝트 관리자에게 연락하여 보고할 수 있습니다. 이 행동 강령은 Contributor Covenant(http:contributor-covenant.org) 버전 1.0.0에서 수정되었습니다. 해당 버전은 http://contributor-covenant.org/version/1/0/0/에서 보실 수 있습니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/CONDUCT.html","id":"contributor-code-of-conduct","dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"기여자 행동 강령","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http:contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"install-bitnlp-in-rstudio-cloud","dir":"Articles","previous_headings":"","what":"Install bitNLP in RStudio Cloud","title":"Install bitNLP in RStudio Cloud","text":"RStudio Cloud 환경은 RStudio사1가 제공하는, Cloud 환경에서 RStudio를 사용할 수 있게 제공하는 서비스입니다. 작은 리소스로 제공하는 이 서비스는, 인터넷만 있으면 어디서든 R Studio 환경으로 코드를 실행해볼 수있기 때문에 R 교육 환경으로 활용하기에 안성맞춤입니다. RStudio Cloud는 여러 제약 사항이 있기 때문에 bitNLP를 설치하기 쉽지 않습니다. RStudio Cloud 환경에 맞는 별도의 작업이 필요합니다. 여기서는 별도의 작업을 통해서 RStudio Cloud에 bitNLP를 설치하는 방법을 다룹니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"install-mecab-ko-in-rstudio-cloud","dir":"Articles","previous_headings":"","what":"Install mecab-ko in Rstudio Cloud","title":"Install bitNLP in RStudio Cloud","text":"RStudio Cloud에서 사용자는 시스템 디렉토리인 /usr/local 디렉터리에 접근할 수 없습니다. 그래서 mecab-ko를 사용자가 접근 가능한 /cloud/lib 경로에 설치하려 합니다. 다음의 스크립트는 표준 R 서버를 위한 Docker 이미지인 docker_rserver의 mecab-ko 설치 스크립트를 RStudio Cloud 환경에 맞게 수정한 스크립트입니다.","code":"#!/bin/bash set -e  # 설치 리소스를 저장할 디렉토리  INSTALLD='/cloud/project/install_resources'   #--------------------------------------------- # 은전한닙 형태소분석기 설치 #--------------------------------------------- mkdir -p ${INSTALLD} cd ${INSTALLD} wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz  tar xzvf mecab-0.996-ko-0.9.2.tar.gz  cd ${INSTALLD}/mecab-0.996-ko-0.9.2  ./configure --prefix=/cloud/lib make  make install  ldconfig   # 설치파일 삭제 rm -rf $INSTALLD/mecab-0.996-ko-0.9.2  rm -rf $INSTALLD/mecab-0.996-ko-0.9.2.tar.gz  PATH=/cloud/lib/bin:$PATH  #--------------------------------------------- # 은전한닙 형태소분석기 사전 설치 #--------------------------------------------- cd ${INSTALLD} wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz  tar xvfz mecab-ko-dic-2.1.1-20180720.tar.gz  cd ${INSTALLD}/mecab-ko-dic-2.1.1-20180720  autoreconf  ./configure --prefix=/cloud/lib make make install  # 설치파일 삭제     rm -rf $INSTALLD/mecab-ko-dic-2.1.1-20180720.tar.gz"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"test-mecab-ko","dir":"Articles","previous_headings":"Install mecab-ko in Rstudio Cloud","what":"Test mecab-ko","title":"Install bitNLP in RStudio Cloud","text":"Shell 환경에서 mecab-ko의 설치 여부를 테스트하기 위해서 다음 명령어를 수행합니다.","code":"echo \"아버지가 방에 들어가신다.\" | mecab 아버지 NNG,*,F,아버지,*,*,*,* 가   JKS,*,F,가,*,*,*,* 방   NNG,장소,T,방,*,*,*,* 에   JKB,*,F,에,*,*,*,* 들어가 VV,*,F,들어가,*,*,*,* 신다  EP+EF,*,F,신다,Inflect,EP,EF,시/EP/*+ᆫ다/EF/* .   SF,*,*,*,*,*,*,* EOS"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"install-rcppmecab","dir":"Articles","previous_headings":"","what":"Install RcppMeCab","title":"Install bitNLP in RStudio Cloud","text":"bitNLP 패키지의 형태소 토크나이징은 RcppMeCab 패키지를 이용합니다. 그래서 RcppMeCab 패키지를 설치합니다. RcppMeCab 패키지는 mecab-ko의 동적 라이브러리인 libmecab..2를 사용합니다. 그래서 패키지를 설치하기 전에 이 동적 라이브러리를 접근할 수 있도록 설정해야 합니다. RStduo Server는 /etc/rstudio/rserver.conf 파일에 다음처럼 동적라이브러리의 경로를 설정합니다. 그러나 RStudio Cloud에서는 해당 파일을 수정할 수 있는 권한이 없기 때문에, dyn.load()로 동적 라이브러리를 로드해야 합니다.","code":"rsession-ld-library-path=/cloud/lib/lib # for binary Sys.setenv(PATH=paste(\"/cloud/lib/bin\", Sys.getenv(\"PATH\"), sep = \":\"))  # for ld library dyn.load(\"/cloud/lib/lib/libmecab.so.2\")  install.packages('RcppMeCab')"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"install-bitnlp","dir":"Articles","previous_headings":"","what":"Install bitNLP","title":"Install bitNLP in RStudio Cloud","text":"현재 bitNLP는 CRAN에 등록되어 있지 않습니다. 그래서 다음과 같이 Github의 개발버전을 설치합니다.","code":"remotes::install_github('bit2r/bitNLP')"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"test-bitnlp","dir":"Articles","previous_headings":"Install bitNLP","what":"Test bitNLP","title":"Install bitNLP in RStudio Cloud","text":"bitNLP의 설치를 확인하기 위해서다음과 같이 명사의 토큰을 추출해 봅니다. 라이브러리를 로드한 후에 동적 라이브러리인 libmecab..2를 로드해야됩니다. `NNG      NNG  \"아버지\"     \"방\"","code":"library(\"bitNLP\") dyn.load(\"/cloud/lib/lib/libmecab.so.2\")  morpho_mecab(\"아버지가 방에 들어가신다.\")"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"set-environments","dir":"Articles","previous_headings":"","what":"Set environments","title":"Install bitNLP in RStudio Cloud","text":"앞에서 bitNLP를 설치했지만, 세션이 종료되고 다시 RStudio 환경에서 bitNLP를 RStudio Cloud에서 사용하기 위해서는 몇 가지 설정이 필요합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"set-path","dir":"Articles","previous_headings":"Set environments","what":"Set PATH","title":"Install bitNLP in RStudio Cloud","text":".Renviron 파일을 통해서 PATH에 다음과 같이 mecab이 포함된 경로를 추가합니다. 아쉽게도 LD_LIBRARY_PATH 환경변수는 RStudio Cloud 환경에서 적용되지 않았습니다. 그래서 .Rprofile 파일을 이용해서 설정해야 합니다.","code":"PATH=/cloud/lib/bin:${PATH} LD_LIBRARY_PATH=/cloud/lib/lib:${LD_LIBRARY_PATH}"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_in_RstudioCloud.html","id":"set-ld_path_path","dir":"Articles","previous_headings":"Set environments","what":"Set LD_PATH_PATH","title":"Install bitNLP in RStudio Cloud","text":".Rprofile 파일에 다음과 같이 libmecab..2를 로드하는 스크립트를 기술합니다.","code":"dyn.load(\"/cloud/lib/lib/libmecab.so.2\")"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"은전한닢-형태소분석기","dir":"Articles","previous_headings":"","what":"은전한닢 형태소분석기","title":"Install mecab-ko","text":"은전한닢 형태소분석기(mecab-ko)는 오픈소스 일본어 형태소분석기인 MeCab(메카브)를 한글의 특성을 반영하여 포팅한 오픈소스입니다. 은전한닢은 국립국어원의 21세기 세종계획 말뭉치(Corpus)로 모델을 학습하였습니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"은전한닢-형태소분석기-장점","dir":"Articles","previous_headings":"은전한닢 형태소분석기","what":"은전한닢 형태소분석기 장점","title":"Install mecab-ko","text":"어찌보면 MeCab의 장점이겠습니다.1 사전, 코퍼스 독립적 범용 디자인 조건부 확률 필드 (CRF)를 기반으로 한 높은 분석 정확도 사전 추출 알고리즘/데이터 구조에는 고속 TRIE 구조인 Double-Array 채택 C++로 개발 perl/ruby/python/java/C#","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"linix와-mac-운영체제","dir":"Articles","previous_headings":"은전한닢 형태소분석기 설치","what":"Linix와 Mac 운영체제","title":"Install mecab-ko","text":"은전한닢 형태소분석기인 mecab-ko와 한글사전인 mecab-ko-dic을 설치해야하는데, Linux와 Mac 운영체제에서의 은전한닢 형태소분석시의 설치는 그리 어렵지 않습니다. mecab-ko-dic 페이지에 설치 방법이 잘 가이드되어 있어, 기술하는 방법으로 소스를 컴파일하여 설치하면 됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"windows-운영체제","dir":"Articles","previous_headings":"은전한닢 형태소분석기 설치","what":"Windows 운영체제","title":"Install mecab-ko","text":"Windows 운영체제에서의 mecab-ko와 mecab-ko-dic을 설치하는 것은 쉽지 않았습니다. 그러나 형태소분석기와 사전을 Windows 환경에서 컴파일한 바이너리 버전을 다음 사이트에서 다운로드 받아 “c:/mecab” 디렉토리에 설치하면 됩니다. 반드시 “c:/mecab” 경로에 설치해야 형태소분석기를 정상적으로 사용할 수 있습니다. mecab-ko-msvc mecab-ko-dic-msvc","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"bitnlp-패키지를-이용한-설치","dir":"Articles","previous_headings":"은전한닢 형태소분석기 설치","what":"bitNLP 패키지를 이용한 설치","title":"Install mecab-ko","text":"은전한닢 형태소분석기를 설치하지 않은 상태에서 bitNLP 패키지를 로드하면, 다음과 같은 메시지가 출력됩니다. Window 운영체제 Mac, Linux 운영체제 Linix와 Mac, Windows 운영체제와 무관하게 bitNLP 패키지의 install_mecab_ko() 함수는 은전한닢 형태소분석기와 한글사전을 설치해줍니다. 그러므로 은전한닢 형태소분석기를 설치하지 않은 상태라면, install_mecab_ko() 함수를 사용하는 것을 추천합니다. 다음과 같이 설치합니다. 다음은 Winows 운영체제에서의 설치 예시입니다. Winows 운영체제에서는 바이너리 프로그램을 다운로드한 후 “c:/mecab” 경로에 복사하는 것으로 설치됩니다. Windows 환경에서 bitNLP 패키지 설치 이전에 이미 mecab-ko와 mecab-ko-dic을 “c:/mecab” 경로에 설치하였다면, 다음처럼 regist_mecab_ko()로 설치된 경로를 bitNLP 패키지에 등록합니다.","code":"> library(bitNLP) To use bitNLP, you need to install mecab-ko and mecab-ko-dic. You can install it with install_mecab_ko(). You have already installed mecab-ko in 'c:/mecab', register the installed path with regist_mecab_ko(). > library(bitNLP) To use bitNLP, you need to install mecab-ko and mecab-ko-dic. You can install it with install_mecab_ko(). library(bitNLP)  install_mecab_ko() > install_mecab_ko() Install mecab-ko-msvc...trying URL 'https://github.com/Pusnow/mecab-ko-msvc/releases/download/release-0.9.2-msvc-3/mecab-ko-msvc-x64.zip' Content type 'application/octet-stream' length 777244 bytes (759 KB) downloaded 759 KB  Install mecab-ko-dic-msvc...trying URL 'https://github.com/Pusnow/mecab-ko-dic-msvc/releases/download/mecab-ko-dic-2.0.3-20170922-msvc/mecab-ko-dic-msvc.zip' Content type 'application/octet-stream' length 32531949 bytes (31.0 MB) downloaded 31.0 MB regist_mecab_ko()"},{"path":"https://r2bit.com/bitNLP/dev/articles/Install_mecab.html","id":"rcppmecab-패키지-설치","dir":"Articles","previous_headings":"은전한닢 형태소분석기 설치","what":"RcppMeCab 패키지 설치","title":"Install mecab-ko","text":"bitNLP에서 형태소분석 기능을 사용하기 위해서는 RcppMeCab 패키지를 설치해야 합니다. 만약에 이 패키지가 설치되어 있지 않다면, 형태소분석기를 호출할 때 다음과 같은 에러가 발생합니다. RcppMeCab은 CRAN에 등록된 패키지므로 다음처럼 간단하게 설치합니다. 여기까지 설치되었다면 비로소 형태소분석을 수행할 수 있습니다.","code":"> morpho_mecab(\"아버지가 방에 들어가신다.\") Error in morpho_mecab(\"아버지가 방에 들어가신다.\") :    To use morpho_mecab(), you need to install RcppMeCab package. You can install it with install.packages(\"RcppMeCab\"). install.packages(\"RcppMeCab\") library(\"bitNLP\")  morpho_mecab(\"아버지가 방에 들어가신다.\", type = \"morpheme\")      NNG      JKS      NNG      JKB       VV    EP+EF       SF  \"아버지\"     \"가\"     \"방\"     \"에\" \"들어가\"   \"신다\"      \".\""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"bitnlp","dir":"Articles","previous_headings":"","what":"bitNLP","title":"Introduce bitNLP","text":"bitNLP는 텍스트 데이터의 자연어 처리(NLP, Natural Language Processing), 텍스트 분석 모델 및 텍스트 분석을 위한 시각화와 도구 모음입니다.","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"텍스트-데이터-전처리-기능","dir":"Articles","previous_headings":"bitNLP > 기능","what":"텍스트 데이터 전처리 기능","title":"Introduce bitNLP","text":"문서 필터링 (Filter Documents) 텍스트 대체 (Replace Texts) 텍스트 연결 (Concatenate Texts) 텍스트 분리 (Split Texts) 텍스트 제거 (Remove Texts) 띄어쓰기 보정 N-Grams 토큰화 (Extracting N-Grams) 품사 기반의 토큰화","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"텍스트-데이터-탐색-기능","dir":"Articles","previous_headings":"bitNLP > 기능","what":"텍스트 데이터 탐색 기능","title":"Introduce bitNLP","text":"텍스트 데이터를 탐색하여, 분석의 실마리를 찾거나 정제하는 기능의 Shiny 앱 제공 패턴 검색 패턴 검색 및 치환 N-Grams 토큰화 (Extracting N-Grams) 품사 기반의 토큰화 (Extracting Nouns) Collocation Analysis Explore Docs","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"형태소분석-기능","dir":"Articles","previous_headings":"bitNLP > 기능","what":"형태소분석 기능","title":"Introduce bitNLP","text":"품사 태깅 품사 기반의 토큰화 Morphological Analysis","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"감성분석","dir":"Articles","previous_headings":"bitNLP > 기능","what":"감성분석","title":"Introduce bitNLP","text":"Positive/Negative 복합 (Complex) 부정 (Negative) 긍정 (Positive) 중립 (Neutral) 해당없음 (None) 주관성(subjectivity) 도출","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"tidytext-패키지-호환","dir":"Articles","previous_headings":"bitNLP > 기능","what":"tidytext 패키지 호환","title":"Introduce bitNLP","text":"morpho_mecab() tokenize_noun_ngrams() unnest_noun_ngrams() Collaboration tidytext package","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/Introduce.html","id":"특장점","dir":"Articles","previous_headings":"","what":"특장점","title":"Introduce bitNLP","text":"bitNLP는 토이(Toy) 데이터가 아닌 대용량 텍스트 데이터 처리를 목적으로 개발되었으며, 다음과 같은 특장점이 있습니다. 속도가 빠르고 성능이 좋은 mecab-ko를 형태소분석기로 채택 병렬처리 프로세싱 구현 Shiny 앱으로 텍스트 데이터를 탐색하여 정제 룰을 발견하고, 정제룰을 메타 파일에 등록하여, 룰 기반의 데이터 전처리 수행 -","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"텍스트-데이터-탐색","dir":"Articles","previous_headings":"","what":"텍스트 데이터 탐색","title":"Explore Documents","text":"데이터 분석을 위해서 데이터를 탐색(EDA, Exploratory Data Analysis)하는 것처럼 텍스트 데이터 분석 역시 데이터의 탐색이 필요합니다. 이 작업을 통해 분석가는 주관적인 판단으로 데이터의 품질을 정성적으로 느끼거나, 데이터를 분석하기 위한 실마리를 찾습니다. 데이터 품질의 인식은 데이터 정제의 패턴 룰을 발견하고, 필터링 룰을 도출하여 분석 대상 문서를 선별하는 작업의 기초가 됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"text-data-explorer","dir":"Articles","previous_headings":"텍스트 데이터 탐색","what":"Text Data Explorer","title":"Explore Documents","text":"bitNLP에는 buzz라는 데이터를 제공하는데 다음과 같은 변수를 가지고 있습니다. 변수 CONTENT를 대상으로 데이터를 탐색해야 합니다. bitNLP는 텍스트 데이터를 탐색할 수 있는 Text Data Explorer를 제공합니다. Text Data Explorer는 Shiny 앱으로 explore_docs() 함수로 호출합니다.","code":"names(bitNLP::buzz)  [1] \"KEYWORD\"        \"SRC\"            \"SECTION\"        \"CRAWL_DT\"        [5] \"PUBLISH_DT\"     \"URL\"            \"TITLE\"          \"CONTENT\"         [9] \"DOC_KEY\"        \"PUBLISH_ID\"     \"CLICK_CNT\"      \"LIKE_CNT\"       [13] \"SEARCH_KEYWORD\" library(bitNLP) data(buzz)  explore_docs()"},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"데이터-구조-파악하기","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능","what":"데이터 구조 파악하기","title":"Explore Documents","text":"Text Data Explorer가 실행되면 다음과 같은, 분석할 데이터를 선택하고, 선택한 데이터의 변수 구조를 알수 있는 데이터 탭이 보여집니다. 현재는 데이터 프레임 객체가 buzz 하나라서 자동으로 해당 데이터가 선택되었습니다. 분석할 데이터 프레임 객체를 선택하면, 오른쪽 테이블에서는 데이터 프레임 객체의 변수 이름과 데이터 유형이 출력됩니다. 그리과 좌측에는 텍스트 데이터를 편집했을 경우, 데이터를 저장하는 기능의 위젯이 위치합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"데이터-탐색과-정제하기","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능","what":"데이터 탐색과 정제하기","title":"Explore Documents","text":"텍스트 데이터를 탐색할 때 특히 하나의 문서가 아니라 여러 개의 문서들로 구성되었을 때, 문서를 하나씩 패치하여 읽어나가거나 정규표현식을 만족하는 문서만 추려서 하나씩 패치하면서 살펴봅니다. 경우에 따라서는 문서 내에서 오기된 단어들을 수정하기도 합니다. 이러한 작업을 콘솔에서 수행하기에는 여간 성가신 것이 아닙니다. 또한 긴 문장으로 구성된 텍스트는 콘솔에서는 일부만 표현되기도 합니다. Text Data Explorer는 텍스트 데이터를 탐색하고 정제할 수 있는 간단한 기능을 제공합니다. 이 기능은 검색/대체 탭을 사용합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"탐색을-위한-변수-선택","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능 > 데이터 탐색과 정제하기","what":"탐색을 위한 변수 선택","title":"Explore Documents","text":"데이터를 탐색하는 방법을 정의하는 과정입니다. 데이터 프레임 객체에서 대상 변수를 선택하는 과정입니다. 다음과 같은 변수를 선택합니다. 패치하면서 출력되는 문서를 식별하거나, 보조적 정보를 표현활 변수들을 선택합니다. 탐색할, 텍스트 분석의 대상이 데는 문서를 담은 변수를 선택합니다. 탐색할 문서들 중에서 특정 조건에 해당하는 하위 집합을 정의할 변수를 선택합니다. 범주형/문자형 데이터가 대상이됩니다. 조건변수값에서 해당 변수에서 탐색한 수준(levels)을 선택합니다. 다음 그림은 buzz의 CONTENTS 변수를 탐색하는데, 그 대상은 KEYWORD가 맞벌이인 데이터를 대상으로 합니다. 화면에는 CONTENTS와 함께 TITLE, SECTION, KEYWORD를 표시할 것입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"검색","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능 > 데이터 탐색과 정제하기","what":"검색","title":"Explore Documents","text":"패턴 검색에 검색하려는 정규표현식을 입력한 후 검색 버튼을 누르면 다음처럼 정규표현식을 만족하는 문서들이 출력됩니다. 1000개의 문서들 중에서 19개의 문서에 검색 패턴인 기저귀가 포함되었으며, 그 중 첫번째 문서라는 것을 알려줍니다. 패턴과 매치되는 텍스트는 붉은색으로 표시됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"패치","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능 > 데이터 탐색과 정제하기","what":"패치","title":"Explore Documents","text":"오른쪽 방향 버튼을 누르면 두번째 문서화면으로 이동(패치)됩니다. 반대의 경우도 가능합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"대체","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능 > 데이터 탐색과 정제하기","what":"대체","title":"Explore Documents","text":"검색한 패턴을 다른 문자열로 대체할 수도 있습니다. 텍스트 데이터의 정제를 위한 기능입니다. 다음은 전업주부라는 복합명사(compound noun)가 전업 주부로 분리되어 있는 사례를 보정하는 예시입니다.  만약에 대체 기능으로 텍스트 데이터를 수정(정제)하였다면, “데이터 구조 파악하기”에서 소개한 저장 기능을 이용해서 변경된 데이터를 저장해야 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"형태소분석을-이용한-데이터-탐색","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능","what":"형태소분석을 이용한 데이터 탐색","title":"Explore Documents","text":"형태소분석 탭의 기능은 장문의 본문을 일일이 읽기 어려울 경우에 유용한 기능입니다. 원문과 함께 명사만 추출한 정보를 제공해서 명사를 탐색하면서 문장의 전체 맥락을 속성으로 이해할 수 있습니다. 몇몇 개의 문서를 탐색하는 경우에는 문제가 발생하지 않지만, 하루 종일 수백, 수천개의 문서를 탐색하면서 텍스트 분석의 실마리를 찾아야하는 경우에 천사와 같은 기능을 제공해줄 것입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"공동발생분석을-이용한-데이터-탐색","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능","what":"공동발생분석을 이용한 데이터 탐색","title":"Explore Documents","text":"공동발생분석 탭의 기능은 검색 키워드와 공동으로 발현(collocation)하는 명사들을 추출해줍니다. 관심있는 키워드와 함께 이야기하는 주제를 파악하기 쉽습니다. 입력 위젯의 Span은 공동발현하는 명사가 키워드를 중심으로 몇번 째 거리에서 출현하는가를 정의합니다. 즉, 아래 그림의 예제는 기저귀와 2번째 거리 이내의 명사를 리스트업합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"n-grams를-이용한-데이터-탐색","dir":"Articles","previous_headings":"텍스트 데이터 탐색 > Text Data Explorer 기능","what":"n-grams를 이용한 데이터 탐색","title":"Explore Documents","text":"N-Gram 탭의 기능은 검색 키워드로 검색된 개별 문서에 대해서 명사를 n-gram으로 토큰화합니다. 이 기능 역시 문서의 주제를 찾는데 유용합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/explore_docs.html","id":"r-명령어-실행","dir":"Articles","previous_headings":"텍스트 데이터 탐색","what":"R 명령어 실행","title":"Explore Documents","text":"bitNLP 패키지에서 실행한 Shiny 앱은 모달(Modal) 창을 띄웁니다. 이것은 앱이 종료되기 전는에 R 콘솔을 사용할 수 없다는 것을 의미합니다. 그래서 Text Data Explorer는 간단한 R 스크립트를 수행할 수 있는 기능을 구현했습니다. R Command 탭은 간단한 R 스크립트를 수행할 수 있습니다. 다음 예제는 Text Data Explorer를 사용중에 get_spacing()으로 문서의 띄어쓰기를 보정하는 예시입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"형태소-사전-관리","dir":"Articles","previous_headings":"","what":"형태소 사전 관리","title":"Manage Dictionary","text":"bitNLP는 은전한닢 형태소분석기를 이용하여 형태소 분석을 수행합니다. 이 과정에서 품사 태깅(토크나이징) 결과가 분석가가 의도하는대로 이뤄지지 않을 수 있습니다. 여기서는 형태소 사전 관리를 통해서 사용자가 의도하는대로 분석이 수행되는 것을 유도하는 방법을 다룹니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"bitnlp의-형태소-관리-기능","dir":"Articles","previous_headings":"형태소 사전 관리","what":"bitNLP의 형태소 관리 기능","title":"Manage Dictionary","text":"형태소 사전 관리는 일반적으로 다음 표의 프로세스 순으로 진행합니다. get_plan_cost() get_userdic_meta() append_userdic_meta() add_sysdic() create_userdic() add_userdic() create_userdic() morpho_mecab() edit_index_dic() update_userdic()","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"낱말비용-기반의-토크나이저-플랜-조회","dir":"Articles","previous_headings":"","what":"낱말비용 기반의 토크나이저 플랜 조회","title":"Manage Dictionary","text":"형태소 분석기가 문장을 품사로 토크나이징할 때에는 낱말비용의 크기로 코크나이징합니다. 만약에 문장이 의도하지 않는 결과로 토크나이징된다면 낱말비용 기반의 토크나이저 플랜을 조회합니다. 토크나이저 플랜을 조회하는 이유는 이미 해당 토큰(낱말)이 사전에 등록되어 있으나, 비용이 커서 의도하지 않는 결과가 나타날 수 있기 때문입니다. 이 경우에는 사전에 등록하는 것보다는 낱말비용을 수정하는 방법으로 원하는 결과의 도출을 유도해야 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"형태소-분석","dir":"Articles","previous_headings":"","what":"형태소 분석","title":"Manage Dictionary","text":"“윤희근은 경찰청장이다.”라는 문장에 대해서, morpho_mecab() 함수를 이용해서 형태소 단위로 토큰화합니다. 윤희근이라는 인명과 경찰청장이라는 일반명사가 토큰화되지 못했습니다. 신규 임명된 정부 및 공공기관의 기관장이나 새로 떠오르는 학계/예체능계 스타 이름은 시스템 사전에 없을 가능성이 있습니다. 이제 우리는 잘못된 토큰화를 바로잡는 과정을 진행할 것입니다.","code":"> doc <- \"윤희근은 경찰청장이다.\" > morpho_mecab(doc, type = \"morphe\")    NNP    NNG     JX    NNG    NNG     VCP     EF     SF  \"윤희\"   \"근\"    \"은\"  \"경찰\" \"청장\"   \"이\"   \"다\"    \".\""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"get_plan_cost","dir":"Articles","previous_headings":"형태소 분석","what":"get_plan_cost()","title":"Manage Dictionary","text":"get_plan_cost()는 낱말비용 기반의 토크나이저 플랜을 조회합니다. 다음과 같은 인수를 사용합니다. x: 플랜을 조회할 낱말이나 문장. 기본값은 3임. 플랜의 개수가 topn보다 작다면, topn 만큼 반복 출력됨 지정하지 않으면, bitNLP가 설치한 사전 경로를 사용 “윤희근은 경찰청장이다.”라는 문장에 대해서 낱말비용 기반의 토크나이저 플랜 상위 2개를 조회합니다. 결과를 보면 윤희근이라는 인명과 경찰청장이라는 일반명사가 어떤 순위로 토큰화되는 지 알 수 있습니다. 토크나이저 플랜이 2개 중에서 상위 1번째 플랜은 다음과 같습니다. 이 결과는 morpho_mecab()의 결과와 동일합니다. 윤희\\NNP+근\\NNG+은\\JX+경찰\\NNG+청장\\NNG+이\\VCP+다\\EF+.\\SF 그런데 우리가 기대한 플랜은 다음과 같습니다. 윤희근\\NNP+은\\JX+경찰청장\\NNG+이\\VCP+다\\EF+.\\SF","code":"get_plan_cost(x, topn = 3, dic_path = NULL) > get_plan_cost(doc, topn = 2) # A tibble: 16 × 9    우선순위 표층형 품사태그 의미부류 좌문맥ID 우문맥ID 낱말비용 연접비용 누적비용       <int> <chr>  <chr>    <chr>       <int>    <int>    <int>    <int>    <int>  1        1 윤희   NNP      \"인명\"       1788     3549     5483    -2347     3136  2        1 근     NNG      \"\"           1780     3534     4535      -17     7654  3        1 은     JX       \"\"            682     2377      349    -2614     5389  4        1 경찰   NNG      \"\"           1780     3534     2371      826     8586  5        1 청장   NNG      \"\"           1780     3534     2084      269    10939  6        1 이     VCP      \"\"           2239     3575     1201    -1615    10525  7        1 다     EF       \"\"              3        5     2700    -3228     9997  8        1 .      SF       \"\"           1794     3560     3518    -1948    11567  9        2 윤희   NNP      \"인명\"       1788     3549     5483    -2347     3136 10        2 근     NNG      \"\"           1780     3534     4535      -17     7654 11        2 은     JX       \"\"            682     2377      349    -2614     5389 12        2 경찰청 NNG      \"\"           1780     3534     1896      826     8111 13        2 장     NNG      \"\"           1780     3534     3899      269    12279 14        2 이     VCP      \"\"           2239     3575     1201    -2955    10525 15        2 다     EF       \"\"              3        5     2700    -3228     9997 16        2 .      SF       \"\"           1794     3560     3518    -1948    11567"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"사용자-사전-정보-생성","dir":"Articles","previous_headings":"","what":"사용자 사전 정보 생성","title":"Manage Dictionary","text":"사용자 정의 사전에 추가할 낱말들은 대부분 NNG(일반명사), NNP(고유명사)일 것입니다. 일반명사는 대부분 복합명사일 것이고 고유명사는 인명, 지명 등이 대부분일 것입니다. bitNLP는 mecab-ko-dic 사전에 명사를 추가하는 기능을 제공합니다. “윤희근은 경찰청장이다.”라는 문장을 “윤희근\\NNP+은\\JX+경찰청장\\NNG+이\\VCP+다\\EF+.\\SF”로 토큰화하기 위해서 우리는 다음의 사전을 추가해야 합니다. 윤희근 경찰청장","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"get_userdic_meta","dir":"Articles","previous_headings":"사용자 사전 정보 생성","what":"get_userdic_meta()","title":"Manage Dictionary","text":"get_userdic_meta()는 사용자 사전정의 디렉토리의 사전파일 읽어, 정의된 내용을 tibble 객체로 반환합니다. 이 기능을 통해서 사용자 명사 사전의 등록(정의) 여부를 파악할 수 있습니다. 다음과 같은 명사 사용자 정의 사전 파일을 참조합니다. 인명사전 : person.csv 지명사전 : place.csv 고유명사사전 : nnp.csv 일반명사사전 : nng.csv 다음과 같은 인수를 사용합니다. 기본값은 “person”로 인명사전을 지정합니다. 지정하지 않으면 사전이 설치된 기본 경로에서 파일을 읽어옵니다. 인명과 일반명사를 등록해야하기 때문에 두 사전 파일에 기술된 정보를 조회합니다. 사용자의 사전 정의 파일의 내용에 따라 다른 결과가 나올 수 있습니다. 인명 사전 정의 파일의 내용은 다음과 같이 조회됩니다. 일반명사 사전 정의 파일의 내용은 다음과 같이 조회됩니다. 조회된 tibble 객체에서 변수는 다음과 같습니다.: 표층형: 낱말명. 미지정1: 사용하지 않는 컬럼. 미지정2: 사용하지 않는 컬럼. 미지정3: 사용하지 않는 컬럼. 품사태그: 인명의 품사. NNP를 사용함. 의미부류: 인명, 혹은 지명과 같은 의미 부류. 종성유무: 낱말의 마지막 음절의 종성 여부. T, F 입력. 읽기: 읽어서 소리나는 말. 타입: inflected, compound, Preanalysis, *. 첫번째 품사: 기분석으로 나눠지는 토큰에 대한 각 품사 입력. 마지막 품사: 기분석으로 나눠지는 토큰에 대한 각 품사 입력. 표현: 낱말이 토큰들로 나눠질 경우의 원형을 +로 묶어 입력 인텍스표현: 사용하지 않는 컬럼, *로 표현","code":"get_userdic_meta(   noun_type = c(\"person\", \"place\", \"nnp\", \"nng\"),   userdic_path = NULL ) > get_userdic_meta(\"person\") # A tibble: 2 × 13                                                                                                                     표층형 미지정1 미지정2 미지정3 품사태그 의미부류 종성유무 읽기   타입  첫번째품사 마지막품사   <chr>  <lgl>   <lgl>   <lgl>   <chr>    <chr>    <lgl>    <chr>  <chr> <chr>      <chr>      1 까비   NA      NA      NA      NNP      인명     FALSE    까비   *     *          *          2 변학도 NA      NA      NA      NNP      인명     FALSE    변학도 *     *          *          # ℹ 2 more variables: 표현 <chr>, 인텍스표현 <chr> > get_userdic_meta(\"nng\") # A tibble: 4 × 13                                                                                                                                                                       표층형     미지정1 미지정2 미지정3 품사태그 의미부류 종성유무 읽기       타입     첫번째품사 마지막품사 표현                    인텍스표현   <chr>      <lgl>   <lgl>   <lgl>   <chr>    <chr>    <lgl>    <chr>      <chr>    <chr>      <chr>      <chr>                   <chr>      1 재직증명서 NA      NA      NA      NNG      *        FALSE    재직증명서 Compound *          *          재직/NNG/*+증명서/NNG/* *          2 육아휴직   NA      NA      NA      NNG      *        TRUE     육아휴직   Compound *          *          육아/NNG/*+휴직/NNG/*   *          3 신혼부부   NA      NA      NA      NNG      *        FALSE    신혼부부   Compound *          *          신혼/NNG/*+부부/NNG/*   *          4 타이디버스 NA      NA      NA      NNG      *        FALSE    타이디버스 *        *          *          *                       *"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"append_userdic_meta","dir":"Articles","previous_headings":"사용자 사전 정보 생성","what":"append_userdic_meta()","title":"Manage Dictionary","text":"사전 파일을 조회해서 등록하려하는 낱말이 없는 것을 확인했으면, 사전 파일에 등록할 낱말을 추가해야 합니다. append_userdic_meta()는 사전에 등록하기 위해 인명/지명/고유명사/일반명사를 mecab-ko-dic의 사용자 사전 디렉토리에 사용자 정의 사전 파일에 추가합니다. 다음과 같은 인수를 사용합니다. mecab-ko-dic 품사 태그 설명에서 ‘표층형’, ’읽기’에 적용됨 mecab-ko-dic 품사 태그 설명에서 ’타입’에 적용됨 mecab-ko-dic 품사 태그 설명에서 ’표현’에 적용됨 인명과 지명도 고유명사이지만 별도로 구분하여 등록함 지정하지 않으면 사전이 설치된 기본 경로에서 파일을 읽어온다 인명사전에 “윤희근”이라는 고유명사를 추가합니다. 마찬가지로 “경찰청장”이라는 복합명사도 추가합니다.","code":"append_userdic_meta(   x,   type = NULL,   prototype = NULL,   noun_type = c(\"person\", \"place\", \"nnp\", \"nng\"),   userdic_path = NULL ) > append_userdic_meta(c(\"윤희근\"), noun_type = \"person\") ── 사전 파일에 인명 추가하기 ─────────────────────────────────────────────────────                                               ✔ 신규 추가 건수: 1 ✔ 최종 인명 건수: 3 > get_userdic_meta(\"person\") # A tibble: 3 × 13                                                                                                      표층형 미지정1 미지정2 미지정3 품사태그 의미부류 종성유무 읽기  타입  첫번째품사   <chr>  <lgl>   <lgl>   <lgl>   <chr>    <chr>    <lgl>    <chr> <chr> <chr>      1 까비   NA      NA      NA      NNP      인명     FALSE    까비  *     *          2 변학도 NA      NA      NA      NNP      인명     FALSE    변학… *     *          3 윤희근 NA      NA      NA      NNP      인명     TRUE     윤희… *     *          # ℹ 3 more variables: 마지막품사 <chr>, 표현 <chr>, 인텍스표현 <chr> > append_userdic_meta(c(\"경찰청장\"), c(\"Compound\"), c(\"경찰/NNG/*+청장/NNG/*\"),  +                     noun_type = \"nng\") ── 사전 파일에 일반명사 추가하기 ───────────────────────────────────────────────                                              ✔ 신규 추가 건수: 1 ✔ 최종 일반명사 건수: 5"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"사용자-사전-생성","dir":"Articles","previous_headings":"","what":"사용자 사전 생성","title":"Manage Dictionary","text":"생성한 사용자 사전 정보로 사전을 생성하는 방법에는 다음과 같은 두가지가 있습니다. 관리자 권한으로 mecab-ko-dic 시스템 사전에 추가 명확하고 변하지 않는 여러 낱말을 일괄적으로 적용할 때 유리 add_sysdic() 함수 이용 별도의 mecab-ko-dic 사전 생성 특정 도메인인 국한된 낱말이거나 일시적인 작업에만 사용할 때 유리 시스템 사전 변경의 권한이 없을 경우 사용자 사전 생성 create_userdic() 함수 이용 사전 업데이트가 빈번하지 않거나 분석 속도를 낮추고 싶지 않은 경우 직접 시스템 사전을 변경하는 것이 좋습니다. 사전 업데이트가 자주 발생하거나 시스템 사전을 변경할 권한이 없으면 사용자 사전을 만드는 것이 좋습니다.","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"add_sysdic","dir":"Articles","previous_headings":"사용자 사전 생성 > 시스템 사전 추가","what":"add_sysdic()","title":"Manage Dictionary","text":"add_sysdic() 함수는 사용자가 정의한 사용자 정의 사전 파일을 mecab-ko-dic 사전에 추가합니다. 이 작업이 수행되야 비로소 형태소분석에 사용자가 추가한 사전이 반영됩니다. 이 함수는 인수가 없습니다. 인명과 복합명사를 사전에 적용합니다. 사전 파일을 사전에 적용하기 위해서는 시스템 관리자 권한이 필요합니다. MacOS나 Linux의 RStudio에서는 다음과 같은 sudo 패스워드를 묻는 다이얼로그가 나타나며, 패스워드를 입력해야 작업이 수행됩니다.  패스워드 입력을 정상적으로 마치면 사전을 추가합니다.","code":"add_sysdic() > add_sysdic() Password:generating userdic... nng.csv /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode... reading /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/nng.csv ...  done! nnp.csv /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode... reading /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/nnp.csv ...  done! person.csv /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode... reading /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/person.csv ...  done! place.csv /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode... reading /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/place.csv ...  done! test -z \"model.bin matrix.bin char.bin sys.dic unk.dic\" || rm -f model.bin matrix.bin char.bin sys.dic unk.dic /usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8 reading ./unk.def ... 13 emitting double-array: 100% |###########################################|  reading ./Foreign.csv ... 11690 reading ./NNB.csv ... 140 reading ./Symbol.csv ... 16 reading ./MM.csv ... 453 reading ./user-person.csv ... 3 reading ./Preanalysis.csv ... 5 reading ./NorthKorea.csv ... 3 reading ./XPN.csv ... 83 reading ./NR.csv ... 482 reading ./NP.csv ... 342 reading ./VA.csv ... 2360 reading ./VV.csv ... 7331 reading ./XSV.csv ... 23 reading ./XSA.csv ... 19 reading ./user-nng.csv ... 5 reading ./NNG.csv ... 208524 reading ./NNP.csv ... 2371 reading ./user-nnp.csv ... 4 reading ./EF.csv ... 1820 reading ./EP.csv ... 51 reading ./user-place.csv ... 3 reading ./VCP.csv ... 9 reading ./IC.csv ... 1305 reading ./MAJ.csv ... 240 reading ./Place-address.csv ... 19301 reading ./EC.csv ... 2547 reading ./NNBC.csv ... 677 reading ./ETM.csv ... 133 reading ./Person-actor.csv ... 99230 reading ./MAG.csv ... 14242 reading ./VCN.csv ... 7 reading ./Wikipedia.csv ... 36762 reading ./ETN.csv ... 14 reading ./Person.csv ... 196459 reading ./Hanja.csv ... 125750 reading ./Place-station.csv ... 1145 reading ./Place.csv ... 30303 reading ./Inflect.csv ... 44820 reading ./J.csv ... 416 reading ./XR.csv ... 3637 reading ./XSN.csv ... 124 reading ./VX.csv ... 125 reading ./CoinedWord.csv ... 148 reading ./Group.csv ... 3176 emitting double-array: 100% |###########################################|  reading ./matrix.def ... 3822x2693 emitting matrix      : 100% |###########################################|   done! echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\" To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\" make[1]: Nothing to be done for `install-exec-am'.  ./install-sh -c -d '/usr/local/lib/mecab/dic/mecab-ko-dic'  /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic' >"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"사전-등록-결과-확인","dir":"Articles","previous_headings":"사용자 사전 생성 > 시스템 사전 추가","what":"사전 등록 결과 확인","title":"Manage Dictionary","text":"사용자가 정의한 사전이 정상적으로 등록되었으니 결과를 확인합니다. 먼저 낱말비용 기반의 토크나이저 플랜을 조회합니다. 원하는 플랜이 우선순위 1로 나타났습니다. 당연히 형태소 토큰화 결과도 플랜이 우선순위 1번의 것과 동일합니다.","code":"> get_plan_cost(doc, topn = 2) # A tibble: 13 × 9    우선순위 표층형   품사태그 의미부류 좌문맥ID 우문맥ID 낱말비용 연접비용 누적비용       <int> <chr>    <chr>    <chr>       <int>    <int>    <int>    <int>    <int>  1        1 윤희근   NNP      \"인명\"       1788     3550     5472    -2347     3125  2        1 은       JX       \"\"            682     2377      349    -2579      895  3        1 경찰청장 NNG      \"\"           1780     3534     2639      826     4360  4        1 이       VCP      \"\"           2239     3575     1201    -1615     3946  5        1 다       EF       \"\"              3        5     2700    -3228     3418  6        1 .        SF       \"\"           1794     3560     3518    -1948     4988  7        2 윤희근   NNP      \"인명\"       1788     3550     5472    -2347     3125  8        2 은       JX       \"\"            682     2377      349    -2579      895  9        2 경찰     NNG      \"\"           1780     3534     2371      826     4092 10        2 청장     NNG      \"\"           1780     3534     2084      269     6445 11        2 이       VCP      \"\"           2239     3575     1201    -3700     3946 12        2 다       EF       \"\"              3        5     2700    -3228     3418 13        2 .        SF       \"\"           1794     3560     3518    -1948     4988 > morpho_mecab(doc, type = \"morphe\")        NNP         JX        NNG        VCP         EF         SF    \"윤희근\"       \"은\" \"경찰청장\"       \"이\"       \"다\"        \".\""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"사용자-사전-생성-1","dir":"Articles","previous_headings":"사용자 사전 생성","what":"사용자 사전 생성","title":"Manage Dictionary","text":"앞의 두 낱말이 시스템 사전에 추가되었으므로, 이제는 다른 낱말로 사용자 사전을 생성해 봅니다. 대장내시경과 대장용종이라는 두 일반명사를 사전 정보 파일에 추가합니다. dic_type 인수값에 “userdic”를 지정하면 사용자 사전에 등록할 정보 파일이 ./user-dic이라는 경로에 생성됩니다. 물론 생성 경로를 사용자가 지정할 수도 있습니다. get_userdic_meta() 함수의 userdic_path 인수에 사전 정의 파일이 생성된 경로를 지정하여 그 내용을 조회할 수 있습니다.","code":"> doc <- \"대장내시경 검사에서 대장용종을 제거했다.\" > morpho_mecab(doc, type = \"morpheme\")      NNG      NNG      NNG      JKB      NNG      NNG      JKO      NNG   XSV+EP       EF       SF    \"대장\" \"내시경\"   \"검사\"   \"에서\"   \"대장\"   \"용종\"     \"을\"   \"제거\"     \"했\"     \"다\"      \".\" > append_userdic_meta( +     c(\"대장내시경\", \"대장용종\"), +     type = c(\"Compound\", \"Compound\"), +     prototype = c(\"대장/NNG/*+내시경/NNG/*\", \"대장/NNG/*+용종/NNG/*\"), +     noun_type = \"nng\",  +     dic_type = \"userdic\" + ) ── 사전 파일에 일반명사 추가하기 ───────────────────────────────────────────────            ✔ 신규 추가 건수: 2 ✔ 최종 일반명사 건수: 6 > get_userdic_meta(noun_type = \"nng\", userdic_path = \"./user_dic\") # A tibble: 6 × 13                                                                                                                                                                                       표층형     미지정1 미지정2 미지정3 품사태그 의미부류 종성유무 읽기       타입     첫번째품사 마지막품사 표현                    인텍스표현   <chr>      <lgl>   <lgl>   <lgl>   <chr>    <chr>    <lgl>    <chr>      <chr>    <chr>      <chr>      <chr>                   <chr>      1 재직증명서 NA      NA      NA      NNG      *        FALSE    재직증명서 Compound *          *          재직/NNG/*+증명서/NNG/* *          2 육아휴직   NA      NA      NA      NNG      *        TRUE     육아휴직   Compound *          *          육아/NNG/*+휴직/NNG/*   *          3 신혼부부   NA      NA      NA      NNG      *        FALSE    신혼부부   Compound *          *          신혼/NNG/*+부부/NNG/*   *          4 타이디버스 NA      NA      NA      NNG      *        FALSE    타이디버스 *        *          *          *                       *          5 대장내시경 NA      NA      NA      NNG      *        TRUE     대장내시경 Compound *          *          대장/NNG/*+내시경/NNG/* *          6 대장용종   NA      NA      NA      NNG      *        TRUE     대장용종   Compound *          *          대장/NNG/*+용종/NNG/*   *"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"create_userdic","dir":"Articles","previous_headings":"사용자 사전 생성 > 사용자 사전 생성","what":"create_userdic()","title":"Manage Dictionary","text":"create_userdic() 함수는 지정한 디렉토리에 있는 모든 사용자 정의 사전 파일을 엮어 사용자 사전을 생성합니다. 다음과 같은 인수를 사용합니다. 지정하지 않으면 ./user_dic라는 이름의 경로를 사용함. 지정하지 않으면 user-dic.dic라는 이름으로 생성함. 이 작업이 끝나면 ./user_dic에 user-dic.dic라는 이름은 사용자 사전이 생성됩니다. ./user_dic/indexed 경로에 있는 파일들은 삭제하지 말고 보관하는 것이 좋습니다. 형태소 분석의 결과에 따라서 낱말비용을 수정해야하는 것이 필요할 수 있기 때문입니다.","code":"create_userdic(   userdic_path = \"./user_dic\",   dic_file = \"user-dic.dic\" ) > create_userdic() generating userdic... nng.csv /usr/local/install_resources/mecab-ko-dic-2.1.1-20180720/model.def is not a binary model. reopen it as text mode... reading ./user_dic/nng.csv ...  done! reading ./user_dic/indexed/merged.csv ... 6 emitting double-array: 100% |###########################################|   done! > system(\"tree ./user_dic\") ./user_dic ├── indexed │   ├── merged.csv │   └── nosys-nng.csv ├── nng.csv └── user-dic.dic  2 directories, 4 files"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"형태소-분석-1","dir":"Articles","previous_headings":"사용자 사전 생성 > 사용자 사전 생성","what":"형태소 분석","title":"Manage Dictionary","text":"morpho_mecab() 함수로 형태소 단위로 토큰화해도 결과는 바뀌지 않습니다. 그 이유는 morpho_mecab() 함수는 기본적으로 시스템 사전만 사용하기 때문입니다. 그러나, user_dic 인수로 사용자 사전을 지정한 morpho_mecab() 함수 호출로 원하는 결과를 얻을 수 있습니다.","code":"> morpho_mecab(doc, type = \"morpheme\")      NNG      NNG      NNG      JKB      NNG      NNG      JKO      NNG   XSV+EP       EF       SF    \"대장\" \"내시경\"   \"검사\"   \"에서\"   \"대장\"   \"용종\"     \"을\"   \"제거\"     \"했\"     \"다\"      \".\" > morpho_mecab(doc, type = \"morpheme\", user_dic = \"./user_dic/user-dic.dic\")          NNG          NNG          JKB          NNG          JKO          NNG       XSV+EP           EF           SF  \"대장내시경\"       \"검사\"       \"에서\"   \"대장용종\"         \"을\"       \"제거\"         \"했\"         \"다\"          \".\""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"낱말비용-수정","dir":"Articles","previous_headings":"","what":"낱말비용 수정","title":"Manage Dictionary","text":"사용자 사전에 낱말을 등록하여 원하는 형태소 토큰화를 유도하더라도, 모든 사례에서 원하는 토큰화가 이루어진다는 보장은 없습니다. 그 이유는 사용자가 등록한 낱말의 비용이 커서 형태소분석기가 우선순위로 고려하지 않을 수 있기 때문입니다. 이때는 분석가가 직접 낱말비용을 수정해서 원하는 토큰화를 유도해야 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"원하지-않는-토큰화-사례","dir":"Articles","previous_headings":"낱말비용 수정","what":"원하지 않는 토큰화 사례","title":"Manage Dictionary","text":"이미 앞에서 사용자 사전에 “신혼부부”를 포함하였습니다. 그러나 다음 문서의 형태소 토큰화는 원하는 결과를 얻지 못합니다. 시스템 사전과 사용자 사전을 사용하는 토큰화에서도 결과는 동일합니다. “신혼부부”의 토크나이저 플랜을 조회하면, “신혼(NNG)+부부(NNG)”의 우선순위가 “신혼부부(NNG)”보다 높습니다. 신혼: 1034, 부부: 410 신혼부부: 2835 신혼+부부: 546 신혼부부: 1677 비용이 낮은 것이 우선순위가 높기 때문에 원하는 “신혼부부”로 토큰화가 되지 않는 것입니다. 즉 사전에 낱말이 추가되더라도 이전에 포함된 낱말과 비용의 경합을 벌여, 비용이 크면 그 낱말로 토큰화되지 않습니다.","code":"> doc <- \"신혼부부가 여행을 온다.\" > morpho_mecab(doc, type = \"morpheme\")    NNG    NNG    JKS    NNG    JKO  VV+EF     SF  \"신혼\" \"부부\"   \"가\" \"여행\"   \"을\" \"온다\"    \".\"  > morpho_mecab(doc, type = \"morpheme\", user_dic = \"./user_dic/user-dic.dic\")    NNG    NNG    JKS    NNG    JKO  VV+EF     SF  \"신혼\" \"부부\"   \"가\" \"여행\"   \"을\" \"온다\"    \".\" > get_plan_cost(\"신혼부부\", topn = 2) # A tibble: 3 × 9   우선순위 표층형   품사태그 의미부류 좌문맥ID 우문맥ID 낱말비용 연접비용 누적비용      <int> <chr>    <chr>    <lgl>       <int>    <int>    <int>    <int>    <int> 1        1 신혼     NNG      NA           1781     3535     1034    -1158     -124 2        1 부부     NNG      NA           1781     3534      410      260      546 3        2 신혼부부 NNG      NA           1781     3534     2835    -1158     1677"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"원하는-토큰화-유도","dir":"Articles","previous_headings":"낱말비용 수정","what":"원하는 토큰화 유도","title":"Manage Dictionary","text":"원하는 토큰화를 위해서는 낱말의 낱말비용의 값을 좀 더 낮게 수정한 후, 사전에 재등록해야 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"낱말비용-수정-1","dir":"Articles","previous_headings":"낱말비용 수정 > 원하는 토큰화 유도","what":"낱말비용 수정","title":"Manage Dictionary","text":"낱말비용을 수정하기 위해서 edit_termcost() 함수를 사용합니다. 다음과 같은 인수를 사용합니다. 지정하지 않으면 “./user_dic”이라는 이름의 경로를 사용합니다. 지정하지 않으면 “user-dic.dic”이라는 이름으로 생성합니다. edit_termcost()을 수행하면 다음과 같은 Shiny 앱이 출력됩니다. 수정할 낱말의 낱말비용을 수정하고, 수정한 값을 반영하려면, 반드시 synchronise 버튼을 눌러야 합니다. Done 버튼을 눌러 작업을 마칩니다. 여기서는 “신혼부부”의 낱말비용을 2639에서 1000으로 낮췄습니다.","code":"edit_termcost(userdic_path = \"./user_dic\", dic_file = \"user-dic.dic\") > edit_termcost()                                                                                                                           Listening on http://127.0.0.1:6152 ── 사전 파일의 낱말비용 수정하기 ───────────────────────────────────────────────            ✔ 낱말비용 수정 건수: 1"},{"path":"https://r2bit.com/bitNLP/dev/articles/manage_dic.html","id":"사용자-사전-업데이트","dir":"Articles","previous_headings":"낱말비용 수정 > 원하는 토큰화 유도","what":"사용자 사전 업데이트","title":"Manage Dictionary","text":"낱말비용을 수정했다고, 사전에 반영되지 않습니다. 사전을 다시 업데이트(생성)해야 합니다. bitNLP는 낱말비용을 수정 기반의 사용자 사전 업데이트 기능을 사용자 사전만 지원합니다. 왜냐하면 시스템 사전의 낱말비용을 수정하는 것이 예기치 못한 부작용(side-effect)을 가져올 수 있기 때문입니다. 사용자 사전 업데이트하기 위해서 update_userdic() 함수를 사용합니다. 다음과 같은 인수를 사용합니다. 지정하지 않으면 “./user_dic”이라는 이름의 경로를 사용합니다. 지정하지 않으면 “user-dic.dic”이라는 이름으로 생성합니다. 기본 설정으로 사용자 사전을 업데이트합니다. 업데이트한 사용자 사전을 이용한 형태소 토큰화는 원하는 결과를 보여줍니다. 토크나이저 플랜을 조회하면, 사용자 사전을 적용한 두번째 결과에서 원하는 토큰화 플랜을 보여줍니다. 그러므로 원하는 토큰화를 위해서는 비용을 수정한 파일로 생성한 사용자 사전을 사용해야 합니다.","code":"update_userdic(userdic_path = \"./user_dic\", dic_file = \"user-dic.dic\") > update_userdic() updating userdic... reading ./user_dic/indexed/merged.csv ... 6 emitting double-array: 100% |###########################################|   done! > morpho_mecab(doc, type = \"morpheme\")    NNG    NNG    JKS    NNG    JKO  VV+EF     SF  \"신혼\" \"부부\"   \"가\" \"여행\"   \"을\" \"온다\"    \".\"  > morpho_mecab(doc, type = \"morpheme\", user_dic = \"./user_dic/user-dic.dic\")        NNG        JKS        NNG        JKO      VV+EF         SF  \"신혼부부\"       \"가\"     \"여행\"       \"을\"     \"온다\"        \".\" > get_plan_cost(\"신혼부부\", topn = 2) # A tibble: 3 × 9   우선순위 표층형   품사태그 의미부류 좌문맥ID 우문맥ID 낱말비용 연접비용 누적비용      <int> <chr>    <chr>    <lgl>       <int>    <int>    <int>    <int>    <int> 1        1 신혼     NNG      NA           1781     3535     1034    -1158     -124 2        1 부부     NNG      NA           1781     3534      410      260      546 3        2 신혼부부 NNG      NA           1781     3534     2835    -1158     1677 > get_plan_cost(\"신혼부부\", topn = 2, userdic = \"./user_dic/user-dic.dic\") # A tibble: 3 × 9   우선순위 표층형   품사태그 의미부류 좌문맥ID 우문맥ID 낱말비용 연접비용 누적비용      <int> <chr>    <chr>    <lgl>       <int>    <int>    <int>    <int>    <int> 1        1 신혼부부 NNG      NA           1781     3534     1000    -1158     -158 2        2 신혼     NNG      NA           1781     3535     1034    -1158     -124 3        2 부부     NNG      NA           1781     3534      410      260      546"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"manipulate-documents","dir":"Articles","previous_headings":"","what":"Manipulate Documents","title":"Manipulate Documents","text":"Manipulate Documents라 쓰고 텍스트 텍스트 데이터 정제라 이야기 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"텍스트-데이터-정제","dir":"Articles","previous_headings":"Manipulate Documents","what":"텍스트 데이터 정제","title":"Manipulate Documents","text":"신문 기사나 소설, 수필과 같은 잘 정리된 텍스트 문서와 뉴스 진행자들이 전하는 뉴스 멘트들은 맞춤법에 부합하는 품질 높은 텍스트 데이터들입니다. 실제로 텍스트 분석에 직면하면 환상은 저 먼 나라의 이야기가 되어 버립니다. 맞춤법, 띄어쓰기가 무시된 텍스트는 그나마 애교가 있는 수준입니다. 통화 내용을 STT(Speech Text)기법으로 텍스트로 변환한 데이터는 변환기의 성능이 완벽하지 않아서 품질이 매우 낮습니다. 화자와 청자의 의도는 유추하여 이해할 수 있겠으나, 텍스트 분석이라는 기계를 시켜서 수행하는 데이터 분석에는 부족함이 많습니다. 카페나 블로그의 게시글, SNS 채널의 글은 맞춤법, 띄어쓰기에 취약하고, 신조어나 암호같은 줄임말, 완전하지 않은 문장들이 포함됩니다. 경우에 따라서는 수집 과정에서 기술적인 한계로, 불필요한 텍스트들이 포함되기도 합니다. 그래서 데이터 정제없이 분석할 수 없는 경우가 많습니다. 어떤 경우는 수집한 텍스트 데이터가 데이터 분석을 수행하려는 목적과 부합하지 않아서 제거해야할 경우도 있습니다. 이처럼 텍스트 데이터 분석은 일반적인 데이터 분석에 비해서 데이터 정제가 차지하는 비중은 매우 큽니다. 텍스트 데이터 정제 성능은 텍스트 데이터 분석 성능과 직결되기 때문입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"형태소분석과-데이터의-품질","dir":"Articles","previous_headings":"Manipulate Documents","what":"형태소분석과 데이터의 품질","title":"Manipulate Documents","text":"텍스트 데이터 분석은 보통 형태소분석을 통해서 품사를 태깅하고, 품사 기반으로 토큰화된 단어로 텍스트 분석을 수행합니다. 문제는 분석에 사용하는 형태소분석기가, 문법과 띄어쓰기에 부합되는 품질 좋은 양질의 텍스트 데이터를 학습해서 만들어진 모델을 이용한다는 점입니다. 그래서 형태소분석을 수행하는 데이터의 품질이 떨어진다면, 형태소분석의 결과도 만족스럽지 못합니다. 어찌 보면 이러한 점이 데이터 정제를 하는 가장 큰 이유 중에 하나입니다. 문서의 품질이 높은 경우에도 문제가 발생할 수 있습니다. 형태소분석기에 사용한 학습 데이터는 우리가 일상 생활에서 이야기하는 대화의 주제, 혹은 직업, 학문과 예술, 종교 등 여러 분야의 내용을 모두 담지 못합니다. 학습 데이터는 지극히 일부의 샘플링된 문장들이라는 점입니다. 그래서 통상적인 생활에서 발화되는 단어가 아닌 전문성이 필요한 영역의 단어를 이해하지 못합니다. 알파고가 쏘아 올린 화두가 학계와 필드의 AI 혁신을 이끌었습니다. 아마도 5년전에는 대중들은 알파고라는 단어에 익숙하지 못했을 겁니다. 이처럼 형태소분석기가 취약한 신조어나, 특정 영역에서 사용하는 전문용어들은 사용자 정의 사전에 등록해서 형태소분석기가 이를 이해할 수 있도록 도와줘야 합니다. 이러한 작업들도 광의적으로 데이터를 정제를 수행하는 덱트스 데이터의 조작(Manipulate Documents)입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"텍스트-데이터-정제를-위한-bitnlp의-기능","dir":"Articles","previous_headings":"Manipulate Documents","what":"텍스트 데이터 정제를 위한 bitNLP의 기능","title":"Manipulate Documents","text":"bitNLP의 텍스트 데이터 조작 기능을 정리하면 다음과 같습니다. 문서 필터링 (Filter Documents) 텍스트 대체 (Replace Texts) 텍스트 연결 (Concatenate Texts) 텍스트 분리 (Split Texts) 텍스트 제거 (Remove Texts) bitNLP는 대용량의 텍스트 데이터에서 상기 데이터 조작을 수행할 수 있도록 도와줍니다. 그래서 다음과 같은 방법으로 작업합니다. 병렬 처리를 통한 속도의 개선 데이터 조작 룰을 등록한 메타(meta) 파일 활용","code":""},{"path":[]},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"메타-데이터의-설정과-확인","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"메타 데이터의 설정과 확인","title":"Manipulate Documents","text":"set_meta() 함수는 세션 안에서 bitNLP 패키지의 메타 데이터를 등록합니다. 다음의 set_meta() 함수의 원형을 보면 데이터 파일을 읽는 방법과 유사합니다. bitNLP 패키지는 샘플 메타 데이터 파일을 제공하는데, 문서 필터링을 위한 샘플 메타 데이터 파일을 읽어 봅니다. get_meta() 함수는 세션 안에서 등록된 메타 데이터를 조회합니다.","code":"set_meta(   id = c(\"filter\", \"replace\", \"remove\", \"concat\", \"split\"),   filename,   sep = \",\",   fileEncoding = \"utf-8\",   append = FALSE ) library(bitNLP)  meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_filter.csv\")  ## 데이터 필터링 메타 신규 등록 set_meta(\"filter\", fname, fileEncoding = \"utf8\") ## 기 등록된 데이터 필터링 메타 조회 get_meta(\"filter\")    rule_nm 1 신문기사 2 제품홍보 3 설문조사 4     출처 5   이벤트 6     방송                                                                                     pattern 1                                   (팍스넷|파이낸셜|연합|(PT)|오마이|경제)[[:space:]]*뉴스 2 ((입법|정치|교육)[[:space:]]*플랫폼)|맘마미아[[:space:]]*가계부[[:print:]]*인증샷|Playtex 3                                                              좌담회|구글설문|채용대행업체 4                                                    출처[[:space:]]*:|문의처보건복지콜센터 5                                     (증정|기념)이벤트|허니스크린|이벤트를[[:space:]]*진행 6                                 제작진|기억저장소|추모카페|블랙홀|푸드스튜디오|연금정보넷   accept  use 1  FALSE TRUE 2  FALSE TRUE 3  FALSE TRUE 4  FALSE TRUE 5  FALSE TRUE 6  FALSE TRUE"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"filter_text를-이용한-문서-필터링","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"filter_text()를 이용한 문서 필터링","title":"Manipulate Documents","text":"텍스트 데이터(문서들) 중에서 분석을 수행하려는 목적과 부합하지 않은 텍스트(문서)를 제거해야할 경우에는 filter_text()를 사용합니다. 이미 앞에서 문서 필터링을 위한 메타 데이터 파일을 읽어들였습니다. 6개의 룰은 accept 값이 FALSE인 deny 룰입니다. 즉 해당 검색 패턴을 만족하는 텍스트 데이터를 제거하는 작업을 수행합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"문자-벡터의-필터링","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리 > filter_text()를 이용한 문서 필터링","what":"문자 벡터의 필터링","title":"Manipulate Documents","text":"버즈 데이터의 본문은 길이가 1000인 문자 벡터입니다. 이 벡터는 5개의 결측치를 포함하고 있습니다. 8개의 코어를 이용해서 필터링을 수행합니다. as_logical = FALSE을 지정하면 문자 벡터의 필터링을 수행할 수 있습니다. 5개의 결측치와 6개의 룰에서 10개의 문서가 제거되어서 길이가 985인 문자 벡터가 만들어졌습니다.","code":"doc_content <- buzz$CONTENT is.character(doc_content) [1] TRUE length(doc_content) [1] 1000  sum(is.na(doc_content)) [1] 5 doc_after_character <- filter_text(doc_content, as_logical = FALSE, mc.cores = 8) ── rejects: 방송 ──────────────────────────────────────────────────────── 3건 ── ── rejects: 설문조사 ──────────────────────────────────────────────────── 1건 ── ── rejects: 신문기사 ──────────────────────────────────────────────────── 1건 ── ── rejects: 이벤트 ────────────────────────────────────────────────────── 1건 ── ── rejects: 제품홍보 ──────────────────────────────────────────────────── 2건 ── ── rejects: 출처 ──────────────────────────────────────────────────────── 2건 ── ── Missing Check: Removing NA ─────────────────────────────────────────── 5건 ──  length(doc_after_character) [1] 985"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"데이터-프레임의-필터링","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리 > filter_text()를 이용한 문서 필터링","what":"데이터 프레임의 필터링","title":"Manipulate Documents","text":"tidytext 패키지를 이용해서 텍스트 데이터 분석을 수행한다면, 문자 벡터의 필터링이 아니라 문자 변수를 이용한 필터링을 수행해야 합니다. 다음처럼 as_logical 인수의 기본값인 TRUE를 사용합니다. 이 경우는 CONTENT 변수의 모든 원소에 대해서 allow 필터링 여부를 의미하는 논리 벡터를 만들어 반환합니다. 그러므로 dplyr 패키지의 filter 함수와 사용하여 필터링합니다.","code":"library(dplyr)  buzz %>%    filter(filter_text(CONTENT, verbos = FALSE)) %>%    select(KEYWORD, SRC, CONTENT)  [38;5;246m# A tibble: 985 × 3 [39m   KEYWORD SRC              CONTENT                                                  [3m [38;5;246m<chr> [39m [23m    [3m [38;5;246m<chr> [39m [23m             [3m [38;5;246m<chr> [39m [23m                                                  [38;5;250m1 [39m 맞벌이  17,18년 베이비맘  [38;5;246m\" [39m지금 둘째 임신중인 어머니예요 첫째는 16년 1월생 둘째출산예정은 17년 3월생 어쩌다 보니…  [38;5;250m2 [39m 맞벌이  20대 수다방       [38;5;246m\" [39m저희 부부는 맞벌이인데요 남편 회사 사람들도 거의 다 맞벌이인가봐요 그래도 아침마다 아내분들…  [38;5;250m3 [39m 맞벌이  20대 수다방       [38;5;246m\" [39m신랑지출 제지출 구분해서 따로적으시나요 제가쓴돈은 알아도 신랑이쓴돈은 잘몰라 어떻게 적어야할…  [38;5;250m4 [39m 맞벌이  20대 수다방       [38;5;246m\" [39m너무 고민이 되서 하소연 할때 없어서 여기서 하소연 해봐요 글이좀 길수가 있어요 양해 부탁 …  [38;5;246m# ℹ 981 more rows [39m"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"replace_text를-이용한-텍스트-대체","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"replace_text()를 이용한 텍스트 대체","title":"Manipulate Documents","text":"문서 안에 포함된 특정 텍스트를 다른 텍스트로 대체하기 위해서는 replace_text()를 사용합니다. as_logical 인수만 없을 뿐 사용 방법은 filter_text()와 유사합니다. 남편이라는 단어와 신랑이라는 단어를 포함한 문장의 수는 각각 175개와 177개입니다. 그러나 이 두 단어는 동의어입니다. 그래서 텍스트 대체 룰에는 이 두 단어를 남편이라는 하나의 단어로 표준화했습니다. 문서들에서 몇 개의 룰이 적용되는지 결과를 보면서 텍스트를 대체합니다. 신랑이라는 단어가 남편으로 대체되었음을 알 수 있습니다.","code":"meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_replace.csv\") set_meta(\"replace\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 대체 룰 확인하기 get_meta(\"replace\")        rule_nm    rule_class 1  다중 구두점   구두점 대체 2         남편 유사단어 대체 3   베이비시터 유사단어 대체 4     텔레비전 유사단어 대체 5         CCTV 유사단어 대체 6       할머니 유사단어 대체 7       어머니 유사단어 대체 8       아버지 유사단어 대체 9         아들 유사단어 대체 10          딸 유사단어 대체 11      화이팅 유사단어 대체 12      모유량 유사단어 대체 13        베개 유사단어 대체 14        초산 유사단어 대체 15        급여 유사단어 대체                                                   pattern    replace  use 1                                               (\\\\.){2,}        \\\\. TRUE 2                                               신랑|남편       남편 TRUE 3  베비시터|((육아|아이|아기)[[:space:]]*(도우미|돌보미)) 베이비시터 TRUE 4                          TV|테레비|티브이|텔레비젼|티비   텔레비전 TRUE 5           (CC|cc|씨씨)[[:space:]]?(텔레비전|티비|tv|TV)       CCTV TRUE 6                                     할(미|머님|무니|매)     할머니 TRUE 7                                 엄마|어머님|엄니|어무니     어머니 TRUE 8                                      아버님|아빠|아부지     아버지 TRUE 9                              아들(래미|아이|애|내미|램)       아들 TRUE 10                               딸(래미|아이|애|내미|램)         딸 TRUE 11                                     파이팅|홧팅|퐈이팅     화이팅 TRUE 12                                모유[[:space:]]?[양|량]     모유량 TRUE 13                                           [베배][게개]       베개 TRUE 14                              (첫|처음)[[:space:]]*출산       초산 TRUE 15                                              월급|봉급       급여 TRUE doc_content <- buzz$CONTENT  stringr::str_detect(doc_content, \"남편\") %>%    sum(na.rm = TRUE) [1] 175  stringr::str_detect(doc_content, \"신랑\") %>%    sum(na.rm = TRUE) [1] 177 buzz_after <- buzz %>%    mutate(CONTENT = replace_text(CONTENT, verbos = TRUE)) ── Replace: [구두점 대체] - 다중 구두점 ───────────────────────────────── 2건 ── ── Replace: [유사단어 대체] - CCTV ────────────────────────────────────── 3건 ── ── Replace: [유사단어 대체] - 급여 ────────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 남편 ──────────────────────────────────── 323건 ── ── Replace: [유사단어 대체] - 딸 ──────────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 모유량 ──────────────────────────────────── 1건 ── ── Replace: [유사단어 대체] - 베개 ────────────────────────────────────── 5건 ── ── Replace: [유사단어 대체] - 베이비시터 ──────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 아들 ────────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 아버지 ──────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 어머니 ──────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 초산 ────────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 텔레비전 ────────────────────────────────── 3건 ── ── Replace: [유사단어 대체] - 할머니 ──────────────────────────────────── 0건 ── ── Replace: [유사단어 대체] - 화이팅 ──────────────────────────────────── 0건 ──  stringr::str_detect(buzz_after$CONTENT, \"남편\") %>%    sum(na.rm = TRUE) [1] 323  stringr::str_detect(buzz_after$CONTENT, \"신랑\") %>%    sum(na.rm = TRUE) [1] 0"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"concat_text를-이용한-텍스트-연결","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"concat_text()를 이용한 텍스트 연결","title":"Manipulate Documents","text":"띄어쓰기된 단어들을 하나의 단어로 묶어주기 위해서 concat_text()를 사용합니다. 일반적으로 복합명사를 정의하는 사례들입니다. 가사도우미라는 단어는 가사와 도우미가 결합된 복합명사입니다. 그런데 두 단어가 띄어쓰기된 경우가 있습니다. 문서들에서 몇 개의 룰이 적용되는지 결과를 보면서 텍스트를 연결합니다. 두 단어가 띄어쓰기된 가사 도우미가 수정되었습니다. 이렇게 수정된 문서들이 형태소분석을 통해서 토큰화되어 분석을 수행한다면, 형태소분석기에도 복합명사가 등록되어 있어야 합니다. 안그러면 단어를 연경하여 복합명사를 만든어 놓아도 토큰화 과정에서 다시 분리됩니다. 다음처럼 mecab-ko의 사전에는 가사도우미라는 명사가 등록되어 있지 않습니다. 이 경우에는 사용자 정의 사전으로 토큰화 과정에서 다시 분리되지 않도록 유도해야 합니다.","code":"meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_concat.csv\") set_meta(\"concat\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 결합 룰 확인하기 get_meta(\"concat\")                 rule_nm                pattern    replace  use 1 (하원도우미) 붙여쓰기 하원[[:space:]]+도우미 하원도우미 TRUE 2 (가사도우미) 붙여쓰기 가사[[:space:]]+도우미 가사도우미 TRUE 3 (산후도우미) 붙여쓰기 산후[[:space:]]+도우미 산후도우미 TRUE 4 (친정어머니) 붙여쓰기 친정[[:space:]]+어머니 친정어머니 TRUE 5 (베이비시터) 붙여쓰기 베이비[[:space:]]+시터 베이비시터 TRUE 6   (연말정산) 붙여쓰기   연말[[:space:]]+정산   연말정산 TRUE 7   (출산휴가) 붙여쓰기   출산[[:space:]]+휴가   출산휴가 TRUE 8   (시어머니) 붙여쓰기   시[[:space:]]+어머니   시어머니 TRUE 9   (육아휴직) 붙여쓰기   육아[[:space:]]+휴직   육아휴직 TRUE doc_content <- buzz$CONTENT  stringr::str_detect(doc_content, \"가사도우미\") %>%    sum(na.rm = TRUE) [1] 1  stringr::str_detect(doc_content, \"가사[[:space:]]+도우미\") %>%    sum(na.rm = TRUE) [1] 22 buzz_after <- buzz %>%    mutate(CONTENT = concat_text(CONTENT, verbos = TRUE)) ── Concat: (가사도우미) 붙여쓰기 ─────────────────────────────────────── 22건 ── ── Concat: (베이비시터) 붙여쓰기 ──────────────────────────────────────── 1건 ── ── Concat: (산후도우미) 붙여쓰기 ──────────────────────────────────────── 1건 ── ── Concat: (시어머니) 붙여쓰기 ────────────────────────────────────────── 1건 ── ── Concat: (연말정산) 붙여쓰기 ────────────────────────────────────────── 1건 ── ── Concat: (육아휴직) 붙여쓰기 ────────────────────────────────────────── 2건 ── ── Concat: (출산휴가) 붙여쓰기 ────────────────────────────────────────── 1건 ── ── Concat: (친정어머니) 붙여쓰기 ──────────────────────────────────────── 5건 ── ── Concat: (하원도우미) 붙여쓰기 ──────────────────────────────────────── 1건 ──  stringr::str_detect(buzz_after$CONTENT, \"가사도우미\") %>%    sum(na.rm = TRUE) [1] 23  stringr::str_detect(buzz_after$CONTENT, \"가사[[:space:]]+도우미\") %>%    sum(na.rm = TRUE) [1] 0 morpho_mecab(\"가사도우가 집안 청소를 했다.\")    NNG    NNG    NNG    NNG  \"가사\" \"도우\" \"집안\" \"청소\""},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"split_text를-이용한-텍스트-분리","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"split_text()를 이용한 텍스트 분리","title":"Manipulate Documents","text":"묶어진 단어를 다시 분리할 경우에는 split_text()를 사용합니다. 가사도우미를 주제로 하는 것이 아니라 도우미를 주제로 분석하려 합니다. 도우미가 들어간 복합명사를 분리해서 도우미라는 독립된 단어를 만들고자 합니다. concat_text()의 사례와는 반대의 경우입니다. 도우미가 들어간 복합명사들이 모두 분리되었습니다.","code":"meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_split.csv\") set_meta(\"split\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 분리 룰 확인하기 get_meta(\"split\")                  rule_nm 1 (도우미) 유형 띄어쓰기                                                    pattern replace  use 1 (하원|등하원|등원|입주|교포|가사|산후|보육|산모)(도우미) \\\\1 \\\\2 TRUE doc_content <- buzz$CONTENT  stringr::str_extract_all(doc_content, \"(하원|등하원|등원|입주|교포|가사|산후|보육|산모)(도우미)\") %>%    unlist() %>%    na.omit() %>%    as.vector()  [1] \"산후도우미\" \"입주도우미\" \"입주도우미\" \"입주도우미\" \"입주도우미\"  [6] \"등원도우미\" \"등원도우미\" \"가사도우미\" \"등원도우미\" \"등원도우미\" [11] \"보육도우미\" buzz_after <- buzz %>%    mutate(CONTENT = split_text(CONTENT, verbos = TRUE)) ── Split: (도우미) 유형 띄어쓰기 ──────────────────────────────────────── 6건 ──  stringr::str_detect(buzz_after$CONTENT, \"(하원|등하원|등원|입주|교포|가사|산후|보육|산모)(도우미)\") %>%    sum(na.rm = TRUE) [1] 0"},{"path":"https://r2bit.com/bitNLP/dev/articles/manipulate_docs.html","id":"remove_text를-이용한-텍스트-제거","dir":"Articles","previous_headings":"bitNLP의 메타 데이터 관리","what":"remove_text()를 이용한 텍스트 제거","title":"Manipulate Documents","text":"문서 안에 불필요한 텍스트들이 포함되어 있을 수 있습니다. 그래서 문서 내에서 패턴 검색으로 불필요한 텍스트를 골라내어 제거할 수 있습니다. remove_text()를 사용합니다. 수집한 카페의 게시글에는 불필요한 텍스트들이 포함될 수 있습니다. 다음은 카페의 게시글을 작성할 때, 관리자가 미리 설정해 놓은 주의사항을 삭제하지 않고 게시글을 작성한 문서들을 조회한 사례입니다. 그리고 불필요한 주의사항을 제거한 후의 내용은 어느 정도 정제가 되었습니다. remove_text()로 불필요한 텍스트를 제거한 후에, 앞의 사례인 “게시판[[:space:]]*이용전[[:print:]]*이동됩니다.”를 조회했습니다. 해당 문장이 삭제되어 패턴 검색이 되지 않았습니다.","code":"meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_remove.csv\") set_meta(\"remove\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 제거 룰 확인하기 get_meta(\"remove\")           rule_nm                                         pattern  use 1 카페 안내문구 1 게시판[[:space:]]*이용전[[:print:]]*이동됩니다. TRUE 2 카페 안내문구 2                  카페이용 전[[:print:]]*참고\\\\) TRUE 3 카페 안내문구 3                 게시글 작성[[:print:]]*35756864 TRUE 4 카페 안내문구 4             흥부야[[:print:]]*기타 하고 싶은 말 TRUE 5        URL 문구   (http|www)([a-zA-Z0-9\\\\>\\\\/\\\\.\\\\:\\\\=\\\\&\\\\_])* TRUE doc_content <- buzz$CONTENT  stringr::str_detect(doc_content, \"게시판[[:space:]]*이용전[[:print:]]*이동됩니다.\") %>%    which  [1]  61  65  67  69  79  82 237 239 245 251 252 256 257 400 403 406 416 417 419 [20] 563 569 571 584 732 737 739 740 903 910 912 915 921 922  doc_content[61] [1] \" 게시판 이용전반드시 카페규정 http://cafe.naver.com/imsanbu/28123090을 미리 숙지 당부드립니다.수다방 성격에 맞지않는 이탈글은 적합한 게시판으로 이동 또는 삭제예정게시판으로 이동됩니다.인천살구 아기는 15개월이에요 선천성기형인 이루공인데 수술하신분들은 어디서하셨나요 지금은 인천국제성모에서진료중이고 고름나기시작해서 수술을하게되면 아주대에서할까하는데 아기가 너무어려서 걱정입니다경험하신분들 조언좀해주세요\"  stringr::str_remove(doc_content[61], \"게시판[[:space:]]*이용전[[:print:]]*이동됩니다.\")  [1] \" 인천살구 아기는 15개월이에요 선천성기형인 이루공인데 수술하신분들은 어디서하셨나요 지금은 인천국제성모에서진료중이고 고름나기시작해서 수술을하게되면 아주대에서할까하는데 아기가 너무어려서 걱정입니다경험하신분들 조언좀해주세요\" buzz_after <- buzz %>%    mutate(CONTENT = remove_text(CONTENT, verbos = TRUE)) ── Removes: URL 문구 ─────────────────────────────────────────────────── 40건 ── ── Removes: 카페 안내문구 1 ──────────────────────────────────────────── 33건 ── ── Removes: 카페 안내문구 2 ───────────────────────────────────────────── 9건 ── ── Removes: 카페 안내문구 3 ──────────────────────────────────────────── 47건 ── ── Removes: 카페 안내문구 4 ──────────────────────────────────────────── 16건 ──  stringr::str_detect(buzz_after$CONTENT, \"게시판[[:space:]]*이용전[[:print:]]*이동됩니다.\") %>%    sum(na.rm = TRUE) [1] 0"},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"형태소분석","dir":"Articles","previous_headings":"","what":"형태소분석","title":"Morphological Analysis","text":"bitNLP는 은전한닢 형태소분석기를 이용하여 형태소 분석을 수행합니다. 이미 사용자는 형태소 분석기를 설치하였거나, install_mecab() 함수를 이용해서 형태소 분석기를 설치한 것을 전제로 합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"은전한닢-형태소분석기-품사태깅","dir":"Articles","previous_headings":"","what":"은전한닢 형태소분석기 품사태깅","title":"Morphological Analysis","text":"새종 품사와 은전한닢 형태소분석기인 mecab-ko의 품사 태그는 다음과 같습니다.","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"함수의-원형","dir":"Articles","previous_headings":"morpho_mecab()을 이용한 품사 태깅과 토큰화","what":"함수의 원형","title":"Morphological Analysis","text":"morpho_mecab() 함수가 은전한닢 형태소분석기를 인터페이스합니다. morpho_mecab() 함수의 인수는 다음과 같습니다. character. 형태소 분석에 사용할 document. character. 형태소 분석의 결과 유형.모든 품사, 명사, 동사 및 형용사와 같은 토큰화 결과 유형을 지정. “morpheme”, “noun”, “noun2”, “verb”, “adj”중에서 선택. 기본값은 “noun”로 일반명사만 추출함. logical. 복수개의 문서일 때 개별 문서를 리스트로 반환할 지를 선택함. TRUE이면 개별 리스트로 반환하고, FALSE이면 하나의 문자 벡터로 반환함. 기본값은 TRUE mecab-ko 형태소 분석기의 사용자 정의 사전 파일. 기본값은 NULL로 사용자 사전파일을 지정하지 않음. 시스템 사전인 “/usr/local/lib/mecab/dic/mecab-ko-dic”(Linux, Mac)를 보완하여 사용됨. 사용자 사전 파일은 mecab-dict-index 명령어로 생성되며, 확장자가 “dic”임.","code":"library(bitNLP)  args(morpho_mecab) function (x, type = c(\"noun\", \"noun2\", \"verb\", \"adj\", \"morpheme\"),      indiv = TRUE, user_dic = NULL, as_list = FALSE)  NULL"},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"품사-태깅","dir":"Articles","previous_headings":"morpho_mecab()을 이용한 품사 태깅과 토큰화","what":"품사 태깅","title":"Morphological Analysis","text":"문서에 품사를 태깅하기 위해서는 type 인수에 “morpheme”를 지정하고, morpho_mecab()를 호출합니다. 이 함수는 문서를 품사 단위로 토큰화합니다. 이때, 결과는 문자 벡터를 반환하며, 품사의 벡터의 이름으로 태깅됩니다. 다음 예에서 “님”은 일반명사인 “NNG”로 태그되었습니다. 굳이 소제목을 광의의 품사 기반의 토큰화가 아닌 협의의 품사 태깅이라 표현한 것은 모든 품사를 토큰화하였기 때문입니다. 만약에 형태소 분석에 사용할 문서가 2개 이상일 경우에는 개별 문서를 리스트의 성분으로 반환합니다. 그런데 여러 개의 문서를 개별로 처리하지 않고, 하나의 문서처럼 묶어 처리할 수 도 있습니다. 다음처럼 indiv 인수값에 FALSE를 지정하면 됩니다.","code":"morpho_mecab(\"님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.\",  type = \"morpheme\")      NNG       JX    VV+EP       EF       SF       IC       SC      NNG      \"님\"     \"은\"     \"갔\" \"습니다\"      \".\"   \"아아\"      \",\"   \"사랑\"       XSV      ETM       NP      JKG      NNG       JX    VV+EP       EF      \"하\"     \"는\"     \"나\"     \"의\"     \"님\"     \"은\"     \"갔\" \"습니다\"        SF       \".\" docs <- c(\"님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.\",           \"푸른 산빛을 깨치고 단풍나무 숲을 향하여 난 작은 길을 걸어서, 차마 떨치고 갔습니다.\") morpho_mecab(docs,  type = \"morpheme\") [[1]]      NNG       JX    VV+EP       EF       SF       IC       SC      NNG      \"님\"     \"은\"     \"갔\" \"습니다\"      \".\"   \"아아\"      \",\"   \"사랑\"       XSV      ETM       NP      JKG      NNG       JX    VV+EP       EF      \"하\"     \"는\"     \"나\"     \"의\"     \"님\"     \"은\"     \"갔\" \"습니다\"        SF       \".\"   [[2]]     VA+ETM        NNG        NNG        JKO         VV         EC        NNG      \"푸른\"       \"산\"       \"빛\"       \"을\"     \"깨치\"       \"고\" \"단풍나무\"         NNG        JKO         VV         EC      NP+JX         VA        ETM        \"숲\"       \"을\"     \"향하\"       \"여\"       \"난\"       \"작\"       \"은\"         NNG        JKO      VV+EC         SC        MAG         VV         EC        \"길\"       \"을\"   \"걸어서\"        \",\"     \"차마\"     \"떨치\"       \"고\"       VV+EP         EF         SF        \"갔\"   \"습니다\"        \".\" morpho_mecab(docs, indiv = FALSE, type = \"morpheme\")        NNG         JX      VV+EP         EF         SF         IC         SC        \"님\"       \"은\"       \"갔\"   \"습니다\"        \".\"     \"아아\"        \",\"         NNG        XSV        ETM         NP        JKG        NNG         JX      \"사랑\"       \"하\"       \"는\"       \"나\"       \"의\"       \"님\"       \"은\"       VV+EP         EF         SF     VA+ETM        NNG        NNG        JKO        \"갔\"   \"습니다\"        \".\"     \"푸른\"       \"산\"       \"빛\"       \"을\"          VV         EC        NNG        NNG        JKO         VV         EC      \"깨치\"       \"고\" \"단풍나무\"       \"숲\"       \"을\"     \"향하\"       \"여\"       NP+JX         VA        ETM        NNG        JKO      VV+EC         SC        \"난\"       \"작\"       \"은\"       \"길\"       \"을\"   \"걸어서\"        \",\"         MAG         VV         EC      VV+EP         EF         SF      \"차마\"     \"떨치\"       \"고\"       \"갔\"   \"습니다\"        \".\""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"품사-토큰화","dir":"Articles","previous_headings":"morpho_mecab()을 이용한 품사 태깅과 토큰화","what":"품사 토큰화","title":"Morphological Analysis","text":"텍스트 분석에서 명사만 추출하여 문서의 맥락을 이해하는 방법이 일반적입니다. 그래서 morpho_mecab() 함수의 type 인수의 기본값이 “noun”입니다. 명사만 토큰화해 봅니다. 인수값 “noun”는 일반명사만 추출합니다. 만약에 좀 더 많은 종류의 명사를 추출하기 위해서는 “noun2”를 사용합니다. “noun2”는 태그가 “N”으로 시작하는 체언을 추출합니다. 동사를 추출하기 위해서는 type 인수에 `“verb”를 사용합니다.","code":"morpho_mecab(docs, indiv = FALSE)        NNG        NNG        NNG        NNG        NNG        NNG        NNG        \"님\"     \"사랑\"       \"님\"       \"산\"       \"빛\" \"단풍나무\"       \"숲\"         NNG        \"길\" morpho_mecab(docs, indiv = FALSE, type = \"noun2\")        NNG        NNG         NP        NNG        NNG        NNG        NNG        \"님\"     \"사랑\"       \"나\"       \"님\"       \"산\"       \"빛\" \"단풍나무\"         NNG      NP+JX        NNG        \"숲\"       \"난\"       \"길\" morpho_mecab(docs, indiv = FALSE, type = \"verb\")    VV+EP    VV+EP       VV       VV    VV+EC       VV    VV+EP      \"갔\"     \"갔\"   \"깨치\"   \"향하\" \"걸어서\"   \"떨치\"     \"갔\""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"품사의-워드클라우드-그리기","dir":"Articles","previous_headings":"morpho_mecab()을 이용한 품사 태깅과 토큰화","what":"품사의 워드클라우드 그리기","title":"Morphological Analysis","text":"명사를 추출하여 워드클라우드를 그려봅니다. bitNLP에 수록된 대통령 연설문 데이터셋인 president_speech에서 임의의 연설문 100개에서 일반명사를 추출 후 워드클라우드를 그려 봅니다.   보통 상위 랭크의 도수(Frequency)를 갖는 명사 토큰은 문서의 맥락을 파악하는 데 불필요한 토큰입니다. 마치 상투어 같은 역할만 합니다. 그래서 경우에 따라서 이를 제거하는 것도 유용할 수 있습니다. 상위 10위 도숫를 갖는 명사 토큰을 제거 후 워드클라우드를 그려 봅니다.","code":"library(dplyr)  president_speech$doc[1:100] %>%    morpho_mecab(indiv = FALSE) %>%    table() %>%    wordcloud2::wordcloud2(fontFamily = \"NanumSquare\") president_speech$doc[1:100] %>%    morpho_mecab(indiv = FALSE) %>%    table() %>%    sort(decreasing = TRUE) %>%    .[-c(1:10)] %>%    wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")"},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"사용자-정의-사전-사용하기","dir":"Articles","previous_headings":"","what":"사용자 정의 사전 사용하기","title":"Morphological Analysis","text":"형태소 분석기의 사전은 우리가 이야기하고, 글로 적는 모든 사례의 언어를 포함하지 못합니다. 일종의 샘플링 데이터입니다. 그러므로 품사 태깅의 오류가 반드시 따라오게 됩니다. 특히 과학, 예술, 의료 등과 같은 전문 영역에서는 그 빈도가 높아집니다. 이 경우에는 오분류하는 품사를 보정하기 위해서 시스템 사전을 개선하던가 사용자 사전을 추가하게 됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"사용자-사전을-이용한-품사-토큰화","dir":"Articles","previous_headings":"사용자 정의 사전 사용하기","what":"사용자 사전을 이용한 품사 토큰화","title":"Morphological Analysis","text":"다음 문서의 일반명사 추출 결과를 보면 성능이 썩 좋지 않습니다. 많은 복합명사가 쪼개졌습니다. bitNLP 패키지에 포함된 샘플 사용자 정의 사전을 적용하기 위해서 user_dic 인수를 사용하였습니다. 결과를 보면 사용자 정의 사전을 사용하지 않았던 결과의 오류가 개선되었습니다.","code":"str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\" morpho_mecab(str)    NNG    NNG    NNG    NNG    NNG    NNG    NNG    NNG    NNG  \"신혼\" \"부부\" \"주말\" \"부부\" \"놀이\" \"공원\" \"자유\" \"이용\" \"구매\" dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\")  morpho_mecab(str, user_dic = dic_file)          NNG          NNG          NNG          NNG          NNG          NNG    \"신혼부부\"   \"주말부부\"       \"놀이\"       \"공원\" \"자유이용권\"       \"구매\""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"사용자-사전-정의하기","dir":"Articles","previous_headings":"사용자 정의 사전 사용하기","what":"사용자 사전 정의하기","title":"Morphological Analysis","text":"-","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/morphology.html","id":"사용자-사전-컴파일하기","dir":"Articles","previous_headings":"사용자 정의 사전 사용하기","what":"사용자 사전 컴파일하기","title":"Morphological Analysis","text":"-","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"tidytext-패키지","dir":"Articles","previous_headings":"","what":"tidytext 패키지","title":"Collaboration with tidytext package","text":"요즘 R 진영에는 tidy한 작업이 대세입니다. 깔끔하게 정도로 번역을 할 수도 있지만, 최적의 단어로 번역이 어렵습니다. 쉽게 생각한다면, tidyverse 패키지군의 “tibble 구조로 데이터를 구조화하여 분석할 수 있다.” 정도의 의미 해석이 가능합니다. 이것은 한편으로는 tidyverse 패키지군과의 협업 용이성을 의미하기도 합니다. 즉, tidyverse 패키지군에서 제공하는 여러 장점을 사용할 수 있다는 것입니다. 아마도 dplyr와의 협업이 주가 될 것입니다. 다음은 CRAN에 등록된 패키지중에서 tidy라는 단어가 들어간 패키지 이름을 조사한 결과입니다. 앞으로 계속 늘어날텐데, 이 작업을 수행한 시점인 2022-07-31에는 73개 패키지가 있습니다. 목록의 63번째 tidytext 패키지는 텍스트 데이터 분석을 수행할 때, tidyverse 패키지군의 dplyr과 ggplot2의 기능과 더불어 쉽고 효과적인 텍스트 분석을 수행할 수 있습니다.","code":"library(tidyverse)  available.packages(repos = \"https://cran.rstudio.com/\") %>%    row.names() %>%    str_subset(\"tidy\")  [1] \"cstidy\"          \"spotidy\"         \"tidyAML\"         \"tidybayes\"        [5] \"tidyBdE\"         \"tidybins\"        \"tidyboot\"        \"tidycat\"          [9] \"tidyCDISC\"       \"tidycensus\"      \"tidychangepoint\" \"tidycharts\"      [13] \"tidyclust\"       \"tidycmprsk\"      \"tidycode\"        \"tidycomm\"        [17] \"tidycountries\"   \"tidyCpp\"         \"tidycwl\"         \"tidydann\"        [21] \"tidydatatutor\"   \"tidydelta\"       \"tidyDenovix\"     \"tidydice\"        [25] \"tidydr\"          \"tidyedgar\"       \"tidyEdSurvey\"    \"tidyEmoji\"       [29] \"tidyestimate\"    \"tidyfast\"        \"tidyfinance\"     \"tidyfit\"         [33] \"tidyformula\"     \"tidyfst\"         \"tidyft\"          \"tidygam\"         [37] \"tidygapminder\"   \"tidygate\"        \"tidygenomics\"    \"tidygeocoder\"    [41] \"tidygeoRSS\"      \"tidygraph\"       \"tidyHeatmap\"     \"tidyheatmaps\"    [45] \"tidyhte\"         \"tidyhydat\"       \"tidyindex\"       \"tidyjson\"        [49] \"tidylda\"         \"tidyllm\"         \"tidylo\"          \"tidylog\"         [53] \"tidyLPA\"         \"tidyMC\"          \"tidymodels\"      \"tidymodlr\"       [57] \"tidync\"          \"tidypaleo\"       \"tidyplate\"       \"tidyplots\"       [61] \"tidyplus\"        \"tidypmc\"         \"tidyposterior\"   \"tidypredict\"     [65] \"tidyprompt\"      \"tidyquant\"       \"tidyquery\"       \"tidyr\"           [69] \"tidyrates\"       \"tidyREDCap\"      \"tidyrgee\"        \"tidyRSS\"         [73] \"tidyrules\"       \"tidysdm\"         \"tidyselect\"      \"tidySEM\"         [77] \"tidyseurat\"      \"tidysmd\"         \"tidysq\"          \"tidystats\"       [81] \"tidystopwords\"   \"tidystringdist\"  \"tidytable\"       \"tidyterra\"       [85] \"tidytext\"        \"tidytidbits\"     \"tidytlg\"         \"tidytransit\"     [89] \"tidytreatment\"   \"tidytree\"        \"tidytuesdayR\"    \"tidyUSDA\"        [93] \"tidyverse\"       \"tidyvpc\"         \"tidywater\"       \"tidywikidatar\"   [97] \"tidyxl\"          \"wikkitidy\""},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"tidytext와의-협업","dir":"Articles","previous_headings":"","what":"tidytext와의 협업","title":"Collaboration with tidytext package","text":"아마도 한국 텍스트분석을 수행하는 분석가중 많은 수가 tidytext 패키지를 이용할 것입니다. 그러나 영문 텍스트 분석을 수행할 목적으로 개발된 tidytext 패키지에서는 한글을 분석하는데 다소 부족한 영역이 존재합니다. 그래서 bitNLP 패키지는 이 지점을 지원하여, 한글 텍스트 분석을 수행함에 있어서 tidytext 패키지를 원활히 사용할 수 있도록 도와줍니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"한글-tokenizer","dir":"Articles","previous_headings":"tidytext와의 협업","what":"한글 tokenizer","title":"Collaboration with tidytext package","text":"교착어인 한글은 영문과 달리, 띄어쓰기 단위인 words가 아닌 형태소 단위로 토큰화를 수행해야 텍스트 분석을 수행할 수 있습니다. 물론 경우에 따라서 words 단위의 토큰화가 유용한 경우도 있습니다. bitNLP에서는 tidytext 패키지에서 지원하지 않는, 엄밀히 말하면 tidytext 패키지 내부에서 사용하는 tokenizers 패키지에서 제공하지 않는 두개의 토크나이저(tokenizers)를 제공합니다.: morpho_mecab() part--speech tagger 단위의 토크나이저 tokenize_noun_ngrams() tidytext 구문에서 형태소 토크나이저인 morpho_mecab()는 다음과 같이 사용합니다. 만약 사용자 사전이 있다면 다음과 같이 user_dic 인수를 사용할 수도 있습니다. 명사 n-grams 토크나이저는 다음과 같이 사용합니다.","code":"library(bitNLP) library(tidyverse) library(tidytext)  nho_noun_indiv <- president_speech %>%   filter(president %in% \"노무현\") %>%   filter(str_detect(category, \"^외교\")) %>%   tidytext::unnest_tokens(     out = \"speech_noun\",     input = \"doc\",     token = morpho_mecab   )     nho_noun_indiv   [38;5;246m# A tibble: 44,316 × 7 [39m   id       president category  type  title                     date  speech_noun    [3m [38;5;246m<chr> [39m [23m     [3m [38;5;246m<chr> [39m [23m      [3m [38;5;246m<chr> [39m [23m      [3m [38;5;246m<chr> [39m [23m  [3m [38;5;246m<chr> [39m [23m                      [3m [38;5;246m<chr> [39m [23m  [3m [38;5;246m<chr> [39m [23m        [38;5;250m1 [39m DOC_0001 노무현    외교-통상 치사   [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m…… 2005… 우정         [38;5;250m2 [39m DOC_0001 노무현    외교-통상 치사   [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m…… 2005… 해           [38;5;250m3 [39m DOC_0001 노무현    외교-통상 치사   [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m…… 2005… 개막식       [38;5;250m4 [39m DOC_0001 노무현    외교-통상 치사   [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m…… 2005… 축하         [38;5;246m# ℹ 44,312 more rows [39m president_speech %>%   filter(president %in% \"노무현\") %>%   filter(str_detect(category, \"^외교\")) %>%   tidytext::unnest_tokens(     out = \"speech_noun\",     input = \"doc\",     token = morpho_mecab,     user_dic = user_dic   ) tokenize_noun_ngrams(president_speech$doc[1:2]) [[1]]   [1] \"우정 해\"       \"해 개막식\"     \"개막식 축하\"   \"축하 행사\"       [5] \"행사 축하\"     \"축하 참석\"     \"참석 모두\"     \"모두 환영\"       [9] \"환영 감사\"     \"감사 인사\"     \"인사 전\"       \"전 이웃\"        [13] \"이웃 옛날\"     \"옛날 이웃\"     \"이웃 이웃\"     \"이웃 사정\"      [17] \"사정 통신사\"   \"통신사 절\"     \"절 시절\"       \"시절 연락선\"    [21] \"연락선 시대\"   \"시대 항공기\"   \"항공기 하루\"   \"하루 안\"        [25] \"안 시대\"       \"시대 교통\"     \"교통 발달\"     \"발달 통신\"      [29] \"통신 관계\"     \"관계 경제\"     \"경제 교류\"     \"교류 말\"        [33] \"말 협력\"       \"협력 국음\"     \"국음 마음\"     \"마음 실행\"      [37] \"실행 가공\"     \"가공 과학\"     \"과학 기술\"     \"기술 옛날\"      [41] \"옛날 사이\"     \"사이 불편\"     \"불편 문제\"     \"문제 생각\"      [45] \"생각 상황\"     \"상황 양국\"     \"양국 관계\"     \"관계 불편\"      [49] \"불편 생존\"     \"생존 자체\"     \"자체 위협\"     \"위협 사이\"      [53] \"사이 유감\"     \"유감 친구\"     \"친구 방법\"     \"방법 관계\"      [57] \"관계 숙명\"     \"숙명 친구\"     \"친구 관계\"     \"관계 친구\"      [61] \"친구 친구\"     \"친구 미래\"     \"미래 적극\"     \"적극 친구\"      [65] \"친구 손\"       \"손 불행\"       \"불행 평화\"     \"평화 번영\"      [69] \"번영 미래\"     \"미래 관계\"     \"관계 자리\"     \"자리 양국\"      [73] \"양국 관계\"     \"관계 도로\"     \"도로 표현\"     \"표현 전\"        [77] \"전 경제\"       \"경제 도로는\"   \"도로는 고속도\" \"고속도 수준\"    [81] \"수준 정치\"     \"정치 안보\"     \"안보 측면\"     \"측면 협력\"      [85] \"협력 도로\"     \"도로 개통\"     \"개통 문화\"     \"문화 도로\"      [89] \"도로 길\"       \"길 길\"         \"길 위\"         \"위 장애물\"      [93] \"장애물 양국\"   \"양국 협력\"     \"협력 관계\"     \"관계 고속\"      [97] \"고속 도로\"     \"도로 장애물\"   \"장애물 직시\"   \"직시 양국\"     [101] \"양국 정부\"     \"정부 국민\"     \"국민 적극\"     \"적극 노력\"     [105] \"노력 가슴\"     \"가슴 우정\"     \"우정 불\"       \"불 자리\"       [109] \"자리 우정\"     \"우정 불\"       \"불 양국\"       \"양국 국민\"     [113] \"국민 사이\"     \"사이 우정\"     \"우정 계기\"     \"계기 이틀\"     [117] \"이틀 전\"       \"전 주최\"       \"주최 행사\"     \"행사 성공\"     [121] \"성공 성원\"     \"성원 참석\"     \"참석 격려\"     \"격려 총리\"     [125] \"총리 국민\"     \"국민 자리\"     \"자리 감사\"     \"감사 올해\"     [129] \"올해 양국\"     \"양국 수교\"     \"수교 해\"       \"해 일\"         [133] \"일 양국\"       \"양국 우정\"     \"우정 성공\"     \"성공 때\"       [137] \"때 보람\"       \"보람 생각\"     \"생각 올해\"     \"올해 이전\"     [141] \"이전 양국\"     \"양국 국민\"     \"국민 교류\"     \"교류 국민\"     [145] \"국민 교류\"     \"교류 해\"       \"해 감사\"        [[2]]  [1] \"각하 국민\"   \"국민 신년\"   \"신년 인사\"   \"인사 새해\"   \"새해 축복\"    [6] \"축복 해\"     \"해 기원\"     \"기원 올해\"   \"올해 양국\"   \"양국 관계\"   [11] \"관계 발전\"   \"발전 전기\"   \"전기 중\"     \"중 교류\"     \"교류 해\"     [16] \"해 경제\"     \"경제 학술\"   \"학술 문화\"   \"문화 체육\"   \"체육 청소년\" [21] \"청소년 분야\" \"분야 행사\"   \"행사 본격\"   \"본격 국민\"   \"국민 교류\"   [26] \"교류 협력\"   \"협력 시대\"   \"시대 나라\"   \"나라 교역\"   \"교역 상대국\" [31] \"상대국 투자\" \"투자 대상\"   \"대상 국\"     \"국 한국인\"   \"한국인 방문\" [36] \"방문 서로\"   \"서로 문화\"   \"문화 이웃\"   \"이웃 양국\"   \"양국 우호\"   [41] \"우호 협력\"   \"협력 올해\"   \"올해 교류\"   \"교류 행사\"   \"행사 강화\"   [46] \"강화 각하\"   \"각하 합의\"   \"합의 전면\"   \"전면 협력\"   \"협력 동반자\" [51] \"동반자 관계\" \"관계 심화\"   \"심화 평화\"   \"평화 공동\"   \"공동 번영\"   [56] \"번영 미래\"   \"미래 기대\"   \"기대 각하\"   \"각하 건강\"   \"건강 무궁\"   [61] \"무궁 발전\"   \"발전 기원\"    # simplify = TRUE tokenize_noun_ngrams(president_speech$doc[1], simplify = TRUE)   [1] \"우정 해\"       \"해 개막식\"     \"개막식 축하\"   \"축하 행사\"       [5] \"행사 축하\"     \"축하 참석\"     \"참석 모두\"     \"모두 환영\"       [9] \"환영 감사\"     \"감사 인사\"     \"인사 전\"       \"전 이웃\"        [13] \"이웃 옛날\"     \"옛날 이웃\"     \"이웃 이웃\"     \"이웃 사정\"      [17] \"사정 통신사\"   \"통신사 절\"     \"절 시절\"       \"시절 연락선\"    [21] \"연락선 시대\"   \"시대 항공기\"   \"항공기 하루\"   \"하루 안\"        [25] \"안 시대\"       \"시대 교통\"     \"교통 발달\"     \"발달 통신\"      [29] \"통신 관계\"     \"관계 경제\"     \"경제 교류\"     \"교류 말\"        [33] \"말 협력\"       \"협력 국음\"     \"국음 마음\"     \"마음 실행\"      [37] \"실행 가공\"     \"가공 과학\"     \"과학 기술\"     \"기술 옛날\"      [41] \"옛날 사이\"     \"사이 불편\"     \"불편 문제\"     \"문제 생각\"      [45] \"생각 상황\"     \"상황 양국\"     \"양국 관계\"     \"관계 불편\"      [49] \"불편 생존\"     \"생존 자체\"     \"자체 위협\"     \"위협 사이\"      [53] \"사이 유감\"     \"유감 친구\"     \"친구 방법\"     \"방법 관계\"      [57] \"관계 숙명\"     \"숙명 친구\"     \"친구 관계\"     \"관계 친구\"      [61] \"친구 친구\"     \"친구 미래\"     \"미래 적극\"     \"적극 친구\"      [65] \"친구 손\"       \"손 불행\"       \"불행 평화\"     \"평화 번영\"      [69] \"번영 미래\"     \"미래 관계\"     \"관계 자리\"     \"자리 양국\"      [73] \"양국 관계\"     \"관계 도로\"     \"도로 표현\"     \"표현 전\"        [77] \"전 경제\"       \"경제 도로는\"   \"도로는 고속도\" \"고속도 수준\"    [81] \"수준 정치\"     \"정치 안보\"     \"안보 측면\"     \"측면 협력\"      [85] \"협력 도로\"     \"도로 개통\"     \"개통 문화\"     \"문화 도로\"      [89] \"도로 길\"       \"길 길\"         \"길 위\"         \"위 장애물\"      [93] \"장애물 양국\"   \"양국 협력\"     \"협력 관계\"     \"관계 고속\"      [97] \"고속 도로\"     \"도로 장애물\"   \"장애물 직시\"   \"직시 양국\"     [101] \"양국 정부\"     \"정부 국민\"     \"국민 적극\"     \"적극 노력\"     [105] \"노력 가슴\"     \"가슴 우정\"     \"우정 불\"       \"불 자리\"       [109] \"자리 우정\"     \"우정 불\"       \"불 양국\"       \"양국 국민\"     [113] \"국민 사이\"     \"사이 우정\"     \"우정 계기\"     \"계기 이틀\"     [117] \"이틀 전\"       \"전 주최\"       \"주최 행사\"     \"행사 성공\"     [121] \"성공 성원\"     \"성원 참석\"     \"참석 격려\"     \"격려 총리\"     [125] \"총리 국민\"     \"국민 자리\"     \"자리 감사\"     \"감사 올해\"     [129] \"올해 양국\"     \"양국 수교\"     \"수교 해\"       \"해 일\"         [133] \"일 양국\"       \"양국 우정\"     \"우정 성공\"     \"성공 때\"       [137] \"때 보람\"       \"보람 생각\"     \"생각 올해\"     \"올해 이전\"     [141] \"이전 양국\"     \"양국 국민\"     \"국민 교류\"     \"교류 국민\"     [145] \"국민 교류\"     \"교류 해\"       \"해 감사\"        str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\"  tokenize_noun_ngrams(str) [[1]] [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" [7] \"자유 이용\" \"이용 구매\"  # 불용어 처리 tokenize_noun_ngrams(str, stopwords = \"구매\") [[1]] [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" [7] \"자유 이용\"   # 사용자 정의 사전 사용 dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\") tokenize_noun_ngrams(str, simplify = TRUE, user_dic = dic_file) [1] \"신혼부부 주말부부\" \"주말부부 놀이\"     \"놀이 공원\"         [4] \"공원 자유이용권\"   \"자유이용권 구매\"    # n_min tokenize_noun_ngrams(str, n_min = 1, user_dic = dic_file) [[1]]  [1] \"신혼부부\"          \"신혼부부 주말부부\" \"주말부부\"           [4] \"주말부부 놀이\"     \"놀이\"              \"놀이 공원\"          [7] \"공원\"              \"공원 자유이용권\"   \"자유이용권\"        [10] \"자유이용권 구매\"   \"구매\"               # ngram_delim tokenize_noun_ngrams(str, ngram_delim = \":\", user_dic = dic_file) [[1]] [1] \"신혼부부:주말부부\" \"주말부부:놀이\"     \"놀이:공원\"         [4] \"공원:자유이용권\"   \"자유이용권:구매\"    # bi-grams tokenize_noun_ngrams(str, n = 2, ngram_delim = \":\", user_dic = dic_file) [[1]] [1] \"신혼부부:주말부부\" \"주말부부:놀이\"     \"놀이:공원\"         [4] \"공원:자유이용권\"   \"자유이용권:구매\""},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"한글-unnest_tokens","dir":"Articles","previous_headings":"tidytext와의 협업","what":"한글 unnest_tokens","title":"Collaboration with tidytext package","text":"bitNLP의 한글 unnest_tokens에는 명사 n-grams 토크나이즈를 지원하는 unnest_noun_ngrams() 함수가 있습니다. 이 함수는 tidytext 패키지의 unnest_tokens 함수군의 사용법과 거의 동일합니다. tidy와 같이 회자되는 단어인 unnest는 “중첩을 해제한다”고 번역되지만, 이것 또한 어렵게 번역되고 있습니다. tidy 데이터의 핵심은 데이터를 관측치인 행과 변수인 열로 구조화는 것입니다. 그리고 열에는 하나의 값인 단일 값(길이가 1인 벡터)을 포함해야 합니다. 즉, 행의 차원와 열의 차원으로 구성된 2차원 데이터 구조가 tidy 데이터입니다. 그런데 하나의 관측치에서 특정 변수의 값이 단일 값이 아닌 경우가 있습니다. 마치 R의 리스트처럼 여러 값으로 구성되어 있습니다. 이 경우에서 문제가 되는 특정 열의 여러 정보를 풀어서 단일 정보로 변환하는 것이 unnest입니다. 결국의 해당 변수의 단일 정보 개수만큼 관측치(행)를 복제한 후, 해당 열에 각각의 단일 정보만 넣는 작업이 unnest입니다. 다음의 한용운님의 님의 침묵 시에서 첫번째와 두번째 줄을 tibble 객체로 만든 것입니다. 우리는 시의 내용에서 다음처럼 일반명사만 추출했습니다. 명사를 추출한 변수 명사에는 첫 행에는 3개의 명사(정보)가, 둘째 행에는 5개의 명사(정보)가 들어있습니다. 그런데 텍스트 분석에서는 문장 레벨의 분석보다는 토큰(한글 텍스트 데이터에서는 명사) 레벨로 분석합니다. 이것은 개별 행에서의 분석의 대상이 되는 컬럼에는 단일 토큰을 넣어야 한다는 의미입니다. 즉 개별 토큰 레벨의 unnest 작업이 필요합니다. 한글 텍스트 데이터에서 일반명사를 추출한 후 이것을 tidy한 데이터로 만들기 위해서는 tidytext의 unnest_tokens() 함수에 토크나이저로 bitNLP의 morpho_mecab()를 사용합니다. 원하는 모습의 tidy 데이터가 만들어진 것입니닫. unnest 작업은 다음처럼 얻는 것과 잃는 것이 있습니다. tidy한 데이터 구조로 변환하였기 때문에 연산이 쉽고, 이해하기 쉽다. 불필요한 데이터가 반복적으로 복제되어 데이터의 크기가 늘어난다.","code":"docs <- c(\"님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.\",           \"푸른 산빛을 깨치고 단풍나무 숲을 향하여 난 작은 길을 걸어서, 차마 떨치고 갔습니다.\")  poem <- tibble(   연 = rep(1, 2),   행 = 1:2,   내용 = docs )  poem  [38;5;246m# A tibble: 2 × 3 [39m      연    행 내용                                                                  [3m [38;5;246m<dbl> [39m [23m  [3m [38;5;246m<int> [39m [23m  [3m [38;5;246m<chr> [39m [23m                                                               [38;5;250m1 [39m     1     1 님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.                   [38;5;250m2 [39m     1     2 푸른 산빛을 깨치고 단풍나무 숲을 향하여 난 작은 길을 걸어서, 차마 떨치고 갔습니다.…… poem %>%    mutate(명사 = collapse_noun(내용)) %>%    select(-내용)  [38;5;246m# A tibble: 2 × 3 [39m      연    행 명사                    [3m [38;5;246m<dbl> [39m [23m  [3m [38;5;246m<int> [39m [23m  [3m [38;5;246m<chr> [39m [23m                 [38;5;250m1 [39m     1     1 님 사랑 님            [38;5;250m2 [39m     1     2 산 빛 단풍나무 숲 길 poem %>%    unnest_tokens(     명사,     내용,     token = morpho_mecab   )  [38;5;246m# A tibble: 8 × 3 [39m      연    행 명사     [3m [38;5;246m<dbl> [39m [23m  [3m [38;5;246m<int> [39m [23m  [3m [38;5;246m<chr> [39m [23m  [38;5;250m1 [39m     1     1 님     [38;5;250m2 [39m     1     1 사랑   [38;5;250m3 [39m     1     1 님     [38;5;250m4 [39m     1     2 산     [38;5;246m# ℹ 4 more rows [39m"},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"unnest_noun_ngrams","dir":"Articles","previous_headings":"tidytext와의 협업 > 한글 unnest_tokens","what":"unnest_noun_ngrams()","title":"Collaboration with tidytext package","text":"bitNLP의 unnest_noun_ngrams()는 추출된 n-grams 명사 토큰들을 tibble의 컬럼에 하나씩 붙여줍니다. 다음은 대통령 연설문의 명사 bi-grams를 추출하여, noun_bigram 변수에 개별 토큰을 넣습니다. noun_bigram 변수에, ngram_delim = \":\"로 토큰의 개별 단어들을 묶어주는 문자에 기본값인 공백이 아닌 콜론(:)을 지정합니다. 그리고 drop = FALSE는 토큰화하려는 변수인 doc를 보존합니다. unnest_noun_ngrams() 함수는 group_by() 함수 함께 사용할 수 있습니다. group_by() 함수를 사용하지 않고도 동일한 작업을 수행할 수 있습니다. collapse 인수를 사용하면 됩니다. unnest_noun_ngrams()는 … 인수를 지원해서 tokenize_noun_ngrams()에서 사용할 수 있는 인수도 사용가능합니다. 즉, 사용자 정의 사전으로 명사를 추출할 수도 있습니다. 그리고 이런 일련의 작업들이 병렬로 처리됩니다.","code":"president_speech %>%   select(title, doc) %>%    filter(row_number() <= 2) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     type = \"noun2\"   )  [38;5;246m# A tibble: 264 × 2 [39m   title                              noun_bigram    [3m [38;5;246m<chr> [39m [23m                               [3m [38;5;246m<chr> [39m [23m        [38;5;250m1 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m 일:우정      [38;5;250m2 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m 우정:해      [38;5;250m3 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m 해:개막식    [38;5;250m4 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m 개막식:축하  [38;5;246m# ℹ 260 more rows [39m president_speech %>%   select(title, doc) %>%    filter(row_number() <= 2) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     drop = FALSE   )     [38;5;246m# A tibble: 209 × 3 [39m   title                              doc                             noun_bigram    [3m [38;5;246m<chr> [39m [23m                               [3m [38;5;246m<chr> [39m [23m                            [3m [38;5;246m<chr> [39m [23m        [38;5;250m1 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m  [38;5;246m\" [39m  먼저 한,일 우정의 해 개막식을 축하합니다. 이 … 우정:해      [38;5;250m2 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m  [38;5;246m\" [39m  먼저 한,일 우정의 해 개막식을 축하합니다. 이 … 해:개막식    [38;5;250m3 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m  [38;5;246m\" [39m  먼저 한,일 우정의 해 개막식을 축하합니다. 이 … 개막식:축하  [38;5;250m4 [39m  [38;5;246m\" [39m2005 한일 우정의 해 개막식 축사  [38;5;246m\" [39m  [38;5;246m\" [39m  먼저 한,일 우정의 해 개막식을 축하합니다. 이 … 축하:행사    [38;5;246m# ℹ 205 more rows [39m # grouping using group_by() function president_speech %>%   filter(row_number() <= 4) %>%   mutate(speech_year = substr(date, 1, 4)) %>%    select(speech_year, title, doc) %>%    group_by(speech_year) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\"   )  [38;5;246m# A tibble: 1,759 × 2 [39m  [38;5;246m# Groups:   speech_year [2] [39m   speech_year noun_bigram    [3m [38;5;246m<chr> [39m [23m        [3m [38;5;246m<chr> [39m [23m        [38;5;250m1 [39m 2005        우정:해      [38;5;250m2 [39m 2005        해:개막식    [38;5;250m3 [39m 2005        개막식:축하  [38;5;250m4 [39m 2005        축하:행사    [38;5;246m# ℹ 1,755 more rows [39m # grouping using collapse argument president_speech %>%   filter(row_number() <= 4) %>%   mutate(speech_year = substr(date, 1, 4)) %>%    select(speech_year, title, doc) %>%    unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     collapse = \"speech_year\"   )  [38;5;246m# A tibble: 1,759 × 2 [39m   speech_year noun_bigram    [3m [38;5;246m<chr> [39m [23m        [3m [38;5;246m<chr> [39m [23m        [38;5;250m1 [39m 2005        우정:해      [38;5;250m2 [39m 2005        해:개막식    [38;5;250m3 [39m 2005        개막식:축하  [38;5;250m4 [39m 2005        축하:행사    [38;5;246m# ℹ 1,755 more rows [39m args(unnest_noun_ngrams) function (tbl, output, input, n = 2L, n_min = n, ngram_delim = \" \",      drop = TRUE, collapse = NULL, ...)  NULL"},{"path":"https://r2bit.com/bitNLP/dev/articles/with_tidytext.html","id":"향후-일정","dir":"Articles","previous_headings":"","what":"향후 일정","title":"Collaboration with tidytext package","text":"앞으로도 bitNLP 패키지는 tidytext와의 협업을 모토로, tidytext에서 사용할 수 있는 유용한 기능을 추가해 나갈 것입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Choonghyun Ryu. Author, maintainer.","code":""},{"path":"https://r2bit.com/bitNLP/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ryu C (2025). bitNLP: Tools NLP Text Analytics. R package version 1.4.4.9000, https://r2bit.com/bitNLP/.","code":"@Manual{,   title = {bitNLP: Tools for NLP and Text Analytics},   author = {Choonghyun Ryu},   year = {2025},   note = {R package version 1.4.4.9000},   url = {https://r2bit.com/bitNLP/}, }"},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"bitnlp-개요","dir":"","previous_headings":"","what":"bitNLP 개요","title":"Tools for NLP and Text Analytics","text":"bitNLP는 텍스트 데이터를 탐색(Explore Documents)하고, 자연어 처리(Natural Language Processing) 및 형태소분석, 감성분석을 수행하는, 한글 텍스트 데이터 분석 도구들의 모음입니다. bitNLP의 다음 기능은 bitNLP 패키지의 비네트인 Introduce bitNLP에 소개되어 있습니다. 텍스트 데이터 전처리 기능 텍스트 데이터 탐색 기능 형태소분석 기능 감성분석 기능 형태소 사전 관리 기능","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"bitnlp-패키지-설치하기","dir":"","previous_headings":"bitNLP 설치","what":"bitNLP 패키지 설치하기","title":"Tools for NLP and Text Analytics","text":"Github 리파지토리에서 배포하는 패키지를 다음과 같이 설치합니다.","code":"remotes::install_github(\"bit2r/bitNLP\")"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"관련-리소스-설치하기","dir":"","previous_headings":"bitNLP 설치","what":"관련 리소스 설치하기","title":"Tools for NLP and Text Analytics","text":"bitNLP를 사용하기 위해서는 다음의 두 리소스를 설치해야 합니다. mecab-ko 혹은 mecab-ko-msvc mecab-ko-dic R에서 mecab-ko 연동을 위한 R 패키지 은전한닢 형태소분석기 시스템과 사전은 bitNLP 패키지의 비네트인 Install mecab-ko에 설명되어 있습니다. 사전에 설치해야 하는 리소스는 다음의 순서와 방법대로 설치하는 것을 추천합니다. 은전한닢 형태소분석기 시스템과 사전 RcppMeCab 패키지 설치","code":"library(\"bitNLP\")  install_mecab_ko() install.packages(\"RcppMeCab\")"},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"한글-자동-띄어쓰기","dir":"","previous_headings":"bitNLP 사용하기","what":"한글 자동 띄어쓰기","title":"Tools for NLP and Text Analytics","text":"한글 문장을 띄어쓰기 규칙에 맞게 자동으로 띄어쓰기 보정","code":"library(bitNLP)  get_spacing(\"최근음성인식정확도가높아짐에따라많은음성데이터가텍스트로변환되고분석되기시작했는데,이를위해잘동작하는띄어쓰기엔진은거의필수적인게되어버렸다\") #> [1] \"최근 음성 인식 정확도가 높아 짐에 따라 많은 음성 데이터가 텍스트로 변환되고 분석되기 시작했는데, 이를 위해 잘 동작하는 띄어쓰기 엔진은 거의 필수적인 게 되어 버렸다\" str <- \"글쓰기에서맞춤법과띄어쓰기를올바르게하는것은좋은글이될수있는요건중하나이다.하지만요즘학생들은부족한어문규정지식으로인해맞춤법과띄어쓰기에서많은오류를범하기도한다.본연구는그중띄어쓰기가글을인식하는데중요한역할을하는것으로판단하여,대학생들이띄어쓰기에대해서어느정도정확하게인식하고있는지,실제오류실태는어떠한지에대해살펴서그오류를개선할수있는교육방안을마련할필요가있다고판단하였다.\" get_spacing(str) #> [1] \"글쓰기에서 맞춤법과 띄어쓰기를 올바르게 하는 것은 좋은 글이 될 수 있는 요건 중 하나이다. 하지만 요즘 학생들은 부족한 어문 규정 지식으로 인해 맞춤법과 띄어쓰기에서 많은 오류를 범하기도 한다. 본 연구는 그 중 띄어쓰기가 글을 인식하는 데 중요한 역할을 하는 것으로 판단하여, 대학생들이 띄어쓰기에 대해서 어느 정도 정확하게 인식하고 있는지, 실제 오류 실태는 어떠한지에 대해 살펴서 그 오류를 개선할 수 있는 교육 방안을 마련할 필요가 있다고 판단하였다.\""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"형태소-분석","dir":"","previous_headings":"bitNLP 사용하기","what":"형태소 분석","title":"Tools for NLP and Text Analytics","text":"은전한닢 형태소 분석기를 호출하여 형태소 분석을 수행합니다. bitNLP는 이 형태소분석을 쉽고 효과적으로 수행하는 것을 도와줍니다. 형태소분석은 비네트인 Morphological Analysis에 설명되어 있습니다. 한글 텍스트에서는 명사만으로 문맥을 파악하는 것이 유용합니다. morpho_mecab() 함수의 기본 인수는 이를 지원합니다. morpho_mecab()는 여러 개의 문서를 하나로 합쳐서 토크나이즈할 수도 있습니다.","code":"docs <- c(\"님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.\",           \"푸른 산빛을 깨치고 단풍나무 숲을 향하여 난 작은 길을 걸어서, 차마 떨치고 갔습니다.\") morpho_mecab(docs,  type = \"morpheme\") #> [[1]] #>      NNG       JX    VV+EP       EF       SF       IC       SC      NNG  #>     \"님\"     \"은\"     \"갔\" \"습니다\"      \".\"   \"아아\"      \",\"   \"사랑\"  #>      XSV      ETM       NP      JKG      NNG       JX    VV+EP       EF  #>     \"하\"     \"는\"     \"나\"     \"의\"     \"님\"     \"은\"     \"갔\" \"습니다\"  #>       SF  #>      \".\"  #>  #> [[2]] #>     VA+ETM        NNG        NNG        JKO         VV         EC        NNG  #>     \"푸른\"       \"산\"       \"빛\"       \"을\"     \"깨치\"       \"고\" \"단풍나무\"  #>        NNG        JKO         VV         EC      NP+JX         VA        ETM  #>       \"숲\"       \"을\"     \"향하\"       \"여\"       \"난\"       \"작\"       \"은\"  #>        NNG        JKO      VV+EC         SC        MAG         VV         EC  #>       \"길\"       \"을\"   \"걸어서\"        \",\"     \"차마\"     \"떨치\"       \"고\"  #>      VV+EP         EF         SF  #>       \"갔\"   \"습니다\"        \".\" morpho_mecab(docs) #> [[1]] #>    NNG    NNG    NNG  #>   \"님\" \"사랑\"   \"님\"  #>  #> [[2]] #>        NNG        NNG        NNG        NNG        NNG  #>       \"산\"       \"빛\" \"단풍나무\"       \"숲\"       \"길\" morpho_mecab(docs, indiv = FALSE) #>        NNG        NNG        NNG        NNG        NNG        NNG        NNG  #>       \"님\"     \"사랑\"       \"님\"       \"산\"       \"빛\" \"단풍나무\"       \"숲\"  #>        NNG  #>       \"길\""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"품사의-워드클라우드-그리기","dir":"","previous_headings":"bitNLP 사용하기 > 형태소 분석","what":"품사의 워드클라우드 그리기","title":"Tools for NLP and Text Analytics","text":"명사를 추출하여 워드클라우드를 그려봅니다. bitNLP에 수록된 대통령 연설문 데이터셋인 president_speech에서 임의의 연설문 100개에서 일반명사를 추출 후 워드클라우드를 그려 봅니다.","code":"library(dplyr)  president_speech$doc[1:100] %>%    morpho_mecab(indiv = FALSE) %>%    table() %>%    wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"텍스트-데이터-탐색","dir":"","previous_headings":"bitNLP 사용하기","what":"텍스트 데이터 탐색","title":"Tools for NLP and Text Analytics","text":"텍스트 데이터 탐색 기능은 비네트인 Explore Documents에 설명되어 있습니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"text-data-explorer","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 탐색","what":"Text Data Explorer","title":"Tools for NLP and Text Analytics","text":"텍스트 데이터 탐색 기능은 Text Data Explorer라는 이름의 Shiny 앱이 제공합니다. 그리고 그 기능은 다음과 같습니다. 데이터 구조 파악하기 데이터 탐색과 정제하기 패턴검색과 문자열 대체 형태소분석을 이용한 데이터 탐색 공동발생분석을 이용한 데이터 탐색 n-grams를 이용한 데이터 탐색 R 명령어 실행","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"text-data-explorer-예시-화면","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 탐색","what":"Text Data Explorer 예시 화면","title":"Tools for NLP and Text Analytics","text":"Text Data Explorer 기능 중에서 탐색 및 치환 기능 화면에 대한 예시는 다음과 같습니다.: 탐색 및 치환 기능 화면","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"tidytext와의-협업","dir":"","previous_headings":"bitNLP 사용하기","what":"tidytext와의 협업","title":"Tools for NLP and Text Analytics","text":"tidytext 패키지와의 협업을 위한 기능은 비네트인 Collaboration tidytext package에 설명되어 있습니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"tokenizers","dir":"","previous_headings":"bitNLP 사용하기 > tidytext와의 협업","what":"tokenizers","title":"Tools for NLP and Text Analytics","text":"bitNLP는 토크나이저로 다음과 같은 함수를 지원합니다. morpho_mecab() part--speech tagger 단위의 토크나이저 tokenize_noun_ngrams()","code":"docs <- c(\"님은 갔습니다. 아아, 사랑하는 나의 님은 갔습니다.\",           \"푸른 산빛을 깨치고 단풍나무 숲을 향하여 난 작은 길을 걸어서, 차마 떨치고 갔습니다.\")  tokenize_noun_ngrams(docs) #> [[1]] #> [1] \"님 사랑\" \"사랑 님\" #>  #> [[2]] #> [1] \"산 빛\"       \"빛 단풍나무\" \"단풍나무 숲\" \"숲 길\"  # simplify = TRUE tokenize_noun_ngrams(docs[1], simplify = TRUE) #> [1] \"님 사랑\" \"사랑 님\"  str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\"  tokenize_noun_ngrams(str) #> [[1]] #> [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" #> [7] \"자유 이용\" \"이용 구매\"  # 불용어 처리 tokenize_noun_ngrams(str, stopwords = \"구매\") #> [[1]] #> [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" #> [7] \"자유 이용\"   # 사용자 정의 사전 사용 dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\") tokenize_noun_ngrams(str, simplify = TRUE, user_dic = dic_file) #> [1] \"신혼부부 주말부부\" \"주말부부 놀이\"     \"놀이 공원\"         #> [4] \"공원 자유이용권\"   \"자유이용권 구매\"  # n_min tokenize_noun_ngrams(str, n_min = 1, user_dic = dic_file) #> [[1]] #>  [1] \"신혼부부\"          \"신혼부부 주말부부\" \"주말부부\"          #>  [4] \"주말부부 놀이\"     \"놀이\"              \"놀이 공원\"         #>  [7] \"공원\"              \"공원 자유이용권\"   \"자유이용권\"        #> [10] \"자유이용권 구매\"   \"구매\"  # ngram_delim tokenize_noun_ngrams(str, ngram_delim = \":\", user_dic = dic_file) #> [[1]] #> [1] \"신혼부부:주말부부\" \"주말부부:놀이\"     \"놀이:공원\"         #> [4] \"공원:자유이용권\"   \"자유이용권:구매\"  # bi-grams tokenize_noun_ngrams(str, n = 2, ngram_delim = \":\", user_dic = dic_file) #> [[1]] #> [1] \"신혼부부:주말부부\" \"주말부부:놀이\"     \"놀이:공원\"         #> [4] \"공원:자유이용권\"   \"자유이용권:구매\""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"한글-unnest_tokens","dir":"","previous_headings":"bitNLP 사용하기 > tidytext와의 협업","what":"한글 unnest_tokens","title":"Tools for NLP and Text Analytics","text":"bitNLP의 한글 unnest_tokens에는 명사 n-grams 토크나이즈를 지원하는 unnest_noun_ngrams() 함수가 있습니다. 이 함수는 tidytext 패키지의 unnest_tokens 함수군의 사용법과 거의 동일합니다.","code":"library(dplyr)  president_speech %>%   select(title, doc) %>%    filter(row_number() <= 2) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     type = \"noun2\"   ) #> # A tibble: 264 × 2 #>    title                              noun_bigram #>    <chr>                              <chr>       #>  1 \"2005 한일 우정의 해 개막식 축사 \" 일:우정     #>  2 \"2005 한일 우정의 해 개막식 축사 \" 우정:해     #>  3 \"2005 한일 우정의 해 개막식 축사 \" 해:개막식   #>  4 \"2005 한일 우정의 해 개막식 축사 \" 개막식:축하 #>  5 \"2005 한일 우정의 해 개막식 축사 \" 축하:행사   #>  6 \"2005 한일 우정의 해 개막식 축사 \" 행사:축하   #>  7 \"2005 한일 우정의 해 개막식 축사 \" 축하:참석   #>  8 \"2005 한일 우정의 해 개막식 축사 \" 참석:여러분 #>  9 \"2005 한일 우정의 해 개막식 축사 \" 여러분:모두 #> 10 \"2005 한일 우정의 해 개막식 축사 \" 모두:환영   #> # ℹ 254 more rows"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"텍스트-데이터-정제","dir":"","previous_headings":"bitNLP 사용하기","what":"텍스트 데이터 정제","title":"Tools for NLP and Text Analytics","text":"텍스트 데이터 정제를 위한 텍스트 데이터 조작은 비네트인 Manipulate Documents에 설명되어 있습니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"텍스트-데이터-정제를-위한-bitnlp의-기능","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 정제","what":"텍스트 데이터 정제를 위한 bitNLP의 기능","title":"Tools for NLP and Text Analytics","text":"bitNLP의 텍스트 데이터 조작 기능을 정리하면 다음과 같습니다. 문서 필터링 (Filter Documents) 텍스트 대체 (Replace Texts) 텍스트 연결 (Concatenate Texts) 텍스트 분리 (Split Texts) 텍스트 제거 (Remove Texts) bitNLP는 대용량의 텍스트 데이터에서 상기 데이터 조작을 수행할 수 있도록 도와줍니다. 그래서 다음과 같은 방법으로 작업합니다. 병렬 처리를 통한 속도의 개선 데이터 조작 룰을 등록한 메타(meta) 파일 활용 본 소개글에서는 문서 필터링에 대한 사례만 소개합니다. 다른 텍스트 조작은 비네트를 참고하십시요.","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"filter_text를-이용한-문서-필터링","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 정제","what":"filter_text()를 이용한 문서 필터링","title":"Tools for NLP and Text Analytics","text":"bitNLP 패키지는 샘플 메타 데이터 파일을 제공하는데, 문서 필터링을 위한 샘플 메타 데이터 파일을 읽어 봅니다. get_meta() 함수는 세션 안에서 등록된 메타 데이터를 조회합니다. 텍스트 데이터(문서들) 중에서 분석을 수행하려는 목적과 부합하지 않은 텍스트(문서)를 제거해야할 경우에는 filter_text()를 사용합니다. 이미 앞에서 문서 필터링을 위한 메타 데이터 파일을 읽어들였습니다. 6개의 룰은 accept 값이 FALSE인 deny 룰입니다. 즉 해당 검색 패턴을 만족하는 텍스트 데이터를 제거하는 작업을 수행합니다.","code":"library(bitNLP)  meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_filter.csv\")  ## 데이터 필터링 메타 신규 등록 set_meta(\"filter\", fname, fileEncoding = \"utf8\") ## 기 등록된 데이터 필터링 메타 조회 get_meta(\"filter\") #>    rule_nm #> 1 신문기사 #> 2 제품홍보 #> 3 설문조사 #> 4     출처 #> 5   이벤트 #> 6     방송 #>                                                                                     pattern #> 1                                   (팍스넷|파이낸셜|연합|(PT)|오마이|경제)[[:space:]]*뉴스 #> 2 ((입법|정치|교육)[[:space:]]*플랫폼)|맘마미아[[:space:]]*가계부[[:print:]]*인증샷|Playtex #> 3                                                              좌담회|구글설문|채용대행업체 #> 4                                                    출처[[:space:]]*:|문의처보건복지콜센터 #> 5                                     (증정|기념)이벤트|허니스크린|이벤트를[[:space:]]*진행 #> 6                                 제작진|기억저장소|추모카페|블랙홀|푸드스튜디오|연금정보넷 #>   accept  use #> 1  FALSE TRUE #> 2  FALSE TRUE #> 3  FALSE TRUE #> 4  FALSE TRUE #> 5  FALSE TRUE #> 6  FALSE TRUE"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"문자-벡터의-필터링","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 정제","what":"문자 벡터의 필터링","title":"Tools for NLP and Text Analytics","text":"버즈 데이터의 본문은 길이가 1000인 문자 벡터입니다. 이 벡터는 5개의 결측치를 포함하고 있습니다. 8개의 코어를 이용해서 필터링을 수행합니다. as_logical = FALSE을 지정하면 문자 벡터의 필터링을 수행할 수 있습니다. 5개의 결측치와 6개의 룰에서 10개의 문서가 제거되어서 길이가 985인 문자 벡터가 만들어졌습니다.","code":"doc_content <- buzz$CONTENT is.character(doc_content) #> [1] TRUE length(doc_content) #> [1] 1000  sum(is.na(doc_content)) #> [1] 5 doc_after_character <- filter_text(doc_content, as_logical = FALSE, mc.cores = 8) #> ── rejects: 방송 ──────────────────────────────────────────────────────── 3건 ── #> ── rejects: 설문조사 ──────────────────────────────────────────────────── 1건 ── #> ── rejects: 신문기사 ──────────────────────────────────────────────────── 1건 ── #> ── rejects: 이벤트 ────────────────────────────────────────────────────── 1건 ── #> ── rejects: 제품홍보 ──────────────────────────────────────────────────── 2건 ── #> ── rejects: 출처 ──────────────────────────────────────────────────────── 2건 ── #> ── Missing Check: Removing NA ─────────────────────────────────────────── 5건 ──  length(doc_after_character) #> [1] 985"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"데이터-프레임의-필터링","dir":"","previous_headings":"bitNLP 사용하기 > 텍스트 데이터 정제","what":"데이터 프레임의 필터링","title":"Tools for NLP and Text Analytics","text":"tidytext 패키지를 이용해서 텍스트 데이터 분석을 수행한다면, 문자 벡터의 필터링이 아니라 문자 변수를 이용한 필터링을 수행해야 합니다. 다음처럼 as_logical 인수의 기본값인 TRUE를 사용합니다. 이 경우는 CONTENT 변수의 모든 원소에 대해서 allow 필터링 여부를 의미하는 논리 벡터를 만들어 반환합니다. 그러므로 dplyr 패키지의 filter 함수와 사용하여 필터링합니다.","code":"library(dplyr)  buzz %>%    filter(filter_text(CONTENT, verbos = FALSE)) %>%    select(KEYWORD, SRC, CONTENT) #> # A tibble: 985 × 3 #>    KEYWORD SRC              CONTENT                                              #>    <chr>   <chr>            <chr>                                                #>  1 맞벌이  17,18년 베이비맘 \"지금 둘째 임신중인 어머니예요 첫째는 16년 1월생 둘째출산예정은 17년 3월생 어쩌다 보… #>  2 맞벌이  20대 수다방      \"저희 부부는 맞벌이인데요 남편 회사 사람들도 거의 다 맞벌이인가봐요 그래도 아침마다 아내분… #>  3 맞벌이  20대 수다방      \"신랑지출 제지출 구분해서 따로적으시나요 제가쓴돈은 알아도 신랑이쓴돈은 잘몰라 어떻게 적어야… #>  4 맞벌이  20대 수다방      \"너무 고민이 되서 하소연 할때 없어서 여기서 하소연 해봐요 글이좀 길수가 있어요 양해 부탁… #>  5 맞벌이  20대 수다방      \"\\\"이제 벌써 결혼 1년차 가까이 되어가는 동갑내기신혼부부입니다 허허다름이 아니라 얼마전 … #>  6 맞벌이  20대 수다방      \"자가는 아니고 신랑 직장때문에 집 팔고 세들어 살고 있는데요1층이라서 좋을줄만 알았는데 위… #>  7 맞벌이  20대 수다방      \"계획했던 임신이 아니라서 급하게 맞벌이 (주말부부)접고 군인신랑따라 철원가려구요 돈 직장보… #>  8 맞벌이  20대 수다방      \"못가지니까 기분이 안좋아요 다른것도아니고 여유가 안되서 못갖는다는게첫째낳고친정부모님들은 맞… #>  9 맞벌이  20대 수다방      \"남편이랑 저랑 동갑에 둘 다 맞벌이에요. 저는 현재 임신 8주구요. 제가 요리를 넘넘 못해… #> 10 맞벌이  20대 수다방      \"요즘 퇴근하고 남편이 데리러 오는데요 살빼려고 하는데 맨날 저녁 먹고 들어가서점점찌고 있습… #> # ℹ 975 more rows"},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"고마운-분들","dir":"","previous_headings":"","what":"고마운 분들","title":"Tools for NLP and Text Analytics","text":"bitNLP는 다음 오픈소스 기여자의 리소스를 사용하거나 참조하였습니다.: 은전한닢 프로젝트 RcppMeCab RmecabKo mecab-ko-msvc","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"도움요청","dir":"","previous_headings":"","what":"도움요청","title":"Tools for NLP and Text Analytics","text":"bitNLP의 발전을 위해서 버그에 대한 리포팅, 기능 개선을 위한 요구사항들은 여기에에 문제를 제기하거나 요청해주세요. 특히 버그는 최소한의 재현 가능한 예제와 함께 제출바랍니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/index.html","id":"기여자-행동-강령","dir":"","previous_headings":"","what":"기여자 행동 강령","title":"Tools for NLP and Text Analytics","text":"이 프로젝트는 Contributor Code Conduct(기여자 행동 강령)과 함께 릴리스되었습니다 . 이 프로젝트에 참여함으로써 귀하는 해당 조건을 준수하는 데 동의하는 것입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/add_sysdic.html","id":null,"dir":"Reference","previous_headings":"","what":"Add user-defined dictionary files to system dictionary. — add_sysdic","title":"Add user-defined dictionary files to system dictionary. — add_sysdic","text":"사용자가 정의한 사용자 정의 사전 파일을 시스템 사전에 추가","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/add_sysdic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add user-defined dictionary files to system dictionary. — add_sysdic","text":"","code":"add_sysdic()"},{"path":"https://r2bit.com/bitNLP/dev/reference/add_sysdic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add user-defined dictionary files to system dictionary. — add_sysdic","text":"사용자 사전정의 디렉토리에 있는 모든 사용자정의 사전 파일을 시스템 사전에 추가한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/add_sysdic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add user-defined dictionary files to system dictionary. — add_sysdic","text":"","code":"if (FALSE) { # \\dontrun{ add_sysdic() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Write to the user-defined noun dictionary file. — append_userdic_meta","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"사용자 명사 사전에 등록하기 위해 인명/지명을 인명/지명/고유명사/일반명사 사전 파일에 추가","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"","code":"append_userdic_meta(   term,   type = NULL,   prototype = NULL,   noun_type = c(\"person\", \"place\", \"nnp\", \"nng\"),   dic_type = c(\"sysdic\", \"userdic\"),   userdic_path = NULL )"},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"term character. mecab-ko 사전에 등록할 이름들. mecab-ko-dic 품사 태그 설명에서 '표층형', '읽기'에 적용됨 type character. mecab-ko 사전에 등록할 타입들. mecab-ko-dic 품사 태그 설명에서 '타입'에 적용됨. prototype character. mecab-ko 사전에 등록할 원형들. mecab-ko-dic 품사 태그 설명에서 '표현'에 적용됨. noun_type character. 인명사전과 지명사전, 고유명사, 일반명사 사전에서 등록할 사용자 정의 명사 사전 선택. dic_type character. 생성할 사용자 정의 사전을 시스템사전에 빌드할 지, 사용자 사전으로 빌드할 지의 선택. 기본값은 \"sysdic\"으로 시스템사전에 빌드할 목적으로 작업함. userdic_path character. 사용자 정의 명사 사전 파일이 존재하는 경로. 지정하지 않으면 사전이 설치된 기본 경로에서 파일을 읽어온다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"사용자 사전정의 디렉토리의 person.csv/place.csv/nnp.csv/nng.csv 파일에 등록할 인명/지명/고유명사/일반명사를 추가한다. mecab-ko-dic 품사 태그 설명에서 '타입'은 두 개 이상의 토큰으로 구성된 복합명사일 때만 사용하며, 'Compound', 'Preanalysis', 'Inflected' 중에 하나를 기술하는데 의미는 다음과 같음.: Compound : 가장 흔한 사례의 복합명사로 개별 토큰의 의미가 합쳐져서도 의미가 유지되는 사례 예) 주말부부: 주말/NNG + 부부/NNG Preanalysis : 개별 토큰의 의미가 합쳐지면서 의미가 상실되는 사례 예) 인터파크: 인터/NNG + 파크/NNG Inflected : 토큰이 합쳐질 때, 개별 토큰에 변형이 일어나는 경우로 복합명사에서는 거의 발생하지 않음","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"mecab-ko-dic 품사 태그 설명. <https://docs.google.com/spreadsheets/d/1-9blXKjtjeKZqsf4NzHeYJCrr49-nXeRF6D80udfcwY/edit#gid=1718487366>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/append_userdic_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write to the user-defined noun dictionary file. — append_userdic_meta","text":"","code":"if (FALSE) { # \\dontrun{ # 인명 사전 get_userdic_meta() append_userdic_meta(c(\"변학도\"))  # 지명 사전 get_userdic_meta(\"place\") append_userdic_meta(c(\"영귀미면\"), noun_type = \"place\") get_userdic_meta(\"place\")  # 고유명사 사전   get_userdic_meta(\"nnp\") append_userdic_meta(c(\"릴리움\", \"인터파크\"), c(\"*\", \"Preanalysis\"),                      c(\"*\", \"인터/NNG/*+파크/NNG/*\"), noun_type = \"nnp\") get_userdic_meta(\"nnp\")  # 일반명사 사전을 사용자 사전에 빌드할 목적으로 등록함   get_userdic_meta(\"nng\", dic_type = \"userdic\") append_userdic_meta(c(\"주말부부\", \"쿼토\"), c(\"Compound\", \"*\"),                      c(\"주말/NNG/*+부부/NNG/*\", \"*\"),                      noun_type = \"nng\",                     dic_type = \"userdic\") get_userdic_meta(\"nng\") } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/bitNLP-package.html","id":null,"dir":"Reference","previous_headings":"","what":"3rd party package of Bit2R with Text Analytics function — bitNLP-package","title":"3rd party package of Bit2R with Text Analytics function — bitNLP-package","text":"자연어 처리(Natural Language Processing), 텍스트 분석 모델 및 텍스트 분석을 위한 시각화와 도구 모음.","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/reference/bitNLP-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"3rd party package of Bit2R with Text Analytics function — bitNLP-package","text":"유충현 Maintainer: 유충현 <choonghyun.ryu@gmail.com>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/buzz.html","id":null,"dir":"Reference","previous_headings":"","what":"Naver Cafe Post Scraping Data — buzz","title":"Naver Cafe Post Scraping Data — buzz","text":"네이버 카페의 게시판에 올라온 포스트를 맞벌이, 워킹맘 등의 몇몇 키워드로 스크랩핑한 데이터","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/buzz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naver Cafe Post Scraping Data — buzz","text":"","code":"data(buzz)"},{"path":"https://r2bit.com/bitNLP/dev/reference/buzz.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Naver Cafe Post Scraping Data — buzz","text":"13개의 변수와 1,000개의 관측치로 구성된 데이터 프레임.: KEYWORD character. 컨텐츠 키워드 SRC character. 컨텐츠 등록 메뉴 SECTION character. 컨텐츠 섹션 CRAWL_DT character. 크롤링 일시 PUBLISH_DT character. 컨텐츠 등록 일자 URL character. 컨텐츠 URL TITLE character. 컨텐츠 제목 CONTENT character. 컨텐츠 내용 DOC_KEY character. 컨텐츠 키 PUBLISH_ID character. 컨텐츠 등록자 아이디 CLICK_CNT integer. 클릭 건수 LIKE_CNT integer. 좋아요 건수 SEARCH_KEYWORD character. 검색 키워드 영문","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/buzz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Naver Cafe Post Scraping Data — buzz","text":"","code":"if (FALSE) { # \\dontrun{ data(buzz)  head(buzz) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/coll_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate t-score and mutual information score — coll_scores","title":"Calculate t-score and mutual information score — coll_scores","text":"공동발생 분석을 위한 공동발생 단어에 대한 t-score, MI(mutual information)-score 계산","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/coll_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate t-score and mutual information score — coll_scores","text":"","code":"coll_scores(x, node, span = 3)"},{"path":"https://r2bit.com/bitNLP/dev/reference/coll_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate t-score and mutual information score — coll_scores","text":"x data.frame. \"collocate()\"를 수행한 공동발생(co-occurrences) 분석결과 node character. 공동발생 분석 단어(term) span integer. 공동발생 window 단위. 기본값은 3.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/coll_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate t-score and mutual information score — coll_scores","text":"data.frame. 공동발생 정보와 T-score, MI-score를 담은 data.frame","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/coll_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate t-score and mutual information score — coll_scores","text":"","code":"# \\donttest{ docs <- president_speech$doc[1]  # default arguments collocate(docs, \"우정\", type = \"morpheme\") #>          Term Before After Span Total #> 1           ,      1     0    1    10 #> 2          같      1     0    1     1 #> 3      개막식      0     1    1     1 #> 4        국민      1     0    1     5 #> 5        따뜻      1     1    2     2 #> 6          불      0     2    2     2 #> 7        사이      1     0    1     3 #> 8        성공      0     1    1     2 #> 9        시킬      0     1    1     1 #> 10       양국      1     0    1     8 #> 11         에      1     0    1     8 #> 12         와      1     0    1     4 #> 13       으로      0     1    1     5 #> 14         은      1     0    1     9 #> 15         을      0     3    3    13 #> 16     을수록      1     0    1     1 #> 17         의      2     3    5    12 #> 18         일      1     0    1     5 #> 19         하      0     1    1    16 #> 20         한      2     0    2     7 #> 21         해      0     1    1     5 #> 22       우정     NA    NA    5     5 #> 23 [[TOKENS]]     15    15   30   617  # change span argument tab_colloc <- collocate(docs, \"우정\", type = \"morpheme\")  coll_scores(tab_colloc, \"우정\", span = 2) #>          Term Before After Span Total         T        MI #> 1           ,      1     0    1    10 0.6758509 1.6252705 #> 2          같      1     0    1     1 0.9675851 4.9471986 #> 3      개막식      0     1    1     1 0.9675851 4.9471986 #> 4        국민      1     0    1     5 0.8379254 2.6252705 #> 5        따뜻      1     1    2     2 1.3683720 4.9471986 #> 6          불      0     2    2     2 1.3683720 4.9471986 #> 7        사이      1     0    1     3 0.9027553 3.3622361 #> 8        성공      0     1    1     2 0.9351702 3.9471986 #> 9        시킬      0     1    1     1 0.9675851 4.9471986 #> 10       양국      1     0    1     8 0.7406807 1.9471986 #> 11         에      1     0    1     8 0.7406807 1.9471986 #> 12         와      1     0    1     4 0.8703404 2.9471986 #> 13       으로      0     1    1     5 0.8379254 2.6252705 #> 14         은      1     0    1     9 0.7082658 1.7772736 #> 15         을      0     3    3    13 1.4887590 2.8317214 #> 16     을수록      1     0    1     1 0.9675851 4.9471986 #> 17         의      2     3    5    12 2.0621113 3.6841642 #> 18         일      1     0    1     5 0.8379254 2.6252705 #> 19         하      0     1    1    16 0.4813614 0.9471986 #> 20         한      2     0    2     7 1.2537679 3.1398437 #> 21         해      0     1    1     5 0.8379254 2.6252705 #> 22       우정     NA    NA    5     5        NA        NA #> 23 [[TOKENS]]     15    15   30   617        NA        NA  # change span argument tab_colloc <- collocate(docs, \"우정\", type = \"morpheme\")  coll_scores(tab_colloc, \"국민\", span = 2) #>          Term Before After Span Total         T        MI #> 1           ,      1     0    1    10 0.6758509 1.6252705 #> 2          같      1     0    1     1 0.9675851 4.9471986 #> 3      개막식      0     1    1     1 0.9675851 4.9471986 #> 4        국민      1     0    1     5        NA        NA #> 5        따뜻      1     1    2     2 1.3683720 4.9471986 #> 6          불      0     2    2     2 1.3683720 4.9471986 #> 7        사이      1     0    1     3 0.9027553 3.3622361 #> 8        성공      0     1    1     2 0.9351702 3.9471986 #> 9        시킬      0     1    1     1 0.9675851 4.9471986 #> 10       양국      1     0    1     8 0.7406807 1.9471986 #> 11         에      1     0    1     8 0.7406807 1.9471986 #> 12         와      1     0    1     4 0.8703404 2.9471986 #> 13       으로      0     1    1     5 0.8379254 2.6252705 #> 14         은      1     0    1     9 0.7082658 1.7772736 #> 15         을      0     3    3    13 1.4887590 2.8317214 #> 16     을수록      1     0    1     1 0.9675851 4.9471986 #> 17         의      2     3    5    12 2.0621113 3.6841642 #> 18         일      1     0    1     5 0.8379254 2.6252705 #> 19         하      0     1    1    16 0.4813614 0.9471986 #> 20         한      2     0    2     7 1.2537679 3.1398437 #> 21         해      0     1    1     5 0.8379254 2.6252705 #> 22       우정     NA    NA    5     5 2.1635860 4.9471986 #> 23 [[TOKENS]]     15    15   30   617        NA        NA # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Collapsed Noun — collapse_noun","title":"Extract Collapsed Noun — collapse_noun","text":"텍스트 문서에서 명사들을 토큰화한 후, 토큰화된 명사들을 공백으로 묶어서 텍스트 문서를 만듦 조회한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Collapsed Noun — collapse_noun","text":"","code":"collapse_noun(   doc,   user_dic = NULL,   type = c(\"noun\", \"noun2\"),   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores() )"},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Collapsed Noun — collapse_noun","text":"doc character. 명사로만 구성될 문서를 만들 대상 텍스트 데이터 user_dic mecab-ko 형태소 분석기의 사용자 정의 사전 파일. 기본값은 NULL로 사용자 사전파일을 지정하지 않음. 시스템 사전인 \"/usr/local/lib/mecab/dic/mecab-ko-dic\"(Linux, Mac)를 보완하여 사용됨. 사용자 사전 파일은 mecab-dict-index 명령어로 생성되며, 확장자가 \"dic\"임. type character. 토큰화할 명사의 유형을 지정. \"noun\", \"noun2\"중에서 선택. 기본값은 \"noun\"로 일반명사를 의미하며, \"noun2\"는 모든 명사를 의미함. chunk integer. 병렬 작업 수행 시 처리 단위인 chunk mc.cores integer. 병렬 작업 수행 시 사용할 코어의 개수","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Collapsed Noun — collapse_noun","text":"character. 명사로만 구성된 텍스트","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Collapsed Noun — collapse_noun","text":"MS-Windows에서는 병렬처리를 지원하지 않음","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collapse_noun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Collapsed Noun — collapse_noun","text":"","code":"# \\donttest{ collapse_noun(president_speech$doc[1:7]) #> [1] \"우정 해 개막식 축하 행사 축하 참석 모두 환영 감사 인사 전 이웃 옛날 이웃 이웃 사정 통신사 절 시절 연락선 시대 항공기 하루 안 시대 교통 발달 통신 관계 경제 교류 말 협력 국음 마음 실행 가공 과학 기술 옛날 사이 불편 문제 생각 상황 양국 관계 불편 생존 자체 위협 사이 유감 친구 방법 관계 숙명 친구 관계 친구 친구 미래 적극 친구 손 불행 평화 번영 미래 관계 자리 양국 관계 도로 표현 전 경제 도로는 고속도 수준 정치 안보 측면 협력 도로 개통 문화 도로 길 길 위 장애물 양국 협력 관계 고속 도로 장애물 직시 양국 정부 국민 적극 노력 가슴 우정 불 자리 우정 불 양국 국민 사이 우정 계기 이틀 전 주최 행사 성공 성원 참석 격려 총리 국민 자리 감사 올해 양국 수교 해 일 양국 우정 성공 때 보람 생각 올해 이전 양국 국민 교류 국민 교류 해 감사\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #> [2] \"각하 국민 신년 인사 새해 축복 해 기원 올해 양국 관계 발전 전기 중 교류 해 경제 학술 문화 체육 청소년 분야 행사 본격 국민 교류 협력 시대 나라 교역 상대국 투자 대상 국 한국인 방문 서로 문화 이웃 양국 우호 협력 올해 교류 행사 강화 각하 합의 전면 협력 동반자 관계 심화 평화 공동 번영 미래 기대 각하 건강 무궁 발전 기원\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  #> [3] \"존경 국민 오늘 사흘 방문 취임 전후 긴박 상황 생각 정세 관계 정상 회담 변화 사실 다행 오늘 참여 정부 대북 정책 성원 국민 진심 감사 국민 이번 정상 회담 실용 회담 정상 회담 관계 길 이번 회담 길 장애물 지체 발걸음 재촉 회담 의제 논의 평화 정착 경제 발전 실질 구체 진전 주력 비핵화 문제 평화 체제 궁극 합의 해결 일 기본 방향 설정 속도 남 북 의지 중요 생각 이번 회담 자 회담 성공 촉진 평화 기여 회담 최선 경제 협력 진전 장애 국제 요인 인식 차이 기인 장애 장애 극복 본격 경제 협력 속도 인식 차이 극복 노력 집중 군사 신뢰 구축 인도 문제 구체 합의 최대한 노력 국민 이번 회담 국민 요구 기대 국민 전문가 제안 의제 부처 제안 의제 정상 회담 추진 위원회 검토 의제 의제 국민 기대 최대한 의제 반영 결과 심정 만남 과제 소화 임기 고려 이번 회담 논의 성사 일 한계 시기 걸음 걸음 중요 생각 욕심 몸 금기 두지 역사 책임 몫 시기 상황 냉정 판단 토대 책임 최선 합의 설득 설득 타협 타협 합의 상호 인식 차이 신뢰 중요 성과 확신 틀 생각 남 북 길 국민 북녘 땅 출발 이틀 후 결과 성원 당부 감사\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         #> [4] \"마중 감사 시간 도착 저녁 임기 얼마 처지 약속 얼마 임기 안 마무리 다음 정부 고심 생각 시기 중요 시기 시기 일 다음 정부 지금 기회 일 시간 뒤 생각 반대 대신 문제 해결 문제 해결 주문 주문 주문 소화 걱정 반영 노력 일거리 걸음 일 성사 걱정 발걸음 보따리 만남 자체 의미 이해 욕심 자락 준비 보따리 보자기 일거리 길 보자기 성과 보자기 짐 성과 생각 국민 성원 덕분 조언 제안 논거 준비 성과 생각 사람 참모 일 성과 점 조언 물론 성원 국민 감사 감사 해외 때 때 연설 박수 환영 박수 부담 생각 습관 이번 북녘 동포 환영 처음 부담 거리 표정 부담 남녘 사람 북녘 사람 자유 소망 가슴 위원장 처음 위원장 회담 잠 느낌 사고방식 차이 벽 합의 눈앞 느낌 기대 통일부 장관 북측 회담 위로 본시 군기 처음 군기 말 기세 싸움 뜻 국방 위원장 그때 실망 용기 격려 기대 오전 오후 말씀 말 통 불만 마음 핵 문제 비핵화 합의 기본 원칙 합의 핵 문제 국제 문제 실질 구체 문제 자회 담 핵 문제 해결 말 문제 해결 타작마당 타작마당 벌 얘기 부담 생각 얘기 확인 회담 분위기 부담 보도 비핵화 기존 합의 확인 자 회담 장 지금 앞 협의 협력 공동 명과 합의 이행 말 핵 폐기 자회 담 정리 위원장 핵 문제 공동 명과 합의 이행 점 비핵화 공동 선언 중요 선언 앞 원칙 확인 점 확인 최고 지도자 핵 폐기 의지 이행 문제 생각 자회 담 북측 표현 상당 양보 평가 정상 회담 시점 정상 회담 성공 협력 점 정상 회담 자 회담 진전 기여 북측 성 노력 감사 회담 도중 위원장 자 회담 북측 수석대표 외무성 부상 회담장 공동 성명 합의 경과 설명 구체 보고 자 회담 진행 장애 핵 문제 확신 핵 문제 평화 체제 정부 방침 평화 체제 종전 협정 평화 협정 순서 동시 절차 문제 관련 앞 원칙 주도 관련 당사국 평화 체제 협의 협력 당사자 협의 시작 협의 각국 제안 기본 합의 과정 일환 대통령 제안 종전 선언 방안 위원장 설명 위원장 종전 체제 평화 체제 전환 기본 동의 뜻 이전 한미 논의 종전 선언 방 안 구체 관심 표명 성사 남측 노력 주문 추진 취지 선언문 표현 앞 당사국 대화 문제 북측 용의 점 평화 정착 경제 협력 확대 협력 질서 구축 미 일 관계 개선 필요 점 강조 협력 제안 점 위원장 합의 말 합의 사항 점 중요 차례 강조 말씀 위원장 경청 앞 핵 문제 해결 관계 개선 평화 체제 논의 본격 분단 반세기 냉전 체제 굴레 평화 시대 기대 판단 군사 긴장 완화 분쟁 문제 대화 협상 해결 합의 전쟁 반대 불가침 의무 준수 뜻 서해 평화 정착 군사 대결 관점 경제 협력 관점 서해 문제 발상 전환 필요 점 강조 서해 공 동어 구역 해 상평 공원 해주 공단 개발 개성 공단 연결 하구 공동 이용 대결 상태 해소 평화 구축 경제 협력 포괄 해결 방안 평화 협력 특별 지대 방안 제의 위원장 참모 상 다음 제안 원칙 수용 의사 정상 선언 포함 설명 이번 공동 선언 핵심 진전 합의 부분 평화 협력 특별 지대 합의 남 우발 충돌 방지 공동 어로수역 지정 수역 평화 수역 방안 협력 사업 군사 보장 조치 문제 군사 신뢰 구축 조치 협의 금년 국방 장관 회담 개최 합의 다음 경제 협력 말씀 이번 회담 경제 협력 준비 실질 회담 시간 할애 대화 논의 개성 공단 개발 그동안 진전 북측 입장 부담 불편 점 불만 점 위원장 경협 일방 양측 모두 필요 경제 협력 중요 문제 점 강조 기업 대북 투자 희망 기업 얘기 경제 협력 일방 지원 머리 회담 방향 대화 때 북측 자존심 일 문제 공동 이익 남측 기대 사람 강조 얘기 점 이해 동안 개성 공단 지역 성공 이외 지역 경협 실패 지지부진 점 설명 장애 요인 해소 기업 안심 투자 안정 기업 활동 체제 중요 점 강조 경협 장애 요인 해결 시간 절차 해결 개성 공단 개발 방식 법 제도 인프라 문제 일괄 해결 제안 강조 기업 원활 경영 활동 기술 이전 경협 지속 발전 사람 사람 소통 중요 합의 사항 예측 가능 점 강조 기업 시장 경제 원칙 아래 활동 제도 장치 마련 당국 합의 경협 사업 군사 보장 점 강조 기업 관계 상황 변화 핵 문제 해결 미 관계 개선 국제 관계 안정 관리 점 강조 토대 위 상호 보완 공동 번영 구상 준비 경제 협력 체계 미래 지향 방향 발전 제안 이번 회담 위원장 대화 앞 경협 발전 필요 과제 인식 공감대 다행 일 생각 실질 문제 합의 말씀 평화 협력 특별 지대 개발 평화 정착 도움 어민 기업 직접 혜택 평화 번영 프로젝트 해주 지역 특별 지대 설정 개성 관계 관계 경제 시너지 효과 생각 밖 논의 각종 경협 사업 정상 합의 이례 구체 합의 성과 생각 구체 합의 끝 앞 총체 문제 경제 협력 합의 사항 이행 문제 해결 부총리 급 공동 위원회 운영 합의 실무 선 해결 문제 문제 제기 해결 해결 문제 해결 기구 생각 사업 제안 합의 계속 토대 생각 이번 합의 경협 수준 차원 중소기업 기회 제공 경제 활동 영역 계기 생각 취임사 평화 번영 평화 번영 얘기 평화 문제 일반 경제 번영 문제 경제 구조 조정 문제 사이 어려움 경제 활로 계기 말 이번 기틀 생각 북방 경제 얘기 얘기 주장 불안감 이번 합의 기초 앞 협력 관계 속 발전 북방 경제 말 이름 앞 이름 경제 계기 생각 경제 협력 평화 구축 평화 경제 협력 뒷받침 선 순환 구조 생각 경제 상생 경제 실현 평화 번영 시대 디딤돌 기대 화해 통일 문제 대화 분야 양측 제기 사항 정치 분야 사실 화해 단계 과거 자유 말 이산가족 국군 포로 문제 근본 해결 제의 이산가족 문제 문제 점 강조 위원장 공감 이산가족 상봉 확대 영상 편지 교환 사업 추진 면회소 완공 쌍방 대표 상주 이산가족 상봉 상시 진행 합의 문제 양측 입장 차이 국민 기대 성과 합의 대화 다음 문제 밑거름 바람 이번 해결 국민 생각 앞 기회 대화 기회 문제 해결 노력 민족 역사 우수 문화 역사 언어 교육 문화 예술 체육 사회 문화 분야 교류 협력 발전 경기 대회 응원단 경의선 열차 이용 참가 정상 회담 개최 정상 회담 정례 제안 국가 정상 선례 문제 때 관계 발전 정상 현안 문제 협의 정도 합의 요구 회담 안정 운영 그동안 장관 급 운영 대화 총괄 창구 총리 급 격상 회의 금년 위원장 답방 요청 위원장 최고 민회 상임 위원장 방문 제안 본인 방문 여건 성숙 때 말 통일 문제 기본 공동 선언 정리 평가 이념 추상 논의 현실 실질 접근 문제 인식 이번 합의 내용 진전 정상 결국 통일 과정 방향 논의 논의 과정 여론 조사 결과 예 국민 동서 독과 통일 상호 공존공영 점진 통일 접근 인식 점 설명 회담 때 문제 거론 외세 공조 민족 공조 문제 쟁점 정부 자주 정부 점 설명 자주 수준 그동안 노력 설명 자주 강조 나라 대화 협력 필요 때 항의 항의 수용 전 과정 배제 고립 점 설명 앞 발전 고립 세계 적극 자주 수준 수준 문제 제안 점 위원장 이해 동행 특별 수행원 단상 분야 북측 간담회 대화 대화 소통 유익 짐작 국민 관계 단계 진입 평화 체제 전환 제도 노력 군사 긴장 완화 실질 노력 시작 경협 전체 무대 발전 경제 공동체 건설 걸음 모두 국민 성원 덕분 생각 감사 말씀 동안 관계 역사 때 합의 중요 합의 실천 일 중요 생각 앞 정부 이번 합의 충실 이행 북측 최선 예정 총리 급 회담 국방 장관 회담 구체 이행 방안 마련 이후 이행 과정 준비 과정 마찬가지 국민 의견 수렴 투명 진행 이번 합의 사항 특정 정당 후보 불리 유리 생각 문제 합의 찬성 불리 합의 반대 불리 일 합의 자체 유리 불리 합의 태도 후보 전략 자체 유리 불리 합의 유리 불리 생각 긴박 주변 정세 변화 정부 시기 역사 과업 수행 생각 합의 기본 합의서 공동 선언 합의 내용 실천 과정 이상 생각 참여 정부 임기 얼마 합의 내용 구체 실천 기본 토대 마련 최선 생각 다음 정부 부담 공동 선언 다음 정부 관계 평화 공동 번영 토대 일 생각 확신 임기 동안 최선 노력 설명 알맹이 느낌 생각 알맹이 선언문 선언문 내용 설명 배경 설명 보고 껍데기 느낌 지금 공동 선언문 보따리 확인 남측 경제 북측 경제 공업 지대 중요 생각 조선업 돌파구 계기 공업 전후방 연관 효과 생각 중요 생각 개수 북측 부담 점 생각 공세 요구 무리 생각 앞 총리 회담 부총리 급 경제 협력 위원회 논의 생각 얘기 선언문 말씀 선언문 생각 배경 설명 국민 감사 자리 격려 감사\" #> [5] \"존경 민간 자문 위원회 위원장 비즈니스 투자 정상 회의 조직 위원장 자리 경제 지도자 안녕 자리 초대 감사 자리 기업 인간 교류 협력 증진 세계 경제 역내 기업 협력 시점 회의 회의 역내 기업 인간 유대 서로 지혜 기회 세계 경제 활력 계기 기대 존경 참석자 각국 지도자 중반 창설 결속 이후 무역 투자 자유 정책 역동 성장 지속 지역 세계 개도국 모범 모델 제시 결실 언어 문화 경제 발전 단계 차이 극복 성취 역내 경제 통합 회원국 단계 자유 무역 지대 실현 계획 작년 말 관세 인하 목표 달성 역내 완전 무관세 목표 매진 이번 비즈니스 투자 정상 회의 그동안 성장 통합 결실 민간 부문 확산 중요 계기 확신 경제 지도자 국가 세계사 소용돌이 경험 우의 협력 역사 대전 이후 식민주의 항거 독립 역사 공유 독립 후 반세기 지속 냉전 체제 강대국 틈바구니 자존 번영 추구 시기 경험 분단 전쟁 고통 때 나라 물심 양면 국제 무대 적극 지원 후반 경제 위기 풍파 극복 국민 친구 우정 간 나라 산업 연수생 협력 증진 체류 산업 연수생 절반 가까이 국가 젊은이 경제 도움 해당 국과 이해 증진 기여 정부 외국인 근로자 처우 개선 인권 보호 노력 올해 말 외국인 고용 허가 법 제정 외국인 근로자 취업 기간 동안 내국인 동등 대우 제도 보장 제도 아래 인 교류 산업 인력 협력 활성 희망 경제 발전 경험 국가 자체 추진 통합 지원 노력 지속 정보 경험 성과 공유 역내 정보 격차 해소 지원 정부 앞 연간 규모 개발 협력 단 파견 예정 내년 규모 개발 협력 단 국가 중심 파견 젊은이 자국 미래 지원 세기 서로 중요 교역 투자 파트너 교역 규모 지난해 기록 서로 교역 상대국 올해 상반기 지역 투자 전체 투자 유입 액 차지 계 상호 보완 협력 분야 지난해 관광객 국가 방문 정도 국민 지역 정도 결과 만족 지금 신뢰 협력 바탕 관계 세기 포괄 동반자 관계 발전 존경 참석자 오늘 내일 국가 지도자 비전 논의 토대 중 장기 협력 방안 구체 그동안 정치 외교 분야 진행 협의 채널 경제 통상 분야 확대 구체 내년 간 경제 장관 회의 고위 경제 관리 회의 신설 정례 무역 투자 활성 미래 지향 경제 협력 관계 발전 중심 통합 움직임 적극 동참 개최 정상 회의 추진 방 안 구상 계획 경제 통합 인근 국가 포괄 경제 협력 관계 구축 노력 주목 동안 전체 협력 통합 노력 비전 그룹 연구 그룹 제안 그룹 수년 동안 참여 협조 아래 성공 연구 진행 연구 그룹 지역 정체 공동체 의식 협력 조치 권고 협력 조치 포럼 개최 예정 자리 역내 회원국 산 관 학 대표 참석 평화 번영 진보 협력 방안 논의 노력 통합 기여 전체 결속 강화 이바지 재무 장관 회의 추진 역내 금융 협력 적극 참여 세기 성장 산업 분야 협력 방안 적극 모색 존경 경제 지도자 지역 지정학 위치 기반 지역 협력 확대 적극 기여 나라 개방 경제 중심 도약 장기 목표 적극 역할 기여 전체 공동 번영 도모 계획 목표 경제 투명 공정 효율 시장 경제 시스템 기업 회계 지배 구조 금융 노사 관계 경제 전 분야 글로벌 스탠더드 개선 국제공항 인프라 확충 교류 확대 기여 인근 지역 자유 비즈니스 활동 가능 경제 자유 지역 조성 계획 궁극 목표 세계 나라 투자 나라 강조 동북 아만 중심 지역 협력 추구 지역 역할 증대 동시 국가 협력 강화 전체 번영 결속 기여 존경 경제 지도자 핵 문제 걱정 압 군사 긴장 대립 전체 안정 번영 장애물 핵 문제 평화 해결 남북한 평화 체제 정착 평화 번영 필수 요소 핵 문제 해결 평화 해결 다행 자 회담 성사 핵 문제 평화 해결 길 장래 회담 결과 기대 핵 포기 경우 국제 사회 협력 개혁 개방 길 필요 지원 핵 문제 평화 해결 노력 경제 지도자 지속 관심 성원 당부 존경 지역 경제 지도자 앞 세기 도전 기회 교차 제국주의 시대 냉전 시기 억압 대결 역사 종언 지역 세계 경제 축 부상 지역 발전 가능 협력 여지 곳 도전 심화 경쟁 구도 속 번영 역내 협력 강화 지역 개방 협력 질서 진전 토대 지역 협력 강화 실질 주역 기업 오늘 만남 계기 각국 경제 계간 협력 활성 노력 힘 노력 회원국 세계 경제 성장 견인차 세기 시대 경청 감사\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #> [6] \"존경 배리 반부 패국 제회 의장 국제 투명 기구 회장 반 부패 분야 지도자 전문가 외귀 반 부패 국제 회의 개막 축 국제기구 세계 참가자 진심 환영 반 부패 국제 회의 동안 반 부패 국제 협력 노력 세계 최대 반 부패 분야 민 관 연대 회의 성장 회의 국민 모두 기쁨 이번 행사 수고 관계자 감사 말씀 회의 국제 투명 기구 경의 표 국제 청렴 부패 발취 재상 수상 축하 인사 외귀 간 양 성장 서구 선진국 산업 반세기 분단 전쟁 폐허 위 양속 성장 부작용 정경 유착 관치 금융 초래 부패 문제 대표 예 외환 위기 국민 양 성장 투명 공정성 확립 과제 변화 추구 출범 참여 정부 지속 개혁 질 성장 토대 구축 원칙 신뢰 공정 투명 대화 타협 분권 자율 문화 사회 구석구석 목표 출발점 시대 잘못 관행 정상 중요 부패 척결 투명 증진 참여 정부 부패 사회 실현 주요 국정 과제 정부 노력 이유 정치 변화 시작 대통령 선거 역대 선거 공정 정치 변화 시대 대세 자리 시장 개혁 투명 공정 경쟁 보장 시장 핵심 각종 제도 관행 글로벌 스탠더드 개선 부패 빌미 제공 필요 규제 철폐 행정 투명 청렴 과제 추진 전자 정부 구현 공직자 자발 개혁 참여 투명 정부 원동력 회의 온라인 민원 처리 시스템 부패 방지 우수 사례 발표 정부 반 부패 국제 협력 적극 동참 국제 투명 기구 활동 협력 존경 참석자 이번 회의 경험 지혜 투명 사회 노력 힘 지구촌 후손 부패 미래 견인차 역할 토론 결과 경청 이번 회의 부패 문제 해결 투명 증진 방향 제시 자리 부패 사회 국민 노력 확인 기회 기대 신록 동안 보람 여정 감사\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                #> [7] \"존경 트 총리 총리 사무총장 국제기구 각국 대표 지역 총회 개회 축 국제기구 참석자 진심 환영 태 총회 간 노동자 인권 보호 권익 신장 기여 공헌 감사 회의 생각 이번 회의 주관 관계자 모두 감사 말씀 내외 귀빈 세계 지식 정보 진전 개인 국가 혜택 개방 경쟁 촉진 무역 자유 가속 부 창출 원천 정보 통신 기술 발달 지역 통합 강화 국가 상호 의존 협력 필요 환경 인권 지구 문제 해결 긍정 영향 태 지역 무역 자유 회원국 경제 성장 국민 후생 증진 기여 평가 경제 전망 보고서 지난해 성장 기록 세계 경제 선도 역사 문화 인 자원 잠재력 발휘 앞 비약 발전 참석자 세계 성과 주목 점 혜택 공평 배분 경제 주체 경쟁력 차이 지역 국가 계층 격차 경제 양극 현상 현상 가속 장기 성장 잠재력 노동 시장 구조 양극 심화 근로자 소득 격차 빈곤층 증대 사회 갈등 지속 가능 성장 부정 영향 태지 역도 양극 도전 직면 실업 고용 성장 지속 청년 실업 문제 이상 실업 배 실정 일자리 부족 근로 취약 계층 고용 안정 근로 조건 일 문제 하루 소득 미만 근로 빈곤층 세계 차지 점 양질 일자리 창출 주제 이번 총회 의미 서로 경험 지혜 방안 제시 기대 내외 귀빈 외환 위기 극복 최근 성장 계속 시장 경쟁 심화 경제 주체 지식 정보 격차 확대 기업 중소기업 정규직 비정규직 소득 계층 격차 격차 심화 소비 위축 내수 시장 침체 투자 감소 양질 일자리 축소 비정규직 근로자 확대 악순환 문제 해결 핵심 일자리 일자리 근본 양극 극복 대책 일자리 일자리 질 일자리 중소기업 활성 정책 역량 집중 중소기업 협력 관계 구축 혁신 중소기업 육성 금융 지원 체계 개편 중소기업 정책 근본 혁신 고용 창출 효과 서비스 산업 다양 고급 고학력 청년 실업 문제 해결 금융 법률 회계 컨설팅 지식 기반 서비스 산업 적극 육성 국민 삶 질 직결 보건 복지 교육 문화 사회 서비스 일자리 지난해 고용 지원 서비스 직업 능력 개발 결합 선진 고용 정망 구축 국가 전략 과제 선정 집중 투자 일 사람 능력 개발 기회 각자 일자리 제공 일 능력 사람 필요 사회 안전망 기능 강화 사회 보장 예산 배 이상 노인 저소득층 복지 증진 비정규직 영세자 영업자 사회 보험 혜택 확대 정책 추진 국제 기준 부합 노사 관계 선진 방안 추진 비정규직 근로자 장애 여성 취약 계층 차별 시정 노력 정부 정책 한계 기업 장기 안목 경영 전략 사람 노동조합 비정규직 노동자 전체 관점 생각 양보 양보 대화 타협 합의 생산 합의 내용 책임 실천 일자리 존경 참석자 인력 자본 자유 세계 시대 일자리 문제 나라 문제 국가 협력 관련 국제기구 전략 파트너 강화 필요 이번 총회 계기 기대 동안 보람 시간 감사\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          # Collaboration with tidytext library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  nho_noun <- president_speech %>%   filter(president %in% \"노무현\") %>%   filter(stringr::str_detect(category, \"^외교\")) %>%   mutate(doc_noun = collapse_noun(doc)) %>%     tidytext::unnest_ngrams(       noun_bigram,       doc_noun,       n = 2    ) nho_noun #> # A tibble: 44,117 × 8 #>    id       president category  type  title              date  doc   noun_bigram #>    <chr>    <chr>     <chr>     <chr> <chr>              <chr> <chr> <chr>       #>  1 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 우정 해     #>  2 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 해 개막식   #>  3 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 개막식 축하 #>  4 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 축하 행사   #>  5 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 행사 축하   #>  6 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 축하 참석   #>  7 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 참석 모두   #>  8 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 모두 환영   #>  9 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 환영 감사   #> 10 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막… 2005… \"  먼… 감사 인사   #> # ℹ 44,107 more rows   nho_noun$noun_bigram[1:5] #> [1] \"우정 해\"     \"해 개막식\"   \"개막식 축하\" \"축하 행사\"   \"행사 축하\"   # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/collocate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate table for co-occurrence analysis — collocate","title":"Calculate table for co-occurrence analysis — collocate","text":"공동발생 분석을 위한 공동발생 단어 추출 및 해당 단어의 공동발생 빈도 및 문서에서의 발생 빈도 정보 생성","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collocate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate table for co-occurrence analysis — collocate","text":"","code":"collocate(   x,   node,   span = 3,   type = c(\"noun\", \"noun2\", \"verb\", \"adj\", \"morpheme\") )"},{"path":"https://r2bit.com/bitNLP/dev/reference/collocate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate table for co-occurrence analysis — collocate","text":"x character. 공동발생(co-occurrences) 분석에 사용할 document. node character. 공동발생 분석 단어(term) span integer. 공동발생 window 단위. 기본값은 3. type character. 공동발생에 사용할 단어를 생성하는 방법으로서의 형태소 분석의 결과 유형. 모든 품사, 명사, 동사 및 형용사와 같은 토큰화 결과 유형을 지정.  \"morpheme\", \"noun\", \"noun2\", \"verb\", \"adj\"중에서 선택. 기본값은 \"noun\"로  일반명사만 추출함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collocate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate table for co-occurrence analysis — collocate","text":"data.frame. 공동발생 정보를 담은 data.frame","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/collocate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate table for co-occurrence analysis — collocate","text":"","code":"# \\donttest{ docs <- president_speech$doc[1]  # default arguments collocate(docs, \"우정\") #>          Term Before After Span Total #> 1        가슴      1     0    1     1 #> 2      개막식      0     1    1     1 #> 3        계기      0     1    1     1 #> 4        국민      1     1    2     5 #> 5        노력      1     0    1     1 #> 6          때      0     1    1     1 #> 7        보람      0     1    1     1 #> 8          불      1     2    3     2 #> 9        사이      1     0    1     3 #> 10       성공      0     1    1     2 #> 11       양국      2     1    3     8 #> 12       우정      1     1    2     5 #> 13       이틀      0     1    1     1 #> 14         일      1     0    1     1 #> 15       자리      1     1    2     3 #> 16       적극      1     0    1     2 #> 17         전      0     1    1     3 #> 18       축하      0     1    1     2 #> 19         해      1     1    2     3 #> 20       우정     NA    NA    5     5 #> 21 [[TOKENS]]     12    15   27   148  # change span argument collocate(docs, \"우정\", span = 4) #>          Term Before After Span Total #> 1        가슴      2     0    2     1 #> 2      개막식      0     1    1     1 #> 3        계기      0     1    1     1 #> 4        국민      2     1    3     5 #> 5        노력      1     0    1     1 #> 6          때      0     1    1     1 #> 7        보람      0     1    1     1 #> 8          불      2     3    5     2 #> 9        사이      1     1    2     3 #> 10       생각      0     1    1     2 #> 11       성공      0     1    1     2 #> 12       수교      1     0    1     1 #> 13       양국      2     1    3     8 #> 14       우정      1     1    2     5 #> 15       이틀      0     1    1     1 #> 16         일      1     0    1     1 #> 17       자리      1     1    2     3 #> 18       적극      1     0    1     2 #> 19         전      0     1    1     3 #> 20       주최      0     1    1     1 #> 21       축하      0     1    1     2 #> 22         해      1     1    2     3 #> 23       행사      0     1    1     2 #> 24       우정     NA    NA    5     5 #> 25 [[TOKENS]]     16    20   36   148  # change type argument collocate(docs, \"우정\", type = \"morpheme\") #>          Term Before After Span Total #> 1           ,      1     0    1    10 #> 2          같      1     0    1     1 #> 3      개막식      0     1    1     1 #> 4        국민      1     0    1     5 #> 5        따뜻      1     1    2     2 #> 6          불      0     2    2     2 #> 7        사이      1     0    1     3 #> 8        성공      0     1    1     2 #> 9        시킬      0     1    1     1 #> 10       양국      1     0    1     8 #> 11         에      1     0    1     8 #> 12         와      1     0    1     4 #> 13       으로      0     1    1     5 #> 14         은      1     0    1     9 #> 15         을      0     3    3    13 #> 16     을수록      1     0    1     1 #> 17         의      2     3    5    12 #> 18         일      1     0    1     5 #> 19         하      0     1    1    16 #> 20         한      2     0    2     7 #> 21         해      0     1    1     5 #> 22       우정     NA    NA    5     5 #> 23 [[TOKENS]]     15    15   30   617 # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/create_userdic.html","id":null,"dir":"Reference","previous_headings":"","what":"create user dictionary with user-defined dictionary files. — create_userdic","title":"create user dictionary with user-defined dictionary files. — create_userdic","text":"사용자가 정의한 사용자 정의 사전 파일을 사용자 사전으로 생성","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/create_userdic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create user dictionary with user-defined dictionary files. — create_userdic","text":"","code":"create_userdic(userdic_path = \"./user_dic\", dic_file = \"user-dic.dic\")"},{"path":"https://r2bit.com/bitNLP/dev/reference/create_userdic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create user dictionary with user-defined dictionary files. — create_userdic","text":"userdic_path character. 사용자 정의 명사 사전 파일이 존재하는 경로. 지정하지 않으면 \"./user_dic\"이라는 이름의 경로를 사용함. dic_file character. 생성할 사용자 사전 파일 이름. 지정하지 않으면 \"user-dic.dic\"이라는 이름으로 생성함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/create_userdic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"create user dictionary with user-defined dictionary files. — create_userdic","text":"사용자 사전정의 디렉토리에 있는 모든 사용자정의 사전 파일을 엮어 사용자 사전에 추가한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/create_userdic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create user dictionary with user-defined dictionary files. — create_userdic","text":"","code":"if (FALSE) { # \\dontrun{ create_userdic() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/edit_termcost.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","title":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","text":"사용자 정의 사전 파일에서 낱말의 낱말비용을 수정","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/edit_termcost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","text":"","code":"edit_termcost(userdic_path = \"./user_dic\", dic_file = \"user-dic.dic\")"},{"path":"https://r2bit.com/bitNLP/dev/reference/edit_termcost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","text":"userdic_path character. 사용자 정의 사전 파일이 존재하는 경로. 지정하지 않으면 \"./user_dic\"이라는 이름의 경로를 사용함. dic_file character. 생성할 사용자 사전 파일 이름. 지정하지 않으면 \"user-dic.dic\"이라는 이름으로 생성함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/edit_termcost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","text":"사용자 사전정의 디렉토리에 있는 병합 사용자 사전 정의 파일의 낱말비용을 수정함. 대상 파일은 \"사용자 정의 사전 파일 경로/indexed/merged.csv\" 파일임. 그리고 낱말비용이 수정되면 수정된 낱말의 정보는 \"사용자 정의 사전 파일 경로/indexed/changed.csv\" 파일에 수정 이력이 저장됨. 이 정보는 사용자 사전 정의 파일을 재정의할 때 수정된 낱말비용 정보가 없어지는 매커니즘을 보완하기 위한 이력 파일임. 낱말비용이 수정되었다는 것 만으로 그 정보가 사전에 반영되는 것은 아님.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/edit_termcost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modify the word cost of a word in a dictionary definition file. — edit_termcost","text":"","code":"if (FALSE) { # \\dontrun{ edit_termcost() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/explore_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Text Data Explorer — explore_docs","title":"Text Data Explorer — explore_docs","text":"정규표현식 기반의 텍스트 데이터  탐색 작업을 위한 Shiny 앱 호출","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/explore_docs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text Data Explorer — explore_docs","text":"","code":"explore_docs()"},{"path":"https://r2bit.com/bitNLP/dev/reference/explore_docs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Text Data Explorer — explore_docs","text":"없음","code":""},{"path":[]},{"path":"https://r2bit.com/bitNLP/dev/reference/explore_docs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Text Data Explorer — explore_docs","text":"유충현 Maintainer: 유충현 <choonghyun.ryu@gmail.com>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/explore_docs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Text Data Explorer — explore_docs","text":"","code":"if (FALSE) { # \\dontrun{  library(bitNLP)   ## 텍스트 데이터 탐색기(Shiny Web Application) 호출  explore_docs() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter data based on string matches of text data — filter_text","title":"Filter data based on string matches of text data — filter_text","text":"텍스트 데이터의 전처리 과정 중 패턴 일치되는 문자열이 있는 데이터를 취하거나 제거한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter data based on string matches of text data — filter_text","text":"","code":"filter_text(   doc,   as_logical = TRUE,   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores(),   verbos = TRUE )"},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter data based on string matches of text data — filter_text","text":"doc character. 문자열 필터링을 수행할 문자열 벡터 as_logical logical. 반환값을 논리벡터로 반환할지의 여부. 기본값 TRUE이면 추출한 대상을 의미하는 논리값을 반환하고, FALSE이면 대상을 추출한 문자열 벡터를 반환. tidytext 패키지를 사용할 경우에는 기본값인 TRUE를 사용하면 됨 chunk integer. 병렬 작업 수행 시 처리 단위인 chunk mc.cores integer. 병렬 작업 수행 시 사용할 코어의 개수 verbos logical. 메타의 Rule 당 처리된 건수를 화면에 출력할 지의 여부","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter data based on string matches of text data — filter_text","text":"character. 문자열 필터링이 수행된 문자열 벡터.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter data based on string matches of text data — filter_text","text":"Windows 운영체제에서는 병력작업이 지원되지 않기 때문에, 사용자의 설정과는 무관하게 mc.cores의 값이 1로 적용됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/filter_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter data based on string matches of text data — filter_text","text":"","code":"# \\donttest{ ##====================================================== ## 문자열 매치 데이터 필터링 ##======================================================  # 매치 데이터 필터링 메타 신규 등록 meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_filter.csv\") set_meta(\"filter\", fname, fileEncoding = \"utf8\")  # 등록된 필터링 룰 확인하기 get_meta(\"filter\") #>    rule_nm #> 1 신문기사 #> 2 제품홍보 #> 3 설문조사 #> 4     출처 #> 5   이벤트 #> 6     방송 #>                                                                                     pattern #> 1                                   (팍스넷|파이낸셜|연합|(PT)|오마이|경제)[[:space:]]*뉴스 #> 2 ((입법|정치|교육)[[:space:]]*플랫폼)|맘마미아[[:space:]]*가계부[[:print:]]*인증샷|Playtex #> 3                                                              좌담회|구글설문|채용대행업체 #> 4                                                    출처[[:space:]]*:|문의처보건복지콜센터 #> 5                                     (증정|기념)이벤트|허니스크린|이벤트를[[:space:]]*진행 #> 6                                 제작진|기억저장소|추모카페|블랙홀|푸드스튜디오|연금정보넷 #>   accept  use #> 1  FALSE TRUE #> 2  FALSE TRUE #> 3  FALSE TRUE #> 4  FALSE TRUE #> 5  FALSE TRUE #> 6  FALSE TRUE  doc_content <- buzz[, \"CONTENT\"]  # 필터링, verbos = FALSE, chunk = 200 doc_after_logical <- filter_text(doc_content, verbos = FALSE, chunk = 200)  # 필터링, as_logical = FALSE,  mc.cores = 8,  doc_after_character <- filter_text(doc_content, as_logical = FALSE, mc.cores = 8) #> ── rejects: 방송 ──────────────────────────────────────────────────────── 3건 ── #> ── rejects: 설문조사 ──────────────────────────────────────────────────── 1건 ── #> ── rejects: 신문기사 ──────────────────────────────────────────────────── 1건 ── #> ── rejects: 이벤트 ────────────────────────────────────────────────────── 1건 ── #> ── rejects: 제품홍보 ──────────────────────────────────────────────────── 2건 ── #> ── rejects: 출처 ──────────────────────────────────────────────────────── 2건 ── #> ── Missing Check: Removing NA ─────────────────────────────────────────── 5건 ──  # 필터링 전/후 비교 NROW(doc_content) #> [1] 1000 sum(doc_after_logical) #> [1] 985 NROW(doc_after_character) #> [1] 985  # tidyverse(혹은 tidytext)와의 협업 library(dplyr) buzz %>%    filter(filter_text(CONTENT, verbos = FALSE)) %>%    select(KEYWORD, SRC, CONTENT) #> # A tibble: 985 × 3 #>    KEYWORD SRC              CONTENT                                              #>    <chr>   <chr>            <chr>                                                #>  1 맞벌이  17,18년 베이비맘 \"지금 둘째 임신중인 어머니예요 첫째는 16년 1월생 둘째출산예정은 17년 3월생 어쩌다 보… #>  2 맞벌이  20대 수다방      \"저희 부부는 맞벌이인데요 남편 회사 사람들도 거의 다 맞벌이인가봐요 그래도 아침마다 아내분… #>  3 맞벌이  20대 수다방      \"신랑지출 제지출 구분해서 따로적으시나요 제가쓴돈은 알아도 신랑이쓴돈은 잘몰라 어떻게 적어야… #>  4 맞벌이  20대 수다방      \"너무 고민이 되서 하소연 할때 없어서 여기서 하소연 해봐요 글이좀 길수가 있어요 양해 부탁… #>  5 맞벌이  20대 수다방      \"\\\"이제 벌써 결혼 1년차 가까이 되어가는 동갑내기신혼부부입니다 허허다름이 아니라 얼마전 … #>  6 맞벌이  20대 수다방      \"자가는 아니고 신랑 직장때문에 집 팔고 세들어 살고 있는데요1층이라서 좋을줄만 알았는데 위… #>  7 맞벌이  20대 수다방      \"계획했던 임신이 아니라서 급하게 맞벌이 (주말부부)접고 군인신랑따라 철원가려구요 돈 직장보… #>  8 맞벌이  20대 수다방      \"못가지니까 기분이 안좋아요 다른것도아니고 여유가 안되서 못갖는다는게첫째낳고친정부모님들은 맞… #>  9 맞벌이  20대 수다방      \"남편이랑 저랑 동갑에 둘 다 맞벌이에요. 저는 현재 임신 8주구요. 제가 요리를 넘넘 못해… #> 10 맞벌이  20대 수다방      \"요즘 퇴근하고 남편이 데리러 오는데요 살빼려고 하는데 맨날 저녁 먹고 들어가서점점찌고 있습… #> # ℹ 975 more rows # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta information processing for text data pre-processing — get_meta","title":"Meta information processing for text data pre-processing — get_meta","text":"텍스트 데이터의 전처리 과정인 패턴 일치되는 데이터 삭제, 문자열 대체, 불필요 문자열 제거, 문자열 연결 등을 수행하기 위한 메타 정보를 등록하고 조회한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta information processing for text data pre-processing — get_meta","text":"","code":"get_meta(id = c(\"filter\", \"replace\", \"remove\", \"concat\", \"split\"))  set_meta(   id = c(\"filter\", \"replace\", \"remove\", \"concat\", \"split\"),   filename,   sep = \",\",   fileEncoding = \"utf-8\",   append = FALSE )"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta information processing for text data pre-processing — get_meta","text":"id character. 메타 정보의 아이디. filename character. 등록할 메타 정보가 포함된 파일의 이름 sep character. 메타 정보를 기술한 파일의 컬럼 구분자 fileEncoding character. 파일의 인코딩 append logical. 메타 정보의 추가 여부. TRUE이면, 기 등록 메타에 추가한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta information processing for text data pre-processing — get_meta","text":"data.frame 등록된 메타정보를 담은 data.frame","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta information processing for text data pre-processing — get_meta","text":"","code":"# \\donttest{ meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_filter.csv\")  ## 데이터 필터링 메타 신규 등록 set_meta(\"filter\", fname, fileEncoding = \"utf8\")  ## 기 등록된 데이터 필터링 메타 조회 get_meta(\"filter\") #>    rule_nm #> 1 신문기사 #> 2 제품홍보 #> 3 설문조사 #> 4     출처 #> 5   이벤트 #> 6     방송 #>                                                                                     pattern #> 1                                   (팍스넷|파이낸셜|연합|(PT)|오마이|경제)[[:space:]]*뉴스 #> 2 ((입법|정치|교육)[[:space:]]*플랫폼)|맘마미아[[:space:]]*가계부[[:print:]]*인증샷|Playtex #> 3                                                              좌담회|구글설문|채용대행업체 #> 4                                                    출처[[:space:]]*:|문의처보건복지콜센터 #> 5                                     (증정|기념)이벤트|허니스크린|이벤트를[[:space:]]*진행 #> 6                                 제작진|기억저장소|추모카페|블랙홀|푸드스튜디오|연금정보넷 #>   accept  use #> 1  FALSE TRUE #> 2  FALSE TRUE #> 3  FALSE TRUE #> 4  FALSE TRUE #> 5  FALSE TRUE #> 6  FALSE TRUE  ## 데이터 필터링 메타 추가 등록 #fname <- \"preparation_filter2.csv\" #set_meta(\"filter\", fname, fileEncoding = \"utf8\", append = TRUE) # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenization with N-gram — get_ngrams","title":"Tokenization with N-gram — get_ngrams","text":"n-gram 토큰화 및 n-gram 토큰화 집계.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenization with N-gram — get_ngrams","text":"","code":"get_ngrams(   x,   n = 2L,   token = c(\"noun\", \"noun2\", \"word\"),   type = c(\"raw\", \"table\"),   user_dic = NULL )"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenization with N-gram — get_ngrams","text":"x character. n-gram 토큰화에 사용할 document. n integer. n-gram 토큰화에서의 n. 기본값은 2. token character. n-gram 토큰화에서 토큰의 종류. \"noun\", \"noun2\", \"word\" 에서 선택. 기본값은 \"noun\"로 일반명사, \"noun2\"는 명사, \"word\"는 단어를 의미함. type character. 반환하는 결과물의 종류. \"raw\"는 토큰화된 n-gram 자체를 반환하며, \"table\"은 토큰화된 n-gram 집계 정보를 반환. user_dic mecab-ko 형태소 분석기의 사용자 정의 사전 파일. 기본값은 NULL로 사용자 사전파일을 지정하지 않음.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tokenization with N-gram — get_ngrams","text":"n-gram 토큰화된 character 벡터, 혹은 n-gram 집계 정보를 담은 데이터 프레임","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":"n-gram-","dir":"Reference","previous_headings":"","what":"n-gram 집계 정보","title":"Tokenization with N-gram — get_ngrams","text":"n-gram 집계 정보를 담은 데이터 프레임 변수는 다음과 같음.: ngrams : n-gram 토큰. character. freq : n-gram 토큰의 도수. integer. prop : n-gram 토큰의 상대도수. numeric.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tokenization with N-gram — get_ngrams","text":"","code":"# \\donttest{ str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\"  # bi-gram get_ngrams(str) #> [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" #> [7] \"자유 이용\" \"이용 구매\"  # tri-gram get_ngrams(str, n = 3) #> [1] \"신혼 부부 주말\" \"부부 주말 부부\" \"주말 부부 놀이\" \"부부 놀이 공원\" #> [5] \"놀이 공원 자유\" \"공원 자유 이용\" \"자유 이용 구매\"  # 워드(띄어쓰기) 기반 토큰화 get_ngrams(str, token = \"word\") #> Error: argument 'str' must be a non-empty vector of strings  # 집계정보 get_ngrams(str, type = \"table\") #>       ngrams freq  prop #> 1 부부 놀이     1 0.125 #> 2 신혼 부부     1 0.125 #> 3 주말 부부     1 0.125 #> 4 부부 주말     1 0.125 #> 5 놀이 공원     1 0.125 #> 6 이용 구매     1 0.125 #> 7 공원 자유     1 0.125 #> 8 자유 이용     1 0.125  # 사용자 정의 사전 사용 dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\") get_ngrams(str, user_dic = dic_file) #> [1] \"신혼부부 주말부부\" \"주말부부 놀이\"     \"놀이 공원\"         #> [4] \"공원 자유이용권\"   \"자유이용권 구매\"    # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_opinion.html","id":null,"dir":"Reference","previous_headings":"","what":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","title":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","text":"한국어 감정분석 코퍼스를 활용하여 문서의 감성분석 결과를 반환","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_opinion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","text":"","code":"get_opinion(doc, n = 1, agg = TRUE)"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_opinion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","text":"doc character. KOSAC를 이용해서 감성분석을 수행할 문자열 벡터 n integer. n-gram 토큰화 계수 agg logical. 집계 여부. TRUE이면 집계 결과만  반환하며, FALSE이면 문자열벡터도 함께 반환","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_opinion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","text":"data.frame 감성분석 결과를 담은 data.frame complex: numeric. 복합 negative: numeric. 부정 positive: numeric. 긍정 neutral: numeric. 중립 none: numeric. 해당없음 vote: character. 감성 투표 결과. \"POS\", \"NEG\" polarity: numeric. 극성 subjectivity: numeric. 주관성 (부정+긍정의 합) doc: character. 문서의 내용","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_opinion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KOSAC(Korean Sentiment Analysis Corpus) Sentiment Analysis — get_opinion","text":"","code":"# \\donttest{ get_opinion(buzz$CONTENT[1]) #>     complex  negative positive    neutral      none vote   polarity #> 1 0.0451915 0.4414439 0.331436 0.06717522 0.1147534  NEG -0.1423351 #>   subjectivity #> 1    0.7728799 # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for tokenizer plans based on word cost — get_plan_cost","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"낱말비용 기반의 토크나이저 플랜을 조회한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"","code":"get_plan_cost(x, topn = 3, dic_path = NULL, userdic = NULL)"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"x character. 플랜을 조회할 단어나 문장. topn integer. 플랜을 조회한 후 표시할 상위 저비용 플랜 개수. 기본값은 3임. dic_path character. mecab-ko-dic의 시스템 사전이 설치된 경로. userdic character. 사용자 사전. 경로와 이름을 기술함. 지정하지 않으면, bitNLP가 설치한 사전 경로를 사용한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"tbl_df. 플랜을 담은 tibble 객체.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"mecab-ko가 주어진 단어나 문장을 토크화(tokenization)하는 플랜을 조회한다. 이 기능을 통해서 사전에서의 단어 비용 조정과 신규 사용자 단어의 추가를 의사결정 할 수 있다. 우선 순위에 따른 10개의 플랜을 조회하며, 실제로 형태소분석기는 우선 순위가 1인 것으로 토큰화한다. 플랜 정보에서 변수는 다음과 같다.: \"우선순위\" : 토큰화 우선 순위. \"표층형\" : 토큰화되는 토큰 \"품사태그\" : 토큰의 품사. \"의미부류\" : 인명, 혹은 지명과 같은 의미. \"좌문맥ID\" : 좌문맥 ID. \"우문맥ID\" : 우문맥 ID. \"낱말비용\" : 가중치. 값은 낮을수록 가중치가 올라간다. \"연접비용\" : 좌측에 공백 문자를 포함하는 품사의 연접 비용. \"누적비용\" : 누적 낱말비용","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_plan_cost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for tokenizer plans based on word cost — get_plan_cost","text":"","code":"if (FALSE) { # \\dontrun{ get_plan_cost(\"가면무도회\") } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_polarity.html","id":null,"dir":"Reference","previous_headings":"","what":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","title":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","text":"군산대학교 한국어 감성 사전을 활용하여 문서의 감성분석 결과를 반환","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_polarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","text":"","code":"get_polarity(doc, n = 1, indiv = TRUE)"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_polarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","text":"doc character. 군산대학교 한국어 감성 사전을 이용해서 감성분석을 수행할 문자열 벡터 n integer. n-gram 토큰화 계수 indiv logical. 복수개의 문서일 때 개별 문서의 결과를 반환할 지를 선택함. TRUE이면 데이터프레임에서 개별 문서의 결과를 관측치(observations)로 반환하고, FALSE이면 하나의 관측치로 반환함. 기본값은 TRUE","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_polarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","text":"data.frame 감성분석 결과를 담은 data.frame n_match: numeric. 감성사전에 매치된 토큰 개수 n_negative: numeric. 감성사전의 부정 단어와 매치된 토큰 개수 n_positive: numeric. 감성사전의 긍정 단어와 매치된 토큰 개수 n_neutral: numeric. 감성사전의 중립 단어와 매치된 토큰 개수 negative: numeric. 감성사전의 부정 단어와 매치된 토큰의 점수의 합 positive: character. 감성사전의 긍정 단어와 매치된 토큰의 점수의 합 polarity: numeric. 감성의 극성. (positive - negative) / (positive + negative).","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_polarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KNU Korean Sentiment Dictionary Sentiment Analysis — get_polarity","text":"","code":"# \\donttest{ get_polarity(buzz$CONTENT[1]) #>   n_match n_negative n_positive n_neutral negative positive polarity #> 1       3          2          1         0        4        1     -0.6  # 개별 문서들의 감성분석 get_polarity(buzz$CONTENT[1:5]) #>   n_match n_negative n_positive n_neutral negative positive   polarity #> 1       3          2          1         0        4        1 -0.6000000 #> 2       0          0          0         0        0        0        NaN #> 3       3          2          1         0        2        1 -0.3333333 #> 4      21         17          2         2       31        2 -0.8787879 #> 5      11          6          5         0       12        5 -0.4117647  # 전체 문서를 통합한 감성분석 get_polarity(buzz$CONTENT[1:5], indiv = FALSE) #>   n_match n_negative n_positive n_neutral negative positive   polarity #> 1      38         27          9         2       49        9 -0.6896552 # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_spacing.html","id":null,"dir":"Reference","previous_headings":"","what":"Korean automatic spacing — get_spacing","title":"Korean automatic spacing — get_spacing","text":"한글 문장을 띄어쓰기 규칙에 맞게 자동으로 띄어쓰기 보정.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_spacing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Korean automatic spacing — get_spacing","text":"","code":"get_spacing(x, user_dic = NULL)"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_spacing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Korean automatic spacing — get_spacing","text":"x character. 띄어쓰기 보정에 사용할 document. user_dic mecab-ko 형태소 분석기의 사용자 정의 사전 파일. 기본값은 NULL로 사용자 사전파일을 지정하지 않음.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_spacing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Korean automatic spacing — get_spacing","text":"띄어쓰기 보정된 character 벡터.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_spacing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Korean automatic spacing — get_spacing","text":"","code":"# \\donttest{ # 한글 자동 띄어쓰기 get_spacing(\"최근음성인식정확도가높아짐에따라많은음성데이터가Text로변환되고분석되기시작했는데,이를위해잘동작하는띄어쓰기엔진은거의필수적인게되어버렸다\") #> [1] \"최근 음성 인식 정확도가 높아 짐에 따라 많은 음성 데이터가 Text로 변환되고 분석되기 시작했는데, 이를 위해 잘 동작하는 띄어쓰기 엔진은 거의 필수적인 게 되어 버렸다\"  str <- \"글쓰기에서맞춤법과띄어쓰기를올바르게하는것은좋은글이될수있는요건중하나이다.하지만요즘학생들은부족한어문규정지식으로인해맞춤법과띄어쓰기에서많은오류를범하기도한다.본연구는그중띄어쓰기가글을인식하는데중요한역할을하는것으로판단하여,대학생들이띄어쓰기에대해서어느정도정확하게인식하고있는지,실제오류실태는어떠한지에대해살펴서그오류를개선할수있는교육방안을마련할필요가있다고판단하였다.\" get_spacing(str) #> [1] \"글쓰기에서 맞춤법과 띄어쓰기를 올바르게 하는 것은 좋은 글이 될 수 있는 요건 중 하나이다. 하지만 요즘 학생들은 부족한 어문 규정 지식으로 인해 맞춤법과 띄어쓰기에서 많은 오류를 범하기도 한다. 본 연구는 그 중 띄어쓰기가 글을 인식하는 데 중요한 역할을 하는 것으로 판단하여, 대학생들이 띄어쓰기에 대해서 어느 정도 정확하게 인식하고 있는지, 실제 오류 실태는 어떠한지에 대해 살펴서 그 오류를 개선할 수 있는 교육 방안을 마련할 필요가 있다고 판단하였다.\" # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the user-defined person dictionary file. — get_userdic_meta","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"사용자 사전 중에서 명사 사전의 내용을 조회한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"","code":"get_userdic_meta(   noun_type = c(\"person\", \"place\", \"nnp\", \"nng\"),   userdic_path = NULL )"},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"noun_type character. 인명사전, 지명사전, 고유명사 사전, 일반명사 사전에서 조회할 사용자 정의 명사 사전 선택. 기본값은 \"person\"로 인명사전을 지정함. userdic_path character. 사용자 정의 명사 사전 파일이 존재하는 경로. 지정하지 않으면 사전이 설치된 기본 경로에서 파일을 읽어온다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"spec_tbl_df. 명사 사전 정의를 담은 tibble 객체. tibble 객체에서 변수는 다음과 같다.: \"표층형\" : 낱말명. \"미지정1\" : 사용하지 않는 컬럼. \"미지정2\" : 사용하지 않는 컬럼. \"미지정3\" : 사용하지 않는 컬럼. \"품사태그\" : 인명의 품사. NNP를 사용함. \"의미부류\" : 인명, 혹은 지명과 같은 의미 부류. \"종성유무\" : 낱말의 마지막 음절의 종성 여부. T, F 입력. \"읽기\" : 읽어서 소리나는 말. \"타입\" : inflected, compound, Preanalysis, *. \"첫번째 품사\" : 기분석으로 나눠지는 토큰에 대한 각 품사 입력. \"마지막 품사\" : 기분석으로 나눠지는 토큰에 대한 각 품사 입력. \"표현\" : 낱말이 토큰들로 나눠질 경우의 원형을 +로 묶어 입력 \"인덱스표현\" : 사용하지 않는 컬럼, *로 표현","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"사용자 사전정의 디렉토리의 사전파일 읽어, 정의된 내용을 tibble 객체로 반환한다. 이 기능을 통해서 사용자 명사 사전의 등록(정의) 여부를 파악할 수 있다. 다음과 같은 명사 사용자 정의 사전 파일을 참조한다. 인명사전 : person.csv 지명사전 : place.csv 고유명사사전 : nnp.csv 일반명사사전 : nng.csv 인명, 지명, 고유명사, 일반명사 사전의 경우에는 타입, 첫번째 품사, 마지막 품사, 인텍스표현의 정보는 의미가 없어 모두 *로 표현함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"mecab-ko-dic 품사 태그 설명. <https://docs.google.com/spreadsheets/d/1-9blXKjtjeKZqsf4NzHeYJCrr49-nXeRF6D80udfcwY/edit#gid=1718487366>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/get_userdic_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the user-defined person dictionary file. — get_userdic_meta","text":"","code":"if (FALSE) { # \\dontrun{ get_userdic_meta(\"person\") } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether the final consonant of Korean terms — has_final_consonant","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"한글의 종성 여부","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"","code":"has_final_consonant(x, last = FALSE)"},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"x character. 종성 여부를 확인할 문자. last logical. 마지막 음절만 체크여부. 기본값은 FALSE로 전체 음절을 체크함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"logical. 음절별 종성포함 여부를 의미하는 벡터. 한글이 아닌 음절의 경우에는 FALSE.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"첫 번째 한글 글자는 ‘가’로 유니코드로는 AC00입니다. ‘가’를 시작 위치를 상대적인 위치 값을 구합니다. 종성이 없는 글자 이후에 27개의 종성이 있는 글자가 옵니다. 그리고 다시 종성이 없는 글자가 옵니다. 따라서 28로 나눴을 때 나머지가 없으면 종성이 없는 글자입니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/has_final_consonant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether the final consonant of Korean terms — has_final_consonant","text":"","code":"# \\donttest{ has_final_consonant(\"홍길동\") #> [1] TRUE TRUE TRUE has_final_consonant(\"홍길동\", last = FALSE) #> [1] TRUE TRUE TRUE  has_final_consonant(\"텍스트 분석\") #> [1]  TRUE FALSE FALSE FALSE  TRUE  TRUE # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/install_mecab_ko.html","id":null,"dir":"Reference","previous_headings":"","what":"Installation of Eunjeonhan morpheme analyzer and dic — install_mecab_ko","title":"Installation of Eunjeonhan morpheme analyzer and dic — install_mecab_ko","text":"은전한닢 형태소분석기인 mecab-ko와 은전한닢 형태소분석기 사전인 mecab-ko-dic을 사용자 환경에 설치한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/install_mecab_ko.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Installation of Eunjeonhan morpheme analyzer and dic — install_mecab_ko","text":"","code":"install_mecab_ko()"},{"path":"https://r2bit.com/bitNLP/dev/reference/install_mecab_ko.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Installation of Eunjeonhan morpheme analyzer and dic — install_mecab_ko","text":"Linux와 Mac은 소스를 가져다 컴파일하며, Windows는 바이너리를 가져다 복사한다. Windows는 \"c:/mecab\" 경로에 설치된다. 만약이 다른 경로에 이미 설치하였다면, 이 경로로 옮겨 놓아야 한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/install_mecab_ko.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Installation of Eunjeonhan morpheme analyzer and dic — install_mecab_ko","text":"","code":"if (FALSE) { # \\dontrun{ # install_mecab_ko() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":null,"dir":"Reference","previous_headings":"","what":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"Mecab 형태소 분석기 기반 형태소분석/품사 태깅을 통한 토큰화","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"","code":"morpho_mecab(   x,   type = c(\"noun\", \"noun2\", \"verb\", \"adj\", \"morpheme\"),   indiv = TRUE,   user_dic = NULL,   as_list = FALSE )"},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"x character. 형태소 분석에 사용할 document. type character. 형태소 분석의 결과 유형.모든 품사, 명사, 동사 및 형용사와 같은 토큰화 결과 유형을 지정. \"morpheme\", \"noun\", \"noun2\", \"verb\", \"adj\"중에서 선택. 기본값은 \"noun\"로 일반명사만 추출함. indiv logical. 복수개의 문서일 때 개별 문서를 리스트로 반환할 지를 선택함. TRUE이면 개별 리스트로 반환하고, FALSE이면 하나의 문자 벡터로 반환함. 기본값은 TRUE user_dic mecab-ko 형태소 분석기의 사용자 정의 사전 파일. 기본값은 NULL로 사용자 사전파일을 지정하지 않음. 시스템 사전인 \"/usr/local/lib/mecab/dic/mecab-ko-dic\"(Linux, Mac)를 보완하여 사용됨. 사용자 사전 파일은 mecab-dict-index 명령어로 생성되며, 확장자가 \"dic\"임. as_list logical. 문서의 개수가 한 개일 때, 결과를 리스트로 반환할지의 여부를 선택함. TRUE일 경우에는 리스트 객체로, FALSE일 경우에는 문자 벡터로 결과를 반환함 tidytext 패키지와 함께 사용할 경우에는 TRUE를 사용하는 것이 좋음. 문서 개수가 1개인 경우, 즉 행(관측치)의 개수가 1개인 경우에 데이터프레임 연산에서의 오류를 방지하기 위한 목적의 인수임","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"Mecab 형태소 분석기 결과 구조의 character 벡터 혹은 character 벡터를 원소로 갖는 list 객체.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"type 인수에 따라 토큰화되는 품사의 종류는 다음과 같다.: \"morpheme\" : 모든 품사 토큰화 \"noun\" : 일반명사(NNG) 토큰화 \"noun2\" : 모든 명사 토큰화 \"verb\" : 동사 토큰화 \"adj\" : 형용사 토큰화 Mecab 형태소 분석기의 시스템 사전의 경로는 \"/usr/local/lib/mecab/dic/mecab-ko-dic\"이며, NIADic이 포팅되어 들어 있음. 그러나, \"/usr/local/lib/mecab/dic/mecab-ko-dic2\"에는 NIADic이 포함되어 있지 않음. 이것은 bitNLP 패키지에서는 참조하지 않음.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/morpho_mecab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"part-of-speech tagger based on mecab-ko morphology analyzer — morpho_mecab","text":"","code":"# \\donttest{ ## Mecab 형태소 분석 morpho_mecab(\"아버지가 방에 들어가신다.\") #>      NNG      NNG  #> \"아버지\"     \"방\"  morpho_mecab(\"아버지가 방에 들어가신다.\", type = \"morpheme\") #>      NNG      JKS      NNG      JKB       VV    EP+EF       SF  #> \"아버지\"     \"가\"     \"방\"     \"에\" \"들어가\"   \"신다\"      \".\"  morpho_mecab(\"아버지가 방에 들어가신다.\", type = \"verb\") #>       VV  #> \"들어가\"   dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\")  str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\" morpho_mecab(str) #>    NNG    NNG    NNG    NNG    NNG    NNG    NNG    NNG    NNG  #> \"신혼\" \"부부\" \"주말\" \"부부\" \"놀이\" \"공원\" \"자유\" \"이용\" \"구매\"  morpho_mecab(str, user_dic = dic_file) #>          NNG          NNG          NNG          NNG          NNG          NNG  #>   \"신혼부부\"   \"주말부부\"       \"놀이\"       \"공원\" \"자유이용권\"       \"구매\"   morpho_mecab(c(\"무궁화꽃이 피었습니다.\", \"나는 어제 올갱이국밥을 먹었다.\")) #> [[1]] #>      NNG      NNG  #> \"무궁화\"     \"꽃\"  #>  #> [[2]] #>      NNG      NNG  #> \"올갱이\"   \"국밥\"  #>  morpho_mecab(c(\"무궁화꽃이 피었습니다.\", \"나는 어제 올갱이국밥을 먹었다.\"), indiv = FALSE) #>      NNG      NNG      NNG      NNG  #> \"무궁화\"     \"꽃\" \"올갱이\"   \"국밥\"   # Using morpho_mecab with tidytext package library(dplyr)  nho_noun_indiv <- president_speech %>%   filter(president %in% \"노무현\") %>%   filter(stringr::str_detect(category, \"^외교\")) %>%   tidytext::unnest_tokens(     out = \"speech_noun\",     input = \"doc\",     token = morpho_mecab   )     nho_noun_indiv  #> # A tibble: 44,316 × 7 #>    id       president category  type  title                    date  speech_noun #>    <chr>    <chr>     <chr>     <chr> <chr>                    <chr> <chr>       #>  1 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 우정        #>  2 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 해          #>  3 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 개막식      #>  4 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 축하        #>  5 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 행사        #>  6 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 축하        #>  7 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 참석        #>  8 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 모두        #>  9 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 환영        #> 10 DOC_0001 노무현    외교-통상 치사  \"2005 한일 우정의 해 개막식 축사 \"… 2005… 감사        #> # ℹ 44,306 more rows # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/movie_ratings_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Naver sentiment movie corpus v1.0 — movie_ratings_train","title":"Naver sentiment movie corpus v1.0 — movie_ratings_train","text":"네이버 영화 리뷰에서 스크랩한 데이터이며, 모두 140자 미만의 길이고, 0(Negative)과 1(Positive)로 라벨링 되어있음","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/movie_ratings_train.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naver sentiment movie corpus v1.0 — movie_ratings_train","text":"","code":"data(movie_ratings_train)  data(movie_ratings_test)"},{"path":"https://r2bit.com/bitNLP/dev/reference/movie_ratings_train.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Naver sentiment movie corpus v1.0 — movie_ratings_train","text":"3개의 변수와 150,000개(train), 50,000(test)의 관측치로 구성된 티블(tibble) 객체.: id character. 리뷰 아이디 document character. 영화 리뷰 label integer. 긍부정의 정보. 부정(0), 긍정(1)","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/movie_ratings_train.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Naver sentiment movie corpus v1.0 — movie_ratings_train","text":"\"Naver sentiment movie corpus v1.0\" github <https://github.com/e9t/nsmc>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/movie_ratings_train.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Naver sentiment movie corpus v1.0 — movie_ratings_train","text":"","code":"if (FALSE) { # \\dontrun{ data(movie_ratings_train) data(movie_ratings_test)  head(movie_ratings_train) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/polarity.html","id":null,"dir":"Reference","previous_headings":"","what":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","title":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","text":"서울대학교 언어학과에서 세종 구문분석 코퍼스로부터 선별한 332개 신문기사의 7,744 문장을 주석 대상으로 구축한 한국어 감정 코퍼스","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/polarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","text":"","code":"data(polarity)"},{"path":"https://r2bit.com/bitNLP/dev/reference/polarity.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","text":"10개의 변수와 15,736개의 관측치로 구성된 데이터 프레임.: ngram character. N-GRAM freq integer. 빈도수 COMP numeric. complex 확률 NEG numeric. negative 확률 NEUT numeric. neutral 확률 None numeric. none 확률 POS numeric. positive 확률 max.value character. max 항목 max.prop numeric. max 항목 확률 type factor. 구분. \"kosac\"","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/polarity.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","text":"Korean Sentiment Analysis Corpus homepage. http://word.snu.ac.kr/kosac/index.php","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/polarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KOSAC(Korean Sentiment Analysis Corpus) sentiment dictionary — polarity","text":"","code":"if (FALSE) { # \\dontrun{ data(polarity)  head(polarity) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":null,"dir":"Reference","previous_headings":"","what":"President's Speech — president_speech","title":"President's Speech — president_speech","text":"대통령기록연구실 홈페이지에서 수집한 역대 퇴임 대통령들의 연설문","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"President's Speech — president_speech","text":"","code":"data(president_speech)"},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"President's Speech — president_speech","text":"7개의 변수와 2,408개의 관측치로 구성된 티블(tibble) 객체.: id character 연설문 아이디 president character 연설 대통령 category character 연설문 분야 type character 연설문 유형 title character 연설문 제목 speech_date double 연설 일자 doc character 연설문 내용","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"President's Speech — president_speech","text":"\"행정안전무 대통령기록관 홈페이지의 기록컬렉션>연설기록 페이지 <http://www.pa.go.kr/research/contents/speech/index.jsp>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"President's Speech — president_speech","text":"역대 대통령 중 김대중, 노무현, 이명박 3명의 대통령 연설문만 수록되어 있음","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/president_speech.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"President's Speech — president_speech","text":"","code":"if (FALSE) { # \\dontrun{ data(president_speech)  head(president_speech) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/regist_mecab_ko.html","id":null,"dir":"Reference","previous_headings":"","what":"Register the path where Mecab-Ko is installed — regist_mecab_ko","title":"Register the path where Mecab-Ko is installed — regist_mecab_ko","text":"은전한닢 형태소분석기인 mecab-ko가 설치된 경로는 bitNLP 패키지에 등록.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/regist_mecab_ko.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register the path where Mecab-Ko is installed — regist_mecab_ko","text":"","code":"regist_mecab_ko()"},{"path":"https://r2bit.com/bitNLP/dev/reference/regist_mecab_ko.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Register the path where Mecab-Ko is installed — regist_mecab_ko","text":"이 메뉴는 MS-Windows 운영체제에서만 지원한다. bitNLP를 설치하기 전에, 이미 mecab-ko를 설치하였을 경우에 그 설치 경로를 bitNLP가 인식하도록 도와준다. Windows는 mecab-ko를 반드시 \"c:/mecab\" 경로에 설치해야 한다. 만약이 다른 경로에 이미 설치하였다면, 이 경로로 옮겨 놓아야 한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/regist_mecab_ko.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register the path where Mecab-Ko is installed — regist_mecab_ko","text":"","code":"if (FALSE) { # \\dontrun{ # regist_mecab_ko() } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace/remove/join/separate strings in text data — replace_text","title":"Replace/remove/join/separate strings in text data — replace_text","text":"텍스트 데이터의 전처리 과정 중 패턴 일치되는 문자열에 대해서 다른 문자열로 대체하거나 제거, 혹은 결합한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace/remove/join/separate strings in text data — replace_text","text":"","code":"replace_text(   doc,   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores(),   verbos = TRUE )  concat_text(   doc,   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores(),   verbos = TRUE )  split_text(   doc,   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores(),   verbos = TRUE )  remove_text(   doc,   chunk = round(length(if (tibble::is_tibble(doc)) dplyr::pull(doc) else doc)/mc.cores),   mc.cores = parallel::detectCores(),   verbos = TRUE )"},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace/remove/join/separate strings in text data — replace_text","text":"doc character. 문자열 대체/제거/결합/분리를 수행할 문자열 벡터 chunk integer. 병렬 작업 수행 시 처리 단위인 chunk mc.cores integer. 병렬 작업 수행 시 사용할 코어의 개수 verbos logical. 메타의 Rule 당 처리된 건수를 화면에 출력할 지의 여부","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace/remove/join/separate strings in text data — replace_text","text":"character. 문자열 대체/제거/결합이 수행된 문자열 벡터.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace/remove/join/separate strings in text data — replace_text","text":"Windows 운영체제에서는 병력작업이 지원되지 않기 때문에, 사용자의 설정과는 무관하게 mc.cores의 값이 1로 적용됩니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/replace_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace/remove/join/separate strings in text data — replace_text","text":"","code":"# \\donttest{ ##====================================================== ## 문자열 대체 ##======================================================  # 문자열 대체 메타 신규 등록 meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_replace.csv\") set_meta(\"replace\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 대체 룰 확인하기 get_meta(\"replace\") #>        rule_nm    rule_class #> 1  다중 구두점   구두점 대체 #> 2         남편 유사단어 대체 #> 3   베이비시터 유사단어 대체 #> 4     텔레비전 유사단어 대체 #> 5         CCTV 유사단어 대체 #> 6       할머니 유사단어 대체 #> 7       어머니 유사단어 대체 #> 8       아버지 유사단어 대체 #> 9         아들 유사단어 대체 #> 10          딸 유사단어 대체 #> 11      화이팅 유사단어 대체 #> 12      모유량 유사단어 대체 #> 13        베개 유사단어 대체 #> 14        초산 유사단어 대체 #> 15        급여 유사단어 대체 #>                                                   pattern    replace  use #> 1                                               (\\\\.){2,}        \\\\. TRUE #> 2                                               신랑|남편       남편 TRUE #> 3  베비시터|((육아|아이|아기)[[:space:]]*(도우미|돌보미)) 베이비시터 TRUE #> 4                          TV|테레비|티브이|텔레비젼|티비   텔레비전 TRUE #> 5           (CC|cc|씨씨)[[:space:]]?(텔레비전|티비|tv|TV)       CCTV TRUE #> 6                                     할(미|머님|무니|매)     할머니 TRUE #> 7                                 엄마|어머님|엄니|어무니     어머니 TRUE #> 8                                      아버님|아빠|아부지     아버지 TRUE #> 9                              아들(래미|아이|애|내미|램)       아들 TRUE #> 10                               딸(래미|아이|애|내미|램)         딸 TRUE #> 11                                     파이팅|홧팅|퐈이팅     화이팅 TRUE #> 12                                모유[[:space:]]?[양|량]     모유량 TRUE #> 13                                           [베배][게개]       베개 TRUE #> 14                              (첫|처음)[[:space:]]*출산       초산 TRUE #> 15                                              월급|봉급       급여 TRUE  doc_content <- buzz[, \"CONTENT\"]  # 문자열 대체, verbos = FALSE, chunk = 200 doc_content_after <- replace_text(doc_content, verbos = FALSE, chunk = 200)  # 문자열 대체, chunk = 500, mc.cores = 8 doc_content_after <- replace_text(doc_content, chunk = 500, mc.cores = 8) #> ── Replace: [구두점 대체] - 다중 구두점 ───────────────────────────────── 2건 ── #> ── Replace: [유사단어 대체] - CCTV ────────────────────────────────────── 3건 ── #> ── Replace: [유사단어 대체] - 급여 ────────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 남편 ──────────────────────────────────── 323건 ── #> ── Replace: [유사단어 대체] - 딸 ──────────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 모유량 ──────────────────────────────────── 1건 ── #> ── Replace: [유사단어 대체] - 베개 ────────────────────────────────────── 5건 ── #> ── Replace: [유사단어 대체] - 베이비시터 ──────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 아들 ────────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 아버지 ──────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 어머니 ──────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 초산 ────────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 텔레비전 ────────────────────────────────── 3건 ── #> ── Replace: [유사단어 대체] - 할머니 ──────────────────────────────────── 0건 ── #> ── Replace: [유사단어 대체] - 화이팅 ──────────────────────────────────── 0건 ── # } # \\donttest{ ##====================================================== ## 문자열 결합 ##======================================================  # 문자열 결합 메타 신규 등록 meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_concat.csv\") set_meta(\"concat\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 결합 룰 확인하기 get_meta(\"concat\") #>                 rule_nm                pattern    replace  use #> 1 (하원도우미) 붙여쓰기 하원[[:space:]]+도우미 하원도우미 TRUE #> 2 (가사도우미) 붙여쓰기 가사[[:space:]]+도우미 가사도우미 TRUE #> 3 (산후도우미) 붙여쓰기 산후[[:space:]]+도우미 산후도우미 TRUE #> 4 (친정어머니) 붙여쓰기 친정[[:space:]]+어머니 친정어머니 TRUE #> 5 (베이비시터) 붙여쓰기 베이비[[:space:]]+시터 베이비시터 TRUE #> 6   (연말정산) 붙여쓰기   연말[[:space:]]+정산   연말정산 TRUE #> 7   (출산휴가) 붙여쓰기   출산[[:space:]]+휴가   출산휴가 TRUE #> 8   (시어머니) 붙여쓰기   시[[:space:]]+어머니   시어머니 TRUE #> 9   (육아휴직) 붙여쓰기   육아[[:space:]]+휴직   육아휴직 TRUE  doc_content <- buzz[, \"CONTENT\"]  ## verbos = FALSE, chunk = 200 doc_content_after <- concat_text(doc_content, verbos = FALSE, chunk = 200)  ## chunk = 500, mc.cores = 8 doc_content_after <- concat_text(doc_content, chunk = 500, mc.cores = 8) #> ── Concat: (가사도우미) 붙여쓰기 ─────────────────────────────────────── 22건 ── #> ── Concat: (베이비시터) 붙여쓰기 ──────────────────────────────────────── 1건 ── #> ── Concat: (산후도우미) 붙여쓰기 ──────────────────────────────────────── 1건 ── #> ── Concat: (시어머니) 붙여쓰기 ────────────────────────────────────────── 1건 ── #> ── Concat: (연말정산) 붙여쓰기 ────────────────────────────────────────── 1건 ── #> ── Concat: (육아휴직) 붙여쓰기 ────────────────────────────────────────── 2건 ── #> ── Concat: (출산휴가) 붙여쓰기 ────────────────────────────────────────── 1건 ── #> ── Concat: (친정어머니) 붙여쓰기 ──────────────────────────────────────── 5건 ── #> ── Concat: (하원도우미) 붙여쓰기 ──────────────────────────────────────── 1건 ── # } # \\donttest{ ##====================================================== ## 문자열 분리 ##======================================================  # 문자열 분리 메타 신규 등록 meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_split.csv\") set_meta(\"split\", fname, fileEncoding = \"utf8\")  # 등록된 문자열 분리 룰 확인하기 get_meta(\"split\") #>                  rule_nm #> 1 (도우미) 유형 띄어쓰기 #>                                                    pattern replace  use #> 1 (하원|등하원|등원|입주|교포|가사|산후|보육|산모)(도우미) \\\\1 \\\\2 TRUE  doc_content <- buzz[, \"CONTENT\"]  # 문자열 분리, verbos = FALSE, chunk = 200 doc_content_after <- split_text(doc_content, verbos = FALSE, chunk = 200)  # 문자열 분리, chunk = 500, mc.cores = 8 doc_content_after <- split_text(doc_content, chunk = 500, mc.cores = 8) #> ── Split: (도우미) 유형 띄어쓰기 ──────────────────────────────────────── 6건 ── # } # \\donttest{ ##====================================================== ## 문자열 제거 ##======================================================  # 문자열 제거 메타 신규 등록 meta_path <- system.file(\"meta\", package = \"bitNLP\") fname <- glue::glue(\"{meta_path}/preparation_remove.csv\") set_meta(\"remove\", fname, fileEncoding = \"utf8\") #> Warning: incomplete final line found by readTableHeader on '/private/var/folders/zy/rmhmyp4n0fd1_t0q9y_dy0hm0000gn/T/RtmphSfuM2/temp_libpatha62073cffd91/bitNLP/meta/preparation_remove.csv'  # 등록된 문자열 제거 룰 확인하기 get_meta(\"remove\") #>           rule_nm                                         pattern  use #> 1 카페 안내문구 1 게시판[[:space:]]*이용전[[:print:]]*이동됩니다. TRUE #> 2 카페 안내문구 2                  카페이용 전[[:print:]]*참고\\\\) TRUE #> 3 카페 안내문구 3                 게시글 작성[[:print:]]*35756864 TRUE #> 4 카페 안내문구 4             흥부야[[:print:]]*기타 하고 싶은 말 TRUE #> 5        URL 문구   (http|www)([a-zA-Z0-9\\\\>\\\\/\\\\.\\\\:\\\\=\\\\&\\\\_])* TRUE  doc_content <- buzz[, \"CONTENT\"]  ## verbos = FALSE, chunk = 800 doc_content_after <- remove_text(doc_content, verbos = FALSE, chunk = 800)  ## chunk = 500, mc.cores = 8 doc_content_after <- remove_text(doc_content, chunk = 500, mc.cores = 8) #> ── Removes: URL 문구 ─────────────────────────────────────────────────── 40건 ── #> ── Removes: 카페 안내문구 1 ──────────────────────────────────────────── 33건 ── #> ── Removes: 카페 안내문구 2 ───────────────────────────────────────────── 9건 ── #> ── Removes: 카페 안내문구 3 ──────────────────────────────────────────── 47건 ── #> ── Removes: 카페 안내문구 4 ──────────────────────────────────────────── 16건 ── # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/rest_area.html","id":null,"dir":"Reference","previous_headings":"","what":"Highway rest area related buzz — rest_area","title":"Highway rest area related buzz — rest_area","text":"네이버와 다음 카페와 블로그의 고속도로 휴계소 키워드로 수집한 텍스트 데이터임","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/rest_area.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highway rest area related buzz — rest_area","text":"","code":"data(rest_area)"},{"path":"https://r2bit.com/bitNLP/dev/reference/rest_area.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Highway rest area related buzz — rest_area","text":"5개의 변수와 26,168개의 관측치로 구성된 티블(tibble) 객체.: SITE_TYPE character. 게시물 사이트 유형. \"BLOG\", \"CAFE\" 중 하나의 값을 가짐 SITE character. 게시물 사이트. \"DAUM\", \"NAVER\"중 하나의 값을 가짐 PUBLISH_DT character. 게시물 등록일자로, \"YYMMDD\" 포맷의 텍스트 데이터 TITLE character. 게시물 제목 CONTENT character. 게시물 본문","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/rest_area.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Highway rest area related buzz — rest_area","text":"","code":"if (FALSE) { # \\dontrun{ data(rest_area)  head(rest_area) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"KNU Korean Sentiment Dictionary — sentiment_dic","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"2018년도 군산대학교 소프트웨어융합공학과 Data Intelligence Lab에서 개발한 한국어 감성사전으로 총 14,841개의 1-gram, 2-gram, ..., 8-gram, 관용구, 문형, 축약어, 이모티콘 등에 대한 긍정, 중립, 부정 판별 및 정도(degree)값 계산","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"","code":"data(sentiment_dic)"},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"4개의 변수와 14,841개의 관측치로 구성된 데이터 프레임.: word character. 사전 단어 word_root character. 어근 polarity integer. 긍부정의 정보. 매우 부정(-2), 부정(-1), 중립(0), 긍정(1), 매우 긍정(2) n_gram integer. n-Gram 수","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"\"KNU 한국어 감성사전\" github <https://github.com/park1200656/KnuSentiLex>","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"표준국어대사전을 구성하는 각 단어의 뜻풀이를 분석하여 긍부정어를 추출하였으며, 표준국어대사전을 구성하는 형용사, 부사, 동사, 명사의 모든 뜻풀이에 대한 긍정, 중립, 부정으로 분류하기 위해 Bi-LSTM 딥 러닝 모델 사용","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/sentiment_dic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KNU Korean Sentiment Dictionary — sentiment_dic","text":"","code":"if (FALSE) { # \\dontrun{ data(sentiment_dic)  head(sentiment_dic) } # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"N-gram Tokenizer — tokenize_noun_ngrams","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"명사를 추출하여 n-gram으로 토큰화합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"","code":"tokenize_noun_ngrams(   x,   n = 2L,   n_min = n,   stopwords = character(),   ngram_delim = \" \",   simplify = FALSE,   type = c(\"noun\", \"noun2\"),   user_dic = NULL,   mc.cores = parallel::detectCores() )"},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"x character. 토큰화할 문자열 벡터 n integer. n-gram의 단어 수입니다. 1 이상의 정수. 기본값은 2. n_min integer. 이것은 1보다 크거나 같고 n보다 작거나 같은 정수여야 함 stopwords character. n-그램에서 제외할 불용어의 문자형 벡터 ngram_delim character. 생성된 n-gram에서 단어 사이의 구분 기호 simplify logical. 기본값은 FALSE로 입력 길이에 관계없이 일관된 값이 반환되도록 list 객체로 반환. TRUE인 경우 x가 단일 값일경우에는 문자 벡터를 반환 mc.cores integer. 병렬 작업 수행 시 사용할 코어의 개수","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"토큰화된 character 벡터를 성분으로 갖는 list. simplify값이 TRUE이고 x가 단일값일 때에는 character 벡터","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"MS-Windows에서는 병렬처리를 지원하지 않음 CPU 자원으로 1개의 core만 지원하는 무료 RStudio Cloud 환경에서는 mc.cores의 값을 1로 설정해야 합니다. 만약 이 설정을 누락하면 에러가 발생합니다. MS-Windows 환경에서는 mc.cores의 값을 1로 설정하지 않아도 정상적으로 동작합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/tokenize_noun_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"N-gram Tokenizer — tokenize_noun_ngrams","text":"","code":"# \\donttest{ tokenize_noun_ngrams(president_speech$doc[1:2]) #> [[1]] #>   [1] \"우정 해\"       \"해 개막식\"     \"개막식 축하\"   \"축하 행사\"     #>   [5] \"행사 축하\"     \"축하 참석\"     \"참석 모두\"     \"모두 환영\"     #>   [9] \"환영 감사\"     \"감사 인사\"     \"인사 전\"       \"전 이웃\"       #>  [13] \"이웃 옛날\"     \"옛날 이웃\"     \"이웃 이웃\"     \"이웃 사정\"     #>  [17] \"사정 통신사\"   \"통신사 절\"     \"절 시절\"       \"시절 연락선\"   #>  [21] \"연락선 시대\"   \"시대 항공기\"   \"항공기 하루\"   \"하루 안\"       #>  [25] \"안 시대\"       \"시대 교통\"     \"교통 발달\"     \"발달 통신\"     #>  [29] \"통신 관계\"     \"관계 경제\"     \"경제 교류\"     \"교류 말\"       #>  [33] \"말 협력\"       \"협력 국음\"     \"국음 마음\"     \"마음 실행\"     #>  [37] \"실행 가공\"     \"가공 과학\"     \"과학 기술\"     \"기술 옛날\"     #>  [41] \"옛날 사이\"     \"사이 불편\"     \"불편 문제\"     \"문제 생각\"     #>  [45] \"생각 상황\"     \"상황 양국\"     \"양국 관계\"     \"관계 불편\"     #>  [49] \"불편 생존\"     \"생존 자체\"     \"자체 위협\"     \"위협 사이\"     #>  [53] \"사이 유감\"     \"유감 친구\"     \"친구 방법\"     \"방법 관계\"     #>  [57] \"관계 숙명\"     \"숙명 친구\"     \"친구 관계\"     \"관계 친구\"     #>  [61] \"친구 친구\"     \"친구 미래\"     \"미래 적극\"     \"적극 친구\"     #>  [65] \"친구 손\"       \"손 불행\"       \"불행 평화\"     \"평화 번영\"     #>  [69] \"번영 미래\"     \"미래 관계\"     \"관계 자리\"     \"자리 양국\"     #>  [73] \"양국 관계\"     \"관계 도로\"     \"도로 표현\"     \"표현 전\"       #>  [77] \"전 경제\"       \"경제 도로는\"   \"도로는 고속도\" \"고속도 수준\"   #>  [81] \"수준 정치\"     \"정치 안보\"     \"안보 측면\"     \"측면 협력\"     #>  [85] \"협력 도로\"     \"도로 개통\"     \"개통 문화\"     \"문화 도로\"     #>  [89] \"도로 길\"       \"길 길\"         \"길 위\"         \"위 장애물\"     #>  [93] \"장애물 양국\"   \"양국 협력\"     \"협력 관계\"     \"관계 고속\"     #>  [97] \"고속 도로\"     \"도로 장애물\"   \"장애물 직시\"   \"직시 양국\"     #> [101] \"양국 정부\"     \"정부 국민\"     \"국민 적극\"     \"적극 노력\"     #> [105] \"노력 가슴\"     \"가슴 우정\"     \"우정 불\"       \"불 자리\"       #> [109] \"자리 우정\"     \"우정 불\"       \"불 양국\"       \"양국 국민\"     #> [113] \"국민 사이\"     \"사이 우정\"     \"우정 계기\"     \"계기 이틀\"     #> [117] \"이틀 전\"       \"전 주최\"       \"주최 행사\"     \"행사 성공\"     #> [121] \"성공 성원\"     \"성원 참석\"     \"참석 격려\"     \"격려 총리\"     #> [125] \"총리 국민\"     \"국민 자리\"     \"자리 감사\"     \"감사 올해\"     #> [129] \"올해 양국\"     \"양국 수교\"     \"수교 해\"       \"해 일\"         #> [133] \"일 양국\"       \"양국 우정\"     \"우정 성공\"     \"성공 때\"       #> [137] \"때 보람\"       \"보람 생각\"     \"생각 올해\"     \"올해 이전\"     #> [141] \"이전 양국\"     \"양국 국민\"     \"국민 교류\"     \"교류 국민\"     #> [145] \"국민 교류\"     \"교류 해\"       \"해 감사\"       #>  #> [[2]] #>  [1] \"각하 국민\"   \"국민 신년\"   \"신년 인사\"   \"인사 새해\"   \"새해 축복\"   #>  [6] \"축복 해\"     \"해 기원\"     \"기원 올해\"   \"올해 양국\"   \"양국 관계\"   #> [11] \"관계 발전\"   \"발전 전기\"   \"전기 중\"     \"중 교류\"     \"교류 해\"     #> [16] \"해 경제\"     \"경제 학술\"   \"학술 문화\"   \"문화 체육\"   \"체육 청소년\" #> [21] \"청소년 분야\" \"분야 행사\"   \"행사 본격\"   \"본격 국민\"   \"국민 교류\"   #> [26] \"교류 협력\"   \"협력 시대\"   \"시대 나라\"   \"나라 교역\"   \"교역 상대국\" #> [31] \"상대국 투자\" \"투자 대상\"   \"대상 국\"     \"국 한국인\"   \"한국인 방문\" #> [36] \"방문 서로\"   \"서로 문화\"   \"문화 이웃\"   \"이웃 양국\"   \"양국 우호\"   #> [41] \"우호 협력\"   \"협력 올해\"   \"올해 교류\"   \"교류 행사\"   \"행사 강화\"   #> [46] \"강화 각하\"   \"각하 합의\"   \"합의 전면\"   \"전면 협력\"   \"협력 동반자\" #> [51] \"동반자 관계\" \"관계 심화\"   \"심화 평화\"   \"평화 공동\"   \"공동 번영\"   #> [56] \"번영 미래\"   \"미래 기대\"   \"기대 각하\"   \"각하 건강\"   \"건강 무궁\"   #> [61] \"무궁 발전\"   \"발전 기원\"   #>   # simplify = TRUE tokenize_noun_ngrams(president_speech$doc[1], simplify = TRUE) #>   [1] \"우정 해\"       \"해 개막식\"     \"개막식 축하\"   \"축하 행사\"     #>   [5] \"행사 축하\"     \"축하 참석\"     \"참석 모두\"     \"모두 환영\"     #>   [9] \"환영 감사\"     \"감사 인사\"     \"인사 전\"       \"전 이웃\"       #>  [13] \"이웃 옛날\"     \"옛날 이웃\"     \"이웃 이웃\"     \"이웃 사정\"     #>  [17] \"사정 통신사\"   \"통신사 절\"     \"절 시절\"       \"시절 연락선\"   #>  [21] \"연락선 시대\"   \"시대 항공기\"   \"항공기 하루\"   \"하루 안\"       #>  [25] \"안 시대\"       \"시대 교통\"     \"교통 발달\"     \"발달 통신\"     #>  [29] \"통신 관계\"     \"관계 경제\"     \"경제 교류\"     \"교류 말\"       #>  [33] \"말 협력\"       \"협력 국음\"     \"국음 마음\"     \"마음 실행\"     #>  [37] \"실행 가공\"     \"가공 과학\"     \"과학 기술\"     \"기술 옛날\"     #>  [41] \"옛날 사이\"     \"사이 불편\"     \"불편 문제\"     \"문제 생각\"     #>  [45] \"생각 상황\"     \"상황 양국\"     \"양국 관계\"     \"관계 불편\"     #>  [49] \"불편 생존\"     \"생존 자체\"     \"자체 위협\"     \"위협 사이\"     #>  [53] \"사이 유감\"     \"유감 친구\"     \"친구 방법\"     \"방법 관계\"     #>  [57] \"관계 숙명\"     \"숙명 친구\"     \"친구 관계\"     \"관계 친구\"     #>  [61] \"친구 친구\"     \"친구 미래\"     \"미래 적극\"     \"적극 친구\"     #>  [65] \"친구 손\"       \"손 불행\"       \"불행 평화\"     \"평화 번영\"     #>  [69] \"번영 미래\"     \"미래 관계\"     \"관계 자리\"     \"자리 양국\"     #>  [73] \"양국 관계\"     \"관계 도로\"     \"도로 표현\"     \"표현 전\"       #>  [77] \"전 경제\"       \"경제 도로는\"   \"도로는 고속도\" \"고속도 수준\"   #>  [81] \"수준 정치\"     \"정치 안보\"     \"안보 측면\"     \"측면 협력\"     #>  [85] \"협력 도로\"     \"도로 개통\"     \"개통 문화\"     \"문화 도로\"     #>  [89] \"도로 길\"       \"길 길\"         \"길 위\"         \"위 장애물\"     #>  [93] \"장애물 양국\"   \"양국 협력\"     \"협력 관계\"     \"관계 고속\"     #>  [97] \"고속 도로\"     \"도로 장애물\"   \"장애물 직시\"   \"직시 양국\"     #> [101] \"양국 정부\"     \"정부 국민\"     \"국민 적극\"     \"적극 노력\"     #> [105] \"노력 가슴\"     \"가슴 우정\"     \"우정 불\"       \"불 자리\"       #> [109] \"자리 우정\"     \"우정 불\"       \"불 양국\"       \"양국 국민\"     #> [113] \"국민 사이\"     \"사이 우정\"     \"우정 계기\"     \"계기 이틀\"     #> [117] \"이틀 전\"       \"전 주최\"       \"주최 행사\"     \"행사 성공\"     #> [121] \"성공 성원\"     \"성원 참석\"     \"참석 격려\"     \"격려 총리\"     #> [125] \"총리 국민\"     \"국민 자리\"     \"자리 감사\"     \"감사 올해\"     #> [129] \"올해 양국\"     \"양국 수교\"     \"수교 해\"       \"해 일\"         #> [133] \"일 양국\"       \"양국 우정\"     \"우정 성공\"     \"성공 때\"       #> [137] \"때 보람\"       \"보람 생각\"     \"생각 올해\"     \"올해 이전\"     #> [141] \"이전 양국\"     \"양국 국민\"     \"국민 교류\"     \"교류 국민\"     #> [145] \"국민 교류\"     \"교류 해\"       \"해 감사\"        str <- \"신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다.\"  tokenize_noun_ngrams(str) #> [[1]] #> [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" #> [7] \"자유 이용\" \"이용 구매\" #>   # 불용어 처리 tokenize_noun_ngrams(str, stopwords = \"구매\") #> [[1]] #> [1] \"신혼 부부\" \"부부 주말\" \"주말 부부\" \"부부 놀이\" \"놀이 공원\" \"공원 자유\" #> [7] \"자유 이용\" #>    # 사용자 정의 사전 사용 dic_path <- system.file(\"dic\", package = \"bitNLP\") dic_file <- glue::glue(\"{dic_path}/buzz_dic.dic\") tokenize_noun_ngrams(str, simplify = TRUE, user_dic = dic_file) #> [1] \"신혼부부 주말부부\" \"주말부부 놀이\"     \"놀이 공원\"         #> [4] \"공원 자유이용권\"   \"자유이용권 구매\"    # n_min tokenize_noun_ngrams(str, n_min = 1, user_dic = dic_file) #> [[1]] #>  [1] \"신혼부부\"          \"신혼부부 주말부부\" \"주말부부\"          #>  [4] \"주말부부 놀이\"     \"놀이\"              \"놀이 공원\"         #>  [7] \"공원\"              \"공원 자유이용권\"   \"자유이용권\"        #> [10] \"자유이용권 구매\"   \"구매\"              #>   # ngram_delim tokenize_noun_ngrams(str, ngram_delim = \":\", user_dic = dic_file) #> [[1]] #> [1] \"신혼부부:주말부부\" \"주말부부:놀이\"     \"놀이:공원\"         #> [4] \"공원:자유이용권\"   \"자유이용권:구매\"   #>  # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/unnest_noun_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","title":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","text":"명사를 추출하여 n-gram으로 토큰화합니다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/unnest_noun_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","text":"","code":"unnest_noun_ngrams(   tbl,   output,   input,   n = 2L,   n_min = n,   ngram_delim = \" \",   drop = TRUE,   collapse = NULL,   ... )"},{"path":"https://r2bit.com/bitNLP/dev/reference/unnest_noun_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","text":"tbl data frame. output character symbol. 출력열로 새로 만들 변수 이름 input character symbol. 입력으로 사용할 변수 이름 n integer. n-gram의 단어 수입니다. 1 이상의 정수. 기본값은 2. n_min integer. 이것은 1보다 크거나 같고 n보다 작거나 같은 정수여야 함 ngram_delim character. 생성된 n-gram에서 단어 사이의 구분 기호 drop logical. 원래 입력 열을 삭제해야 하는지 여부. 기본값은 TRUE이며 원래 입력 열과 새 출력 열의 이름이 같은 경우 무시됨. collapse character vector. 결과에서 개별 n-gram들을 그룹핑할 변수 이름. 기본값은 NULL로 개별 n-gram들을 묶지 않음. ... 토크나이저(tokenize_noun_ngrams)에 전달되는 추가 인수 stopwords character. n-그램에서 제외할 불용어의 문자형 벡터","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/unnest_noun_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","text":"토큰화된 character 벡터를 성분으로 갖는 list. simplify값이 TRUE이고 x가 단일값일 때에는 character 벡터","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/unnest_noun_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper around unnest_tokens for n-grams of noun — unnest_noun_ngrams","text":"","code":"# \\donttest{ library(dplyr)  president_speech %>%   select(title, doc) %>%    filter(row_number() <= 2) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     type = \"noun2\"   ) #> # A tibble: 264 × 2 #>    title                              noun_bigram #>    <chr>                              <chr>       #>  1 \"2005 한일 우정의 해 개막식 축사 \" 일:우정     #>  2 \"2005 한일 우정의 해 개막식 축사 \" 우정:해     #>  3 \"2005 한일 우정의 해 개막식 축사 \" 해:개막식   #>  4 \"2005 한일 우정의 해 개막식 축사 \" 개막식:축하 #>  5 \"2005 한일 우정의 해 개막식 축사 \" 축하:행사   #>  6 \"2005 한일 우정의 해 개막식 축사 \" 행사:축하   #>  7 \"2005 한일 우정의 해 개막식 축사 \" 축하:참석   #>  8 \"2005 한일 우정의 해 개막식 축사 \" 참석:여러분 #>  9 \"2005 한일 우정의 해 개막식 축사 \" 여러분:모두 #> 10 \"2005 한일 우정의 해 개막식 축사 \" 모두:환영   #> # ℹ 254 more rows    president_speech %>%   select(title, doc) %>%    filter(row_number() <= 2) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     drop = FALSE   )    #> # A tibble: 209 × 3 #>    title                              doc                            noun_bigram #>    <chr>                              <chr>                          <chr>       #>  1 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 우정:해     #>  2 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 해:개막식   #>  3 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 개막식:축하 #>  4 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 축하:행사   #>  5 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 행사:축하   #>  6 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 축하:참석   #>  7 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 참석:모두   #>  8 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 모두:환영   #>  9 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 환영:감사   #> 10 \"2005 한일 우정의 해 개막식 축사 \" \"  먼저 한,일 우정의 해 개막식을 축하합니다. 이… 감사:인사   #> # ℹ 199 more rows   # grouping using group_by() function president_speech %>%   filter(row_number() <= 4) %>%   mutate(speech_year = substr(date, 1, 4)) %>%    select(speech_year, title, doc) %>%    group_by(speech_year) %>%   unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\"   ) #> # A tibble: 1,759 × 2 #> # Groups:   speech_year [2] #>    speech_year noun_bigram #>    <chr>       <chr>       #>  1 2005        우정:해     #>  2 2005        해:개막식   #>  3 2005        개막식:축하 #>  4 2005        축하:행사   #>  5 2005        행사:축하   #>  6 2005        축하:참석   #>  7 2005        참석:모두   #>  8 2005        모두:환영   #>  9 2005        환영:감사   #> 10 2005        감사:인사   #> # ℹ 1,749 more rows    # grouping using collapse argument president_speech %>%   filter(row_number() <= 4) %>%   mutate(speech_year = substr(date, 1, 4)) %>%    select(speech_year, title, doc) %>%    unnest_noun_ngrams(     noun_bigram,     doc,     n = 2,     ngram_delim = \":\",     collapse = \"speech_year\"   ) #> # A tibble: 1,759 × 2 #>    speech_year noun_bigram #>    <chr>       <chr>       #>  1 2005        우정:해     #>  2 2005        해:개막식   #>  3 2005        개막식:축하 #>  4 2005        축하:행사   #>  5 2005        행사:축하   #>  6 2005        축하:참석   #>  7 2005        참석:모두   #>  8 2005        모두:환영   #>  9 2005        환영:감사   #> 10 2005        감사:인사   #> # ℹ 1,749 more rows # }"},{"path":"https://r2bit.com/bitNLP/dev/reference/update_userdic.html","id":null,"dir":"Reference","previous_headings":"","what":"update user dictionary with user-defined dictionary files. — update_userdic","title":"update user dictionary with user-defined dictionary files. — update_userdic","text":"수정된 사용자 정의 사전 파일을 이용하여 사용자 사전 업데이트","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/update_userdic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"update user dictionary with user-defined dictionary files. — update_userdic","text":"","code":"update_userdic(userdic_path = \"./user_dic\", dic_file = \"user-dic.dic\")"},{"path":"https://r2bit.com/bitNLP/dev/reference/update_userdic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"update user dictionary with user-defined dictionary files. — update_userdic","text":"userdic_path character. 사용자 정의 명사 사전 파일이 존재하는 경로. 지정하지 않으면 \"./user_dic\"이라는 이름의 경로를 사용함. dic_file character. 생성할 사용자 사전 파일 이름. 지정하지 않으면 \"user-dic.dic\"이라는 이름으로 생성함.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/update_userdic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"update user dictionary with user-defined dictionary files. — update_userdic","text":"사용자 사전정의 디렉토리 내에 있는 \"merged.csv\" 파일로 사용자 정의 사전을 업데이트/생성한다.","code":""},{"path":"https://r2bit.com/bitNLP/dev/reference/update_userdic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"update user dictionary with user-defined dictionary files. — update_userdic","text":"","code":"if (FALSE) { # \\dontrun{ update_userdic() } # }"}]
